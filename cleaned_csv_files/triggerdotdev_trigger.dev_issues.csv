issue_id,issue_number,issue_title,issue_body,comment_id,comment_body
2682753501,1490,bug: Error: Unable to resolve module @trigger.dev/core/v3 ,"### Provide environment information

""@trigger.dev/react-hooks"": ""^3.2.1"",
React native

### Describe the bug

Hi - I'm trying to use the react hooks as stated in the documentation but whenever I try to call authentication or subscribe I get the below error. Can someone please help.

```
Error: Unable to resolve module @trigger.dev/core/v3 from /Users/USER/other/PROJECT/node_modules/@trigger.dev/react-hooks/dist/commonjs/hooks/useApiClient.js: @trigger.dev/core/v3 could not be found within the project or in these directories:
  node_modules
  3 | Object.defineProperty(exports, ""__esModule"", { value: true });
  4 | exports.useApiClient = useApiClient;
> 5 | const v3_1 = require(""@trigger.dev/core/v3"");
    |                       ^
  6 | const contexts_js_1 = require(""../contexts.js"");
  7 | /**
  8 |  * Hook to create an API client instance using authentication context or provided options.
    at ModuleResolver.resolveDependency (Users/USER/other/PROJECT/node_modules/metro/src/node-haste/DependencyGraph/ModuleResolution.js:138:15)
    at DependencyGraph.resolveDependency (Users/USER/other/PROJECT/node_modules/metro/src/node-haste/DependencyGraph.js:231:43)
    at Users/USER/other/PROJECT//node_modules/metro/src/lib/transformHelpers.js:156:21
    at resolveDependencies (Users/USER/other/PROJECT/node_modules/metro/src/DeltaBundler/buildSubgraph.js:42:25)
    at visit (Users/USER/other/PROJECT/node_modules/metro/src/DeltaBundler/buildSubgraph.js:83:30)
    at async Promise.all (index 1)
    at async visit (/Users/USER/other/PROJECT/node_modules/metro/src/DeltaBundler/buildSubgraph.js:92:5)
    at async Promise.all (index 17)
    at async visit (Users/USER/other/PROJECT/node_modules/metro/src/DeltaBundler/buildSubgraph.js:92:5)
    at async Promise.all (index 7)
```

### Reproduction repo

https://github.com/triggerdotdev/trigger.dev

### To reproduce

Build react native application and install package as stated in docs

### Additional information

_No response_",2496759580,"Hi there! I understand you're encountering a module resolution error while trying to use @trigger.dev/react-hooks in your React Native project.

The error you're seeing suggests there's a compatibility issue between the React Native environment and the @trigger.dev packages. Looking at the underlying issue, this is happening because @trigger.dev/react-hooks is trying to import from @trigger.dev/core/v3, but this dependency isn't being resolved correctly in the React Native environment.

Here's what I suggest to resolve this:

1. First, make sure you have all the necessary dependencies installed:
```bash
npm install @trigger.dev/react-hooks@3.2.1 @trigger.dev/core@3.2.1
```

2. Since you're using React Native, you'll need to add the core package explicitly to your dependencies in package.json:
```json
{
  ""dependencies"": {
    ""@trigger.dev/react-hooks"": ""^3.2.1"",
    ""@trigger.dev/core"": ""^3.2.1""
  }
}
```

3. After updating your dependencies, clear your React Native bundler cache:
```bash
# For Metro bundler
npx react-native start --reset-cache
```

Important considerations:
- React Native has specific module resolution rules that can sometimes conflict with packages designed primarily for web React
- Make sure all your @trigger.dev packages are on the same version to avoid compatibility issues
- You might need to configure Metro bundler to properly resolve these packages

If you're still experiencing issues after trying these steps, please let me know:
1. What version of React Native you're using
2. Your metro.config.js configuration (if you have customized it)
3. Whether you're using Expo or bare React Native

The error appears to be a module resolution issue rather than a functional one, so once we get the packages properly resolved, you should be able to use the React hooks as documented.

Let me know if you need any clarification or run into other issues!"
2666435567,1480,"bug: `prismaExtension`'s version detection only works when ""@prisma/client"" is added to `additionalPackages`","### Provide environment information

  System:
    OS: macOS 15.1
    CPU: (11) arm64 Apple M3 Pro
    Memory: 133.08 MB / 18.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 20.18.0 - /opt/homebrew/opt/node@20/bin/node
    npm: 10.8.2 - /opt/homebrew/opt/node@20/bin/npm
    pnpm: 9.12.3 - /opt/homebrew/opt/node@20/bin/pnpm

### Describe the bug

Running `pnpm dlx trigger.dev@latest deploy` fails when using `prismaExtension`'s default config.

Based on [this doc](https://trigger.dev/docs/config/config-file#prisma), the `prismaExtension` should automatically detect the installed version. Without a `version`, the deployment succeeds and silently reports an error:

```bash
% pnpm trigger deploy

Trigger.dev (3.2.0)
------------------------------------------------------
┌  Deploying project
│
◇  Retrieved your account details for ...
│
◇  Successfully built project
✘ [ERROR] Failed to apply extension PrismaExtension onBuildComplete Error: PrismaExtension could not determine the version of @prisma/client. It's possible that the @prisma/client was not used in the project. If this isn't the case, please provide a version in the PrismaExtension options.

      at PrismaExtension.onBuildComplete
  (/Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/@trigger.dev+build@3.2.0_typescript@5.6.3/node_modules/@trigger.dev/build/dist/commonjs/extensions/prisma.js:55:19)
      at notifyExtensionOnBuildComplete
  (file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/build/extensions.js:16:33)
      at async buildWorker
  (file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/build/buildWorker.js:70:21)
      at async _deployCommand
  (file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/commands/deploy.js:120:27)
      at async
  file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/commands/deploy.js:77:16
      at async
  file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/cli/common.js:54:28
      at async wrapCommandAction
  (file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/cli/common.js:40:12)
      at async deployCommand
  (file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/commands/deploy.js:76:12)
      at async
  file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/commands/deploy.js:71:13
      at async handleTelemetry
  (file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/cli/common.js:30:9)
      at async Command.<anonymous>
  (file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/commands/deploy.js:69:9)
      at async Command.parseAsync
  (/Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/commander@9.5.0/node_modules/commander/lib/command.js:935:5)
      at async main
  (file:///Users/guillaume/alephic/trigger-prisma-bug/node_modules/.pnpm/trigger.dev@3.2.0_typescript@5.6.3/node_modules/trigger.dev/dist/esm/index.js:5:5)


│
◇  Successfully deployed version 20241117.8
│
└  Version 20241117.8 deployed with 1 detected task 
```

When adding `version: ""5.22.0""`, the deployment fails entirely:

```bash
% pnpm trigger deploy  

Trigger.dev (3.2.0)
------------------------------------------------------
┌  Deploying project
│
◇  Retrieved your account details for ...
│
◇  Successfully built project
▲ [WARNING] prismaExtension could not resolve the DATABASE_URL environment variable. Make sure you add it to your environment variables. See our docs for more info: https://trigger.dev/docs/deploy-environment-variables


│
◇  Failed to deploy project
│
└  Error: Error building image. Full build logs have been saved to /var/folders/4j/sp9fwh5s369b28x_jjckbgd40000gn/T/trigger-Z2WsDu/build-gwivrttk.log
```

Here's a snippet of the build error:

```
------
> [build 6/7] RUN node node_modules/prisma/build/index.js generate --schema=./prisma/schema.prisma:
#17 0.456 Prisma schema loaded from prisma/schema.prisma
#17 0.579 Error: Command failed with ENOENT: pnpm add @prisma/client@5.22.0 --silent
#17 0.579 spawn pnpm ENOENT
------
Error: failed to solve: process ""/bin/sh -c node node_modules/prisma/build/index.js generate --schema=./prisma/schema.prisma"" did not complete successfully: exit code: 1
```

### Workaround

Adding ""@prisma/client"" to `additionalPackages` fixes the issue:

```tsx
import { defineConfig } from ""@trigger.dev/sdk/v3"";
import { additionalPackages } from ""@trigger.dev/build/extensions/core"";
import { prismaExtension } from ""@trigger.dev/build/extensions/prisma"";

export default defineConfig({
  build: {
    extensions: [
      prismaExtension({ schema: ""prisma/schema.prisma"" }),
      additionalPackages({ packages: [""@prisma/client@5.22.0""] }),
    ]
  }
})
```

### Reproduction repo

https://github.com/gmathieu/trigger-prisma-bug

### To reproduce

- Check out the https://github.com/gmathieu/trigger-prisma-bug
- run `pnpm install`
- Replace `project` with your project ID in `trigger.config.ts` 

Note: Don't worry about `DATABASE_URL` warnings, we're only testing the deployment cycle.

#### Scenario 1: silent failure

- run `pnpm trigger deploy`

#### Scenario 2: build failure with version

- Uncomment [the version](https://github.com/gmathieu/trigger-prisma-bug/blob/daf426141ab496c95d0ee5bc7bad3f429a427c73/trigger.config.ts#L14)
- run `pnpm trigger deploy`

#### Scenario 3: successful deployment with `additionalPackages`

- Uncomment [additionalPackages](https://github.com/gmathieu/trigger-prisma-bug/blob/daf426141ab496c95d0ee5bc7bad3f429a427c73/trigger.config.ts#L20-L22)
- run `pnpm trigger deploy`

Note: `additionalPackages` properly populates the manifest's externals [here](https://github.com/triggerdotdev/trigger.dev/blob/332854bbcbc53703e64e9a5dd71944deabe51f2b/packages/build/src/extensions/prisma.ts#L101-L111), so version can be omitted. 


### Additional information

_No response_",2496773472,"Hi! I understand the issue you're experiencing with the `prismaExtension`'s version detection. This appears to be a known limitation in how the extension currently works with Prisma dependencies.

Here's how to resolve this issue:

1. Update your `trigger.config.ts` to use both the `prismaExtension` and `additionalPackages` together:

```typescript
import { defineConfig } from ""@trigger.dev/sdk/v3"";
import { additionalPackages } from ""@trigger.dev/build/extensions/core"";
import { prismaExtension } from ""@trigger.dev/build/extensions/prisma"";

export default defineConfig({
  build: {
    extensions: [
      prismaExtension({ 
        schema: ""prisma/schema.prisma""
        // Note: You don't need to specify version when using additionalPackages
      }),
      additionalPackages({ 
        packages: [""@prisma/client@5.22.0""] 
      }),
    ]
  }
})
```

This configuration ensures that:
- The Prisma schema is properly loaded
- The correct version of `@prisma/client` is available during build
- The version detection will work correctly

Be aware that:
- You should match the version of `@prisma/client` to what's in your project's package.json
- Make sure your DATABASE_URL environment variable is properly configured for deployment

This is currently the recommended workaround until the version detection functionality is improved in a future release.

Let me know if you need any clarification or run into any other issues!"
2666328334,1479,Errors from the providers aren't handled,"## The Problem

Providers _mostly_ don't report any errors they encounter back up to the core system. This means that if something fails, it's possible for it to just cause an unlimited ""hang"". In my case the hang causes the trigger to have been marked as `started`, when it hasn't actually been started. In the docker provider for example, errors are caught and simply ignored ([example](https://github.com/triggerdotdev/trigger.dev/blob/main/apps/docker-provider/src/index.ts#L134-L148)).

I'm not familiar with the codebase so please let me know if there any mistakes. I spent some time following around the providers, and found a few examples like the following where, a effectively a request to deploy the trigger is just sent but never followed up upon.

https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/v3/marqs/sharedQueueConsumer.server.ts#L544-L560

I'm guessing what needs to happen is that the provider needs some way to return an error code, which core can then ""bubble up"" by changing the deployment status. I didn't want to attempt to make changes without creating an issue first, as I'm missing a lot of context. I'm also not sure how prs such as #1470 interact with this issue for example.

## Example Reproduction

I originally reported this in #1476, but moved it here as I realised my issue was a symptom of a wider problem that I described above. I encountered this while I was setting up authentication for my self hosted docker registry. Trigger would try to deploy a task, and the docker provider would fail to run it, because it couldn't download the image. This would cause trigger to hang exponentially, as it was unaware that the docker provider failed to run the task.

During my testing last night I added a scheduled task that runs every 20 minutes. I then forgot about it, and was messing around with some other things in trigger. After some sleep, I came back to it and noticed that there was a long list of ""running"" scheduled tasks. Upon further investigation, before going to sleep I had made an incomplete deployment which resulted in a missing docker image from the registry. This lead to the same place where, trigger tries to deploy the image, it fails to, but trigger has no idea. This lead to the long list of running tasks, the longest of which was hanging for ~14 hours.

![image](https://github.com/user-attachments/assets/49fc91fb-bde0-4f37-80c1-4abb441fef29)

<details>
<summary>Screenshot of the runs list</summary>

For reference, when the task is working correctly it takes ~2 seconds from start to finish.

![image](https://github.com/user-attachments/assets/218c4417-4e38-47ec-88f5-adc61389536b)

</details>

",2482943270,"Thanks for digging into this and creating two very thorough issues!

The self-hosting story isn't great at the moment, this being part of the problem. We're going to make some big changes in the next couple of months. One of those changes means providers will go away completely - there will only be a single runtime-agnostic image to run per deployment.

There's currently no easy way to fail a task from the provider. Also, any changes here would also touch parts that affect our cloud deployment.

I think for those reasons, it makes more sense not to touch this at all currently. This will be fixed by the new self-hosted setup.

However, what you could do in the meantime to prevent this and other issues is to set a [max duration](https://trigger.dev/docs/runs/max-duration) on your tasks. This would at least prevent tasks running forever and ""alert"" to investigate any underlying causes, including provider errors. Not ideal, but I think it's the best we can do for now."
2665656296,1477,Runs API failing with 403 when using access token with broad scopes (not run specific),"### Provide environment information

""@trigger.dev/react-hooks"": ""^3.2.0"",
""@trigger.dev/sdk"": ""^3.1.2"",
""@trigger.dev/build"": ""^3.1.2"",

### Describe the bug

Front-end API access returns 403 for access token with broad scopes.

Possibly introduce by https://github.com/triggerdotdev/trigger.dev/pull/1402.

### Reproduction repo

http://sorry.out.of.time.com

### To reproduce

Steps to repro:

Create a token as documented here [](https://trigger.dev/docs/frontend/overview#scopes)
```
const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      runs: true,
    },
  },
});
```

Paste the generate token to the JWT debugger [](https://jwt.io/#debugger-io) and observe that the scopes array in the decoded payload is empty.
When making a request with this token, the response from ""https://api.trigger.dev/api/v3/runs/"" is 403.


Analysis from looking at the code:
In https://github.com/triggerdotdev/trigger.dev/blob/332854bbcbc53703e64e9a5dd71944deabe51f2b/packages/trigger-sdk/src/v3/auth.ts
```
function flattenScopes(permissions: PublicTokenPermissions): string[] {
  const flattenedPermissions: string[] = [];

  for (const [action, properties] of Object.entries(permissions)) {
    if (properties) {
      if (typeof properties === ""boolean"" && properties) {
        flattenedPermissions.push(action);
      } else if (typeof properties === ""object"") {
        for (const [property, value] of Object.entries(properties)) {
          if (Array.isArray(value)) {
            for (const item of value) {
              flattenedPermissions.push(`${action}:${property}:${item}`);
            }
          } else if (typeof value === ""string"") {
            flattenedPermissions.push(`${action}:${property}:${value}`);
          }
        }
      }
    }
  }

  return flattenedPermissions;
}
```

The check 
```
if (typeof properties === ""boolean"" && properties) {
```
seems incorrect. The action is 'read' but 'properties' is not a boolean, it is'{ runs: true }'.


For what it's worth, when forcing TS to accept an object in the shape that ""flattenScopes"" expects
```
return auth.createPublicToken({
scopes: {
     read: true,
} as any)
```
the JWT claims have the expected (?) shape but the API still gives me 403.

### Additional information

_No response_",2481314515,"An ugly workaround to allow reading all runs
```
import { apiClientManager } from '@trigger.dev/core/v3'
import { generateJWT } from '@trigger.dev/core/v3'

export async function getTriggerDevAccessToken() {
  const apiClient = apiClientManager.clientOrThrow()

  const claims = await apiClient.generateJWTClaims()

  return generateJWT({
    secretKey: apiClient.accessToken,
    payload: {
      ...claims,
      scopes: ['read:runs'],
    },
  })
}
```"
2665656296,1477,Runs API failing with 403 when using access token with broad scopes (not run specific),"### Provide environment information

""@trigger.dev/react-hooks"": ""^3.2.0"",
""@trigger.dev/sdk"": ""^3.1.2"",
""@trigger.dev/build"": ""^3.1.2"",

### Describe the bug

Front-end API access returns 403 for access token with broad scopes.

Possibly introduce by https://github.com/triggerdotdev/trigger.dev/pull/1402.

### Reproduction repo

http://sorry.out.of.time.com

### To reproduce

Steps to repro:

Create a token as documented here [](https://trigger.dev/docs/frontend/overview#scopes)
```
const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      runs: true,
    },
  },
});
```

Paste the generate token to the JWT debugger [](https://jwt.io/#debugger-io) and observe that the scopes array in the decoded payload is empty.
When making a request with this token, the response from ""https://api.trigger.dev/api/v3/runs/"" is 403.


Analysis from looking at the code:
In https://github.com/triggerdotdev/trigger.dev/blob/332854bbcbc53703e64e9a5dd71944deabe51f2b/packages/trigger-sdk/src/v3/auth.ts
```
function flattenScopes(permissions: PublicTokenPermissions): string[] {
  const flattenedPermissions: string[] = [];

  for (const [action, properties] of Object.entries(permissions)) {
    if (properties) {
      if (typeof properties === ""boolean"" && properties) {
        flattenedPermissions.push(action);
      } else if (typeof properties === ""object"") {
        for (const [property, value] of Object.entries(properties)) {
          if (Array.isArray(value)) {
            for (const item of value) {
              flattenedPermissions.push(`${action}:${property}:${item}`);
            }
          } else if (typeof value === ""string"") {
            flattenedPermissions.push(`${action}:${property}:${value}`);
          }
        }
      }
    }
  }

  return flattenedPermissions;
}
```

The check 
```
if (typeof properties === ""boolean"" && properties) {
```
seems incorrect. The action is 'read' but 'properties' is not a boolean, it is'{ runs: true }'.


For what it's worth, when forcing TS to accept an object in the shape that ""flattenScopes"" expects
```
return auth.createPublicToken({
scopes: {
     read: true,
} as any)
```
the JWT claims have the expected (?) shape but the API still gives me 403.

### Additional information

_No response_",2481425254,"This has been fixed in #1470, which should be going live this week"
2665656296,1477,Runs API failing with 403 when using access token with broad scopes (not run specific),"### Provide environment information

""@trigger.dev/react-hooks"": ""^3.2.0"",
""@trigger.dev/sdk"": ""^3.1.2"",
""@trigger.dev/build"": ""^3.1.2"",

### Describe the bug

Front-end API access returns 403 for access token with broad scopes.

Possibly introduce by https://github.com/triggerdotdev/trigger.dev/pull/1402.

### Reproduction repo

http://sorry.out.of.time.com

### To reproduce

Steps to repro:

Create a token as documented here [](https://trigger.dev/docs/frontend/overview#scopes)
```
const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      runs: true,
    },
  },
});
```

Paste the generate token to the JWT debugger [](https://jwt.io/#debugger-io) and observe that the scopes array in the decoded payload is empty.
When making a request with this token, the response from ""https://api.trigger.dev/api/v3/runs/"" is 403.


Analysis from looking at the code:
In https://github.com/triggerdotdev/trigger.dev/blob/332854bbcbc53703e64e9a5dd71944deabe51f2b/packages/trigger-sdk/src/v3/auth.ts
```
function flattenScopes(permissions: PublicTokenPermissions): string[] {
  const flattenedPermissions: string[] = [];

  for (const [action, properties] of Object.entries(permissions)) {
    if (properties) {
      if (typeof properties === ""boolean"" && properties) {
        flattenedPermissions.push(action);
      } else if (typeof properties === ""object"") {
        for (const [property, value] of Object.entries(properties)) {
          if (Array.isArray(value)) {
            for (const item of value) {
              flattenedPermissions.push(`${action}:${property}:${item}`);
            }
          } else if (typeof value === ""string"") {
            flattenedPermissions.push(`${action}:${property}:${value}`);
          }
        }
      }
    }
  }

  return flattenedPermissions;
}
```

The check 
```
if (typeof properties === ""boolean"" && properties) {
```
seems incorrect. The action is 'read' but 'properties' is not a boolean, it is'{ runs: true }'.


For what it's worth, when forcing TS to accept an object in the shape that ""flattenScopes"" expects
```
return auth.createPublicToken({
scopes: {
     read: true,
} as any)
```
the JWT claims have the expected (?) shape but the API still gives me 403.

### Additional information

_No response_",2482888998,"Great, thanks a lot!"
2665656296,1477,Runs API failing with 403 when using access token with broad scopes (not run specific),"### Provide environment information

""@trigger.dev/react-hooks"": ""^3.2.0"",
""@trigger.dev/sdk"": ""^3.1.2"",
""@trigger.dev/build"": ""^3.1.2"",

### Describe the bug

Front-end API access returns 403 for access token with broad scopes.

Possibly introduce by https://github.com/triggerdotdev/trigger.dev/pull/1402.

### Reproduction repo

http://sorry.out.of.time.com

### To reproduce

Steps to repro:

Create a token as documented here [](https://trigger.dev/docs/frontend/overview#scopes)
```
const publicToken = await auth.createPublicToken({
  scopes: {
    read: {
      runs: true,
    },
  },
});
```

Paste the generate token to the JWT debugger [](https://jwt.io/#debugger-io) and observe that the scopes array in the decoded payload is empty.
When making a request with this token, the response from ""https://api.trigger.dev/api/v3/runs/"" is 403.


Analysis from looking at the code:
In https://github.com/triggerdotdev/trigger.dev/blob/332854bbcbc53703e64e9a5dd71944deabe51f2b/packages/trigger-sdk/src/v3/auth.ts
```
function flattenScopes(permissions: PublicTokenPermissions): string[] {
  const flattenedPermissions: string[] = [];

  for (const [action, properties] of Object.entries(permissions)) {
    if (properties) {
      if (typeof properties === ""boolean"" && properties) {
        flattenedPermissions.push(action);
      } else if (typeof properties === ""object"") {
        for (const [property, value] of Object.entries(properties)) {
          if (Array.isArray(value)) {
            for (const item of value) {
              flattenedPermissions.push(`${action}:${property}:${item}`);
            }
          } else if (typeof value === ""string"") {
            flattenedPermissions.push(`${action}:${property}:${value}`);
          }
        }
      }
    }
  }

  return flattenedPermissions;
}
```

The check 
```
if (typeof properties === ""boolean"" && properties) {
```
seems incorrect. The action is 'read' but 'properties' is not a boolean, it is'{ runs: true }'.


For what it's worth, when forcing TS to accept an object in the shape that ""flattenScopes"" expects
```
return auth.createPublicToken({
scopes: {
     read: true,
} as any)
```
the JWT claims have the expected (?) shape but the API still gives me 403.

### Additional information

_No response_",2490269276,Fix verified with 3.2.1. Thank you! Closing.
2665164670,1476,"bug: when the image fails to be pulled from the registry, the deployment hangs","### Provide environment information

n/a

### Describe the bug

I have a self-hosted registry for trigger exclusively, and I noticed while debugging the setup that when the image failed to be pulled the task just kept going seemingly unaware. I can't recall if this happened when the image was missing, but it definitely happened if the authentication failed.	

### Reproduction repo

n/a

### To reproduce

Self host a registry, and use it with trigger. I'd try kicking it offline, and if that error does appear in the task logs then try adding auth to the registry but not the docker-provider container. Self hosting the registry was rather simple with docker:

```yaml
  trigger-registry:
    container_name: trigger-registry
    image: registry:2
    restart: always
    volumes:
      - ./rdata:/var/lib/registry
      - ./auth:/auth
 ```

See [the guide on built-in auth](https://distribution.github.io/distribution/about/deploying/#native-basic-auth) if you need.

### Additional information

_No response_",2481423154,"It looks like it's because these errors aren't returned up from the docker provider, they're simply logged and then ignored.

https://github.com/triggerdotdev/trigger.dev/blob/main/apps/docker-provider/src/index.ts#L134-L148"
2665164670,1476,"bug: when the image fails to be pulled from the registry, the deployment hangs","### Provide environment information

n/a

### Describe the bug

I have a self-hosted registry for trigger exclusively, and I noticed while debugging the setup that when the image failed to be pulled the task just kept going seemingly unaware. I can't recall if this happened when the image was missing, but it definitely happened if the authentication failed.	

### Reproduction repo

n/a

### To reproduce

Self host a registry, and use it with trigger. I'd try kicking it offline, and if that error does appear in the task logs then try adding auth to the registry but not the docker-provider container. Self hosting the registry was rather simple with docker:

```yaml
  trigger-registry:
    container_name: trigger-registry
    image: registry:2
    restart: always
    volumes:
      - ./rdata:/var/lib/registry
      - ./auth:/auth
 ```

See [the guide on built-in auth](https://distribution.github.io/distribution/about/deploying/#native-basic-auth) if you need.

### Additional information

_No response_",2481429562,"There only seems to be one example of a provider shell handler providing a more detailed error: https://github.com/triggerdotdev/trigger.dev/blob/main/packages/core/src/v3/apps/provider.ts#L235-L241

I think fixing this will require work from the core team, I'll make a better issue for this"
2655798890,1473,[TRI-3988] Support imports with aliases inside the trigger.config file,"## Problem

If you are using imports in your trigger.config file with aliases you've defined in your tsconfig.json paths, you will get an error like this:

```
X Error: Cannot find module '@services/environment' 
```

You can't use import aliases that you've setup in your tsconfig.json file inside of the trigger.config.ts file. They work in all other files inside the /trigger folder but just not in this file.

They don't work because we use [https://github.com/unjs/c12](https://github.com/unjs/c12) to load the config file and it doesn't automatically read tsconfig aliases.

[https://github.com/unjs/jiti/issues/166](https://github.com/unjs/jiti/issues/166)

## Workaround

If you experience this problem, for now you can change the path to a relative folder path import.

## Potential built-in solution

There is an `alias` option when using jiti and it looks like we might be able to read the relevant tsconfig paths and populate this with them. [https://github.com/unjs/jiti?tab=readme-ov-file#alias](https://github.com/unjs/jiti?tab=readme-ov-file#alias)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-3988](https://linear.app/triggerdotdev/issue/TRI-3988/support-imports-with-aliases-inside-the-triggerconfig-file)</sub>",2484773383,Hey @matt-aitken please assign this issue to me?
2651823801,1468,feat: Ability to change the node version,"### Is your feature request related to a problem? Please describe.

In a data processing pipeline which uses a lot of grouping operations introduced in node v21 the code fails with.
```
TypeError: Map.groupBy(...).entries(...).map is not a function
```
From what I see trigger runs on node v20.

### Describe the solution you'd like to see

Allow users to change the node version in their trigger config. I understand that this will increase the testing and maintenance cost a LOT so it's probably not worth implementing.

### Describe alternate solutions

1. Document how to conditionally polifill unavailable features 
2. Warn if one uses too new features unavailable in the runtime 

### Additional information

_No response_",2470354650,"For now I've added poly-fills directly to trigger.config.ts
```ts
// Add polifills for Node v22
// https://github.com/triggerdotdev/trigger.dev/issues/1468
import 'core-js/actual/iterator';
import 'core-js/actual/object';
import 'core-js/actual/map';
```"
2651814835,1467,"prioritize location of `trigger.config.ts` file to set the ""base"" path instead of package.json","Some monorepo setups don't have a package.json inside the individual workspace (instead they just have 1 at the root of the monorepo), which messes up some path resolution logic during the dev command. We should use the `trigger.config.ts` file path instead of the package.json to determine the ""base"" path when running the dev command to fix this.",,
2651059248,1466,feat: Support custom run command so I can use dotenvx,"### Is your feature request related to a problem? Please describe.

I manage environment vars with [dotenvx](https://dotenvx.com/). The way is works is that you store encrypted env vars in your repo, and you have just one secret key that gets used to unencrypt everything else at runtime. Makes env management across multiple platforms much easier.

The problem is that you unencrypt vars by using a custom run command, ex.:

`dotenvx run -- my_script.ts`

This doesn't work well with trigger.dev. Could you allow me to set custom run commands for my tasks?

### Describe the solution you'd like to see

Allow a custom run command to be specified in the task config, or support doing this with extensions.

### Describe alternate solutions

My temp solutions:
- don't use dotenvx for the vars that I want to use with my trigger.dev tasks
- Wrap my task script so that instead of calling directly, my task does something like `run_bash('dotenvx run -- node my_script.js')`. Haven't tested this yet; it would probably work but I assume it would cause me to lose my telemetry.

### Additional information

_No response_",2494296592,"@warrenbhw I'm not familiar enough with trigger.dev but could you instead load dotenvx in code using the `.config()` method?

```js
// somejob.js
require('@dotenvx/dotenvx').config()
console.log(`Hello ${process.env.HELLO}`)
```"
2651059248,1466,feat: Support custom run command so I can use dotenvx,"### Is your feature request related to a problem? Please describe.

I manage environment vars with [dotenvx](https://dotenvx.com/). The way is works is that you store encrypted env vars in your repo, and you have just one secret key that gets used to unencrypt everything else at runtime. Makes env management across multiple platforms much easier.

The problem is that you unencrypt vars by using a custom run command, ex.:

`dotenvx run -- my_script.ts`

This doesn't work well with trigger.dev. Could you allow me to set custom run commands for my tasks?

### Describe the solution you'd like to see

Allow a custom run command to be specified in the task config, or support doing this with extensions.

### Describe alternate solutions

My temp solutions:
- don't use dotenvx for the vars that I want to use with my trigger.dev tasks
- Wrap my task script so that instead of calling directly, my task does something like `run_bash('dotenvx run -- node my_script.js')`. Haven't tested this yet; it would probably work but I assume it would cause me to lose my telemetry.

### Additional information

_No response_",2495368334,Let me give this a shot! Thanks 
2646926666,1465,bug: Creating Personal Access Tokens on selfhosted site creates undefined error,"### Provide environment information

  System:
    OS: Linux 6.8 Debian GNU/Linux 11 (bullseye) 11 (bullseye)
    CPU: (4) x64 Intel(R) N100
    Memory: 11.64 GB / 15.37 GB
    Container: Yes
    Shell: 5.1.4 - /bin/bash
  Binaries:
    Node: 20.11.1 - /usr/local/bin/node
    npm: 10.2.4 - /usr/local/bin/npm
    pnpm: 8.15.5 - /usr/local/bin/pnpm

### Describe the bug

After creating a Personal Access Tokens and adding the name (any string) I then trigger the following error: 
<img width=""359"" alt=""image"" src=""https://github.com/user-attachments/assets/5a69cb77-6a0e-4c4a-95e9-55b0130365cf"">


### Reproduction repo

not applicable 

### To reproduce

1. I am running this on a coolify project using the following docker compose: 
```
# documentation: https://trigger.dev
# slogan: The open source Background Jobs framework for TypeScript
# tags: trigger.dev, background jobs, typescript, trigger, jobs, cron, scheduler
# logo: svgs/trigger.png
# port: 3000
x-common-env: &common-env
  PORT: 3030
  REMIX_APP_PORT: 3000
  NODE_ENV: production
  RUNTIME_PLATFORM: docker-compose
  V3_ENABLED: true
  INTERNAL_OTEL_TRACE_DISABLED: 1
  INTERNAL_OTEL_TRACE_LOGGING_ENABLED: 0
  POSTGRES_USER: $SERVICE_USER_POSTGRES
  POSTGRES_PASSWORD: $SERVICE_PASSWORD_POSTGRES
  POSTGRES_DB: ${POSTGRES_DB:-trigger}
  MAGIC_LINK_SECRET: $SERVICE_PASSWORD_64_MAGIC
  SESSION_SECRET: $SERVICE_PASSWORD_64_SESSION
  ENCRYPTION_KEY: $SERVICE_PASSWORD_64_ENCRYPTION
  PROVIDER_SECRET: $SERVICE_PASSWORD_64_PROVIDER
  COORDINATOR_SECRET: $SERVICE_PASSWORD_64_COORDINATOR
  DATABASE_HOST: postgresql:5432
  DATABASE_URL: postgres://$SERVICE_USER_POSTGRES:$SERVICE_PASSWORD_POSTGRES@postgresql:5432/$POSTGRES_DB?sslmode=disable
  DIRECT_URL: postgres://$SERVICE_USER_POSTGRES:$SERVICE_PASSWORD_POSTGRES@postgresql:5432/$POSTGRES_DB?sslmode=disable
  REDIS_HOST: redis
  REDIS_PORT: 6379
  REDIS_TLS_DISABLED: true
  COORDINATOR_HOST: 127.0.0.1
  COORDINATOR_PORT: 9020
  WHITELISTED_EMAILS: """"
  ADMIN_EMAILS: """"
  DEFAULT_ORG_EXECUTION_CONCURRENCY_LIMIT: 300
  DEFAULT_ENV_EXECUTION_CONCURRENCY_LIMIT: 100
  DEPLOY_REGISTRY_HOST: docker.io
  DEPLOY_REGISTRY_NAMESPACE: trigger
  REGISTRY_HOST: ${DEPLOY_REGISTRY_HOST}
  REGISTRY_NAMESPACE: ${DEPLOY_REGISTRY_NAMESPACE}
  AUTH_GITHUB_CLIENT_ID: ${AUTH_GITHUB_CLIENT_ID}
  AUTH_GITHUB_CLIENT_SECRET: ${AUTH_GITHUB_CLIENT_SECRET}
  RESEND_API_KEY: ${RESEND_API_KEY}
  FROM_EMAIL: ${FROM_EMAIL}
  REPLY_TO_EMAIL: ${REPLY_TO_EMAIL}
  LOGIN_ORIGIN: $SERVICE_FQDN_TRIGGER_3000
  APP_ORIGIN: $SERVICE_FQDN_TRIGGER_3000
  DEV_OTEL_EXPORTER_OTLP_ENDPOINT: $SERVICE_FQDN_TRIGGER_3000/otel
  OTEL_EXPORTER_OTLP_ENDPOINT: ""http://trigger:3040/otel""
  ELECTRIC_ORIGIN: http://electric:3000
services:
  trigger:
    image: ghcr.io/triggerdotdev/trigger.dev:v3
    environment:
      SERVICE_FQDN_TRIGGER_3000: """"
      <<: *common-env
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
      electric:
        condition: service_healthy
    healthcheck:
      test: ""timeout 10s bash -c ':> /dev/tcp/127.0.0.1/3000' || exit 1""
      interval: 10s
      timeout: 5s
      retries: 5
  electric:
    image: electricsql/electric
    environment:
      <<: *common-env
    depends_on:
      postgresql:
        condition: service_healthy
    healthcheck:
      test:
        - CMD-SHELL
        - pwd
  redis:
    image: ""redis:7""
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    healthcheck:
      test:
        - CMD-SHELL
        - ""redis-cli -h localhost -p 6379 ping""
      interval: 5s
      timeout: 5s
      retries: 3
    volumes:
      - redis-data:/data
  postgresql:
    image: postgres:16-alpine
    volumes:
      - postgresql-data:/var/lib/postgresql/data
    environment:
      <<: *common-env
    command:
      - -c
      - wal_level=logical
    healthcheck:
      test: [""CMD-SHELL"", ""pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}""]
      interval: 5s
      timeout: 20s
      retries: 10
  docker-provider:
    image: ghcr.io/triggerdotdev/provider/docker:v3
    platform: linux/amd64
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    depends_on:
      trigger:
        condition: service_healthy
    environment:
      <<: *common-env
      PLATFORM_HOST: trigger
      PLATFORM_WS_PORT: 3030
      SECURE_CONNECTION: ""false""
      PLATFORM_SECRET: $PROVIDER_SECRET
  coordinator:
    image: ghcr.io/triggerdotdev/coordinator:v3
    platform: linux/amd64
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    depends_on:
      trigger:
        condition: service_healthy
    environment:
      <<: *common-env
      PLATFORM_HOST: trigger
      PLATFORM_WS_PORT: 3030
      SECURE_CONNECTION: ""false""
      PLATFORM_SECRET: $COORDINATOR_SECRET
    healthcheck:
      test:
        - CMD-SHELL
        - pwd
  ```
2. Create a new access token
3. Error will then trigger

### Additional information

Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
tokens:24 
        
        
       GET https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015 net::ERR_BLOCKED_BY_CLIENT
root-JWRAFXBJ.js:9 
        
        
       POST https://trigger.claasen.cc/account/tokens?_data=routes%2Faccount.tokens 400 (Bad Request)
window._fetchProxy @ root-JWRAFXBJ.js:9
window._highlightFetchPatch @ root-JWRAFXBJ.js:9
Fr @ chunk-JBSYHZX3.js:18
await in Fr
da @ chunk-JBSYHZX3.js:24
action @ chunk-JBSYHZX3.js:24
m @ chunk-JBSYHZX3.js:2
ot @ chunk-JBSYHZX3.js:2
wa @ chunk-JBSYHZX3.js:1
Ea @ chunk-JBSYHZX3.js:1
(anonymous) @ chunk-JBSYHZX3.js:2
w.createElement.ce.onSubmit @ chunk-JBSYHZX3.js:2
oc @ chunk-LYHQCUWL.js:5
ac @ chunk-LYHQCUWL.js:5
cc @ chunk-LYHQCUWL.js:5
po @ chunk-LYHQCUWL.js:5
As @ chunk-LYHQCUWL.js:5
(anonymous) @ chunk-LYHQCUWL.js:5
ku @ chunk-LYHQCUWL.js:8
cs @ chunk-LYHQCUWL.js:5
Fl @ chunk-LYHQCUWL.js:5
Xi @ chunk-LYHQCUWL.js:5
Nc @ chunk-LYHQCUWL.js:5
chunk-LYHQCUWL.js:8 TypeError: Cannot read properties of undefined (reading 'split')
    at L (chunk-4QLYPARN.js:1:2114)
    at chunk-GVVQJ7TX.js:1:1694
    at Object.pa [as useMemo] (chunk-LYHQCUWL.js:6:23795)
    at r.useMemo (chunk-FTYKMG53.js:1:6137)
    at oe (chunk-GVVQJ7TX.js:1:1644)
    at re (account.tokens-CBMHX44X.js:1:4940)
    at du (chunk-LYHQCUWL.js:6:19466)
    at _i (chunk-LYHQCUWL.js:8:3133)
    at Ba (chunk-LYHQCUWL.js:8:44432)
    at Ua (chunk-LYHQCUWL.js:8:39459)
overrideMethod @ hook.js:608
xi @ chunk-LYHQCUWL.js:8
i.componentDidCatch.t.callback @ chunk-LYHQCUWL.js:8
Co @ chunk-LYHQCUWL.js:6
Ao @ chunk-LYHQCUWL.js:8
Ra @ chunk-LYHQCUWL.js:8
If @ chunk-LYHQCUWL.js:8
Bf @ chunk-LYHQCUWL.js:8
hn @ chunk-LYHQCUWL.js:8
Fa @ chunk-LYHQCUWL.js:8
Sl @ chunk-LYHQCUWL.js:1
hl @ chunk-LYHQCUWL.js:1
Show 1 more frame
Show less
chunk-JBSYHZX3.js:2 React Router caught the following error during render TypeError: Cannot read properties of undefined (reading 'split')
    at L (chunk-4QLYPARN.js:1:2114)
    at chunk-GVVQJ7TX.js:1:1694
    at Object.pa [as useMemo] (chunk-LYHQCUWL.js:6:23795)
    at r.useMemo (chunk-FTYKMG53.js:1:6137)
    at oe (chunk-GVVQJ7TX.js:1:1644)
    at re (account.tokens-CBMHX44X.js:1:4940)
    at du (chunk-LYHQCUWL.js:6:19466)
    at _i (chunk-LYHQCUWL.js:8:3133)
    at Ba (chunk-LYHQCUWL.js:8:44432)
    at Ua (chunk-LYHQCUWL.js:8:39459) {componentStack: '\n    at re (https://trigger.claasen.cc/build/route…claasen.cc/build/_shared/chunk-DGKAL6G7.js:1:186)'}componentStack: ""\n    at re (https://trigger.claasen.cc/build/routes/account.tokens-CBMHX44X.js:1:4909)\n    at div\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:4583\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3130\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:2725\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-Y6JHH73C.js:1:384\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:3527\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:2339\n    at Ce (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7705)\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:2087\n    at div\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3130\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:2725\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7410\n    at Ce (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7705)\n    at u (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:996)\n    at se (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:1327)\n    at ee (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:4672)\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:5173\n    at u (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:996)\n    at ne (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:601)\n    at div\n    at j (https://trigger.claasen.cc/build/_shared/chunk-WZVPZJ3P.js:1:1895)\n    at div\n    at div\n    at div\n    at G (https://trigger.claasen.cc/build/_shared/chunk-WZVPZJ3P.js:1:1047)\n    at div\n    at fo (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3658)\n    at X (https://trigger.claasen.cc/build/routes/account.tokens-CBMHX44X.js:1:3588)\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at _n (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21220)\n    at div\n    at yt (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3548)\n    at div\n    at div\n    at vo (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3424)\n    at L\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at _n (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21220)\n    at body\n    at html\n    at rs (https://trigger.claasen.cc/build/root-JWRAFXBJ.js:14:109345)\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at dr (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:22722)\n    at Qo (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:30169)\n    at gr (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21257)\n    at Mn (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:28244)\n    at $t (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:14:2378)\n    at Ui (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:24:2690)\n    at x (https://trigger.claasen.cc/build/_shared/chunk-XEZL6SGQ.js:1:185)\n    at y (https://trigger.claasen.cc/build/_shared/chunk-DGKAL6G7.js:1:186)""[[Prototype]]: Object
overrideMethod @ hook.js:608
componentDidCatch @ chunk-JBSYHZX3.js:2
i.componentDidCatch.t.callback @ chunk-LYHQCUWL.js:8
Co @ chunk-LYHQCUWL.js:6
Ao @ chunk-LYHQCUWL.js:8
Ra @ chunk-LYHQCUWL.js:8
If @ chunk-LYHQCUWL.js:8
Bf @ chunk-LYHQCUWL.js:8
hn @ chunk-LYHQCUWL.js:8
Fa @ chunk-LYHQCUWL.js:8
Sl @ chunk-LYHQCUWL.js:1
hl @ chunk-LYHQCUWL.js:1
Show 1 more frame
Show less
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
root-JWRAFXBJ.js:9 
        
        
       POST https://trigger.claasen.cc/account/tokens?_data=routes%2Faccount.tokens 400 (Bad Request)
window._fetchProxy @ root-JWRAFXBJ.js:9
window._highlightFetchPatch @ root-JWRAFXBJ.js:9
Fr @ chunk-JBSYHZX3.js:18
await in Fr
da @ chunk-JBSYHZX3.js:24
action @ chunk-JBSYHZX3.js:24
m @ chunk-JBSYHZX3.js:2
ot @ chunk-JBSYHZX3.js:2
wa @ chunk-JBSYHZX3.js:1
Ea @ chunk-JBSYHZX3.js:1
(anonymous) @ chunk-JBSYHZX3.js:2
w.createElement.ce.onSubmit @ chunk-JBSYHZX3.js:2
oc @ chunk-LYHQCUWL.js:5
ac @ chunk-LYHQCUWL.js:5
cc @ chunk-LYHQCUWL.js:5
po @ chunk-LYHQCUWL.js:5
As @ chunk-LYHQCUWL.js:5
(anonymous) @ chunk-LYHQCUWL.js:5
ku @ chunk-LYHQCUWL.js:8
cs @ chunk-LYHQCUWL.js:5
Fl @ chunk-LYHQCUWL.js:5
Xi @ chunk-LYHQCUWL.js:5
Nc @ chunk-LYHQCUWL.js:5
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
",2466618974,I am happy to share access if required. 
2646926666,1465,bug: Creating Personal Access Tokens on selfhosted site creates undefined error,"### Provide environment information

  System:
    OS: Linux 6.8 Debian GNU/Linux 11 (bullseye) 11 (bullseye)
    CPU: (4) x64 Intel(R) N100
    Memory: 11.64 GB / 15.37 GB
    Container: Yes
    Shell: 5.1.4 - /bin/bash
  Binaries:
    Node: 20.11.1 - /usr/local/bin/node
    npm: 10.2.4 - /usr/local/bin/npm
    pnpm: 8.15.5 - /usr/local/bin/pnpm

### Describe the bug

After creating a Personal Access Tokens and adding the name (any string) I then trigger the following error: 
<img width=""359"" alt=""image"" src=""https://github.com/user-attachments/assets/5a69cb77-6a0e-4c4a-95e9-55b0130365cf"">


### Reproduction repo

not applicable 

### To reproduce

1. I am running this on a coolify project using the following docker compose: 
```
# documentation: https://trigger.dev
# slogan: The open source Background Jobs framework for TypeScript
# tags: trigger.dev, background jobs, typescript, trigger, jobs, cron, scheduler
# logo: svgs/trigger.png
# port: 3000
x-common-env: &common-env
  PORT: 3030
  REMIX_APP_PORT: 3000
  NODE_ENV: production
  RUNTIME_PLATFORM: docker-compose
  V3_ENABLED: true
  INTERNAL_OTEL_TRACE_DISABLED: 1
  INTERNAL_OTEL_TRACE_LOGGING_ENABLED: 0
  POSTGRES_USER: $SERVICE_USER_POSTGRES
  POSTGRES_PASSWORD: $SERVICE_PASSWORD_POSTGRES
  POSTGRES_DB: ${POSTGRES_DB:-trigger}
  MAGIC_LINK_SECRET: $SERVICE_PASSWORD_64_MAGIC
  SESSION_SECRET: $SERVICE_PASSWORD_64_SESSION
  ENCRYPTION_KEY: $SERVICE_PASSWORD_64_ENCRYPTION
  PROVIDER_SECRET: $SERVICE_PASSWORD_64_PROVIDER
  COORDINATOR_SECRET: $SERVICE_PASSWORD_64_COORDINATOR
  DATABASE_HOST: postgresql:5432
  DATABASE_URL: postgres://$SERVICE_USER_POSTGRES:$SERVICE_PASSWORD_POSTGRES@postgresql:5432/$POSTGRES_DB?sslmode=disable
  DIRECT_URL: postgres://$SERVICE_USER_POSTGRES:$SERVICE_PASSWORD_POSTGRES@postgresql:5432/$POSTGRES_DB?sslmode=disable
  REDIS_HOST: redis
  REDIS_PORT: 6379
  REDIS_TLS_DISABLED: true
  COORDINATOR_HOST: 127.0.0.1
  COORDINATOR_PORT: 9020
  WHITELISTED_EMAILS: """"
  ADMIN_EMAILS: """"
  DEFAULT_ORG_EXECUTION_CONCURRENCY_LIMIT: 300
  DEFAULT_ENV_EXECUTION_CONCURRENCY_LIMIT: 100
  DEPLOY_REGISTRY_HOST: docker.io
  DEPLOY_REGISTRY_NAMESPACE: trigger
  REGISTRY_HOST: ${DEPLOY_REGISTRY_HOST}
  REGISTRY_NAMESPACE: ${DEPLOY_REGISTRY_NAMESPACE}
  AUTH_GITHUB_CLIENT_ID: ${AUTH_GITHUB_CLIENT_ID}
  AUTH_GITHUB_CLIENT_SECRET: ${AUTH_GITHUB_CLIENT_SECRET}
  RESEND_API_KEY: ${RESEND_API_KEY}
  FROM_EMAIL: ${FROM_EMAIL}
  REPLY_TO_EMAIL: ${REPLY_TO_EMAIL}
  LOGIN_ORIGIN: $SERVICE_FQDN_TRIGGER_3000
  APP_ORIGIN: $SERVICE_FQDN_TRIGGER_3000
  DEV_OTEL_EXPORTER_OTLP_ENDPOINT: $SERVICE_FQDN_TRIGGER_3000/otel
  OTEL_EXPORTER_OTLP_ENDPOINT: ""http://trigger:3040/otel""
  ELECTRIC_ORIGIN: http://electric:3000
services:
  trigger:
    image: ghcr.io/triggerdotdev/trigger.dev:v3
    environment:
      SERVICE_FQDN_TRIGGER_3000: """"
      <<: *common-env
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
      electric:
        condition: service_healthy
    healthcheck:
      test: ""timeout 10s bash -c ':> /dev/tcp/127.0.0.1/3000' || exit 1""
      interval: 10s
      timeout: 5s
      retries: 5
  electric:
    image: electricsql/electric
    environment:
      <<: *common-env
    depends_on:
      postgresql:
        condition: service_healthy
    healthcheck:
      test:
        - CMD-SHELL
        - pwd
  redis:
    image: ""redis:7""
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    healthcheck:
      test:
        - CMD-SHELL
        - ""redis-cli -h localhost -p 6379 ping""
      interval: 5s
      timeout: 5s
      retries: 3
    volumes:
      - redis-data:/data
  postgresql:
    image: postgres:16-alpine
    volumes:
      - postgresql-data:/var/lib/postgresql/data
    environment:
      <<: *common-env
    command:
      - -c
      - wal_level=logical
    healthcheck:
      test: [""CMD-SHELL"", ""pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}""]
      interval: 5s
      timeout: 20s
      retries: 10
  docker-provider:
    image: ghcr.io/triggerdotdev/provider/docker:v3
    platform: linux/amd64
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    depends_on:
      trigger:
        condition: service_healthy
    environment:
      <<: *common-env
      PLATFORM_HOST: trigger
      PLATFORM_WS_PORT: 3030
      SECURE_CONNECTION: ""false""
      PLATFORM_SECRET: $PROVIDER_SECRET
  coordinator:
    image: ghcr.io/triggerdotdev/coordinator:v3
    platform: linux/amd64
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    depends_on:
      trigger:
        condition: service_healthy
    environment:
      <<: *common-env
      PLATFORM_HOST: trigger
      PLATFORM_WS_PORT: 3030
      SECURE_CONNECTION: ""false""
      PLATFORM_SECRET: $COORDINATOR_SECRET
    healthcheck:
      test:
        - CMD-SHELL
        - pwd
  ```
2. Create a new access token
3. Error will then trigger

### Additional information

Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
tokens:24 
        
        
       GET https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015 net::ERR_BLOCKED_BY_CLIENT
root-JWRAFXBJ.js:9 
        
        
       POST https://trigger.claasen.cc/account/tokens?_data=routes%2Faccount.tokens 400 (Bad Request)
window._fetchProxy @ root-JWRAFXBJ.js:9
window._highlightFetchPatch @ root-JWRAFXBJ.js:9
Fr @ chunk-JBSYHZX3.js:18
await in Fr
da @ chunk-JBSYHZX3.js:24
action @ chunk-JBSYHZX3.js:24
m @ chunk-JBSYHZX3.js:2
ot @ chunk-JBSYHZX3.js:2
wa @ chunk-JBSYHZX3.js:1
Ea @ chunk-JBSYHZX3.js:1
(anonymous) @ chunk-JBSYHZX3.js:2
w.createElement.ce.onSubmit @ chunk-JBSYHZX3.js:2
oc @ chunk-LYHQCUWL.js:5
ac @ chunk-LYHQCUWL.js:5
cc @ chunk-LYHQCUWL.js:5
po @ chunk-LYHQCUWL.js:5
As @ chunk-LYHQCUWL.js:5
(anonymous) @ chunk-LYHQCUWL.js:5
ku @ chunk-LYHQCUWL.js:8
cs @ chunk-LYHQCUWL.js:5
Fl @ chunk-LYHQCUWL.js:5
Xi @ chunk-LYHQCUWL.js:5
Nc @ chunk-LYHQCUWL.js:5
chunk-LYHQCUWL.js:8 TypeError: Cannot read properties of undefined (reading 'split')
    at L (chunk-4QLYPARN.js:1:2114)
    at chunk-GVVQJ7TX.js:1:1694
    at Object.pa [as useMemo] (chunk-LYHQCUWL.js:6:23795)
    at r.useMemo (chunk-FTYKMG53.js:1:6137)
    at oe (chunk-GVVQJ7TX.js:1:1644)
    at re (account.tokens-CBMHX44X.js:1:4940)
    at du (chunk-LYHQCUWL.js:6:19466)
    at _i (chunk-LYHQCUWL.js:8:3133)
    at Ba (chunk-LYHQCUWL.js:8:44432)
    at Ua (chunk-LYHQCUWL.js:8:39459)
overrideMethod @ hook.js:608
xi @ chunk-LYHQCUWL.js:8
i.componentDidCatch.t.callback @ chunk-LYHQCUWL.js:8
Co @ chunk-LYHQCUWL.js:6
Ao @ chunk-LYHQCUWL.js:8
Ra @ chunk-LYHQCUWL.js:8
If @ chunk-LYHQCUWL.js:8
Bf @ chunk-LYHQCUWL.js:8
hn @ chunk-LYHQCUWL.js:8
Fa @ chunk-LYHQCUWL.js:8
Sl @ chunk-LYHQCUWL.js:1
hl @ chunk-LYHQCUWL.js:1
Show 1 more frame
Show less
chunk-JBSYHZX3.js:2 React Router caught the following error during render TypeError: Cannot read properties of undefined (reading 'split')
    at L (chunk-4QLYPARN.js:1:2114)
    at chunk-GVVQJ7TX.js:1:1694
    at Object.pa [as useMemo] (chunk-LYHQCUWL.js:6:23795)
    at r.useMemo (chunk-FTYKMG53.js:1:6137)
    at oe (chunk-GVVQJ7TX.js:1:1644)
    at re (account.tokens-CBMHX44X.js:1:4940)
    at du (chunk-LYHQCUWL.js:6:19466)
    at _i (chunk-LYHQCUWL.js:8:3133)
    at Ba (chunk-LYHQCUWL.js:8:44432)
    at Ua (chunk-LYHQCUWL.js:8:39459) {componentStack: '\n    at re (https://trigger.claasen.cc/build/route…claasen.cc/build/_shared/chunk-DGKAL6G7.js:1:186)'}componentStack: ""\n    at re (https://trigger.claasen.cc/build/routes/account.tokens-CBMHX44X.js:1:4909)\n    at div\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:4583\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3130\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:2725\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-Y6JHH73C.js:1:384\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:3527\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:2339\n    at Ce (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7705)\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:2087\n    at div\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3130\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:2725\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7410\n    at Ce (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7705)\n    at u (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:996)\n    at se (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:1327)\n    at ee (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:4672)\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:5173\n    at u (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:996)\n    at ne (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:601)\n    at div\n    at j (https://trigger.claasen.cc/build/_shared/chunk-WZVPZJ3P.js:1:1895)\n    at div\n    at div\n    at div\n    at G (https://trigger.claasen.cc/build/_shared/chunk-WZVPZJ3P.js:1:1047)\n    at div\n    at fo (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3658)\n    at X (https://trigger.claasen.cc/build/routes/account.tokens-CBMHX44X.js:1:3588)\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at _n (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21220)\n    at div\n    at yt (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3548)\n    at div\n    at div\n    at vo (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3424)\n    at L\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at _n (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21220)\n    at body\n    at html\n    at rs (https://trigger.claasen.cc/build/root-JWRAFXBJ.js:14:109345)\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at dr (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:22722)\n    at Qo (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:30169)\n    at gr (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21257)\n    at Mn (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:28244)\n    at $t (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:14:2378)\n    at Ui (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:24:2690)\n    at x (https://trigger.claasen.cc/build/_shared/chunk-XEZL6SGQ.js:1:185)\n    at y (https://trigger.claasen.cc/build/_shared/chunk-DGKAL6G7.js:1:186)""[[Prototype]]: Object
overrideMethod @ hook.js:608
componentDidCatch @ chunk-JBSYHZX3.js:2
i.componentDidCatch.t.callback @ chunk-LYHQCUWL.js:8
Co @ chunk-LYHQCUWL.js:6
Ao @ chunk-LYHQCUWL.js:8
Ra @ chunk-LYHQCUWL.js:8
If @ chunk-LYHQCUWL.js:8
Bf @ chunk-LYHQCUWL.js:8
hn @ chunk-LYHQCUWL.js:8
Fa @ chunk-LYHQCUWL.js:8
Sl @ chunk-LYHQCUWL.js:1
hl @ chunk-LYHQCUWL.js:1
Show 1 more frame
Show less
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
root-JWRAFXBJ.js:9 
        
        
       POST https://trigger.claasen.cc/account/tokens?_data=routes%2Faccount.tokens 400 (Bad Request)
window._fetchProxy @ root-JWRAFXBJ.js:9
window._highlightFetchPatch @ root-JWRAFXBJ.js:9
Fr @ chunk-JBSYHZX3.js:18
await in Fr
da @ chunk-JBSYHZX3.js:24
action @ chunk-JBSYHZX3.js:24
m @ chunk-JBSYHZX3.js:2
ot @ chunk-JBSYHZX3.js:2
wa @ chunk-JBSYHZX3.js:1
Ea @ chunk-JBSYHZX3.js:1
(anonymous) @ chunk-JBSYHZX3.js:2
w.createElement.ce.onSubmit @ chunk-JBSYHZX3.js:2
oc @ chunk-LYHQCUWL.js:5
ac @ chunk-LYHQCUWL.js:5
cc @ chunk-LYHQCUWL.js:5
po @ chunk-LYHQCUWL.js:5
As @ chunk-LYHQCUWL.js:5
(anonymous) @ chunk-LYHQCUWL.js:5
ku @ chunk-LYHQCUWL.js:8
cs @ chunk-LYHQCUWL.js:5
Fl @ chunk-LYHQCUWL.js:5
Xi @ chunk-LYHQCUWL.js:5
Nc @ chunk-LYHQCUWL.js:5
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
",2466662852,Seems to also have an issue when trying to create a token via the CLI. I am guessing it's related. 
2646926666,1465,bug: Creating Personal Access Tokens on selfhosted site creates undefined error,"### Provide environment information

  System:
    OS: Linux 6.8 Debian GNU/Linux 11 (bullseye) 11 (bullseye)
    CPU: (4) x64 Intel(R) N100
    Memory: 11.64 GB / 15.37 GB
    Container: Yes
    Shell: 5.1.4 - /bin/bash
  Binaries:
    Node: 20.11.1 - /usr/local/bin/node
    npm: 10.2.4 - /usr/local/bin/npm
    pnpm: 8.15.5 - /usr/local/bin/pnpm

### Describe the bug

After creating a Personal Access Tokens and adding the name (any string) I then trigger the following error: 
<img width=""359"" alt=""image"" src=""https://github.com/user-attachments/assets/5a69cb77-6a0e-4c4a-95e9-55b0130365cf"">


### Reproduction repo

not applicable 

### To reproduce

1. I am running this on a coolify project using the following docker compose: 
```
# documentation: https://trigger.dev
# slogan: The open source Background Jobs framework for TypeScript
# tags: trigger.dev, background jobs, typescript, trigger, jobs, cron, scheduler
# logo: svgs/trigger.png
# port: 3000
x-common-env: &common-env
  PORT: 3030
  REMIX_APP_PORT: 3000
  NODE_ENV: production
  RUNTIME_PLATFORM: docker-compose
  V3_ENABLED: true
  INTERNAL_OTEL_TRACE_DISABLED: 1
  INTERNAL_OTEL_TRACE_LOGGING_ENABLED: 0
  POSTGRES_USER: $SERVICE_USER_POSTGRES
  POSTGRES_PASSWORD: $SERVICE_PASSWORD_POSTGRES
  POSTGRES_DB: ${POSTGRES_DB:-trigger}
  MAGIC_LINK_SECRET: $SERVICE_PASSWORD_64_MAGIC
  SESSION_SECRET: $SERVICE_PASSWORD_64_SESSION
  ENCRYPTION_KEY: $SERVICE_PASSWORD_64_ENCRYPTION
  PROVIDER_SECRET: $SERVICE_PASSWORD_64_PROVIDER
  COORDINATOR_SECRET: $SERVICE_PASSWORD_64_COORDINATOR
  DATABASE_HOST: postgresql:5432
  DATABASE_URL: postgres://$SERVICE_USER_POSTGRES:$SERVICE_PASSWORD_POSTGRES@postgresql:5432/$POSTGRES_DB?sslmode=disable
  DIRECT_URL: postgres://$SERVICE_USER_POSTGRES:$SERVICE_PASSWORD_POSTGRES@postgresql:5432/$POSTGRES_DB?sslmode=disable
  REDIS_HOST: redis
  REDIS_PORT: 6379
  REDIS_TLS_DISABLED: true
  COORDINATOR_HOST: 127.0.0.1
  COORDINATOR_PORT: 9020
  WHITELISTED_EMAILS: """"
  ADMIN_EMAILS: """"
  DEFAULT_ORG_EXECUTION_CONCURRENCY_LIMIT: 300
  DEFAULT_ENV_EXECUTION_CONCURRENCY_LIMIT: 100
  DEPLOY_REGISTRY_HOST: docker.io
  DEPLOY_REGISTRY_NAMESPACE: trigger
  REGISTRY_HOST: ${DEPLOY_REGISTRY_HOST}
  REGISTRY_NAMESPACE: ${DEPLOY_REGISTRY_NAMESPACE}
  AUTH_GITHUB_CLIENT_ID: ${AUTH_GITHUB_CLIENT_ID}
  AUTH_GITHUB_CLIENT_SECRET: ${AUTH_GITHUB_CLIENT_SECRET}
  RESEND_API_KEY: ${RESEND_API_KEY}
  FROM_EMAIL: ${FROM_EMAIL}
  REPLY_TO_EMAIL: ${REPLY_TO_EMAIL}
  LOGIN_ORIGIN: $SERVICE_FQDN_TRIGGER_3000
  APP_ORIGIN: $SERVICE_FQDN_TRIGGER_3000
  DEV_OTEL_EXPORTER_OTLP_ENDPOINT: $SERVICE_FQDN_TRIGGER_3000/otel
  OTEL_EXPORTER_OTLP_ENDPOINT: ""http://trigger:3040/otel""
  ELECTRIC_ORIGIN: http://electric:3000
services:
  trigger:
    image: ghcr.io/triggerdotdev/trigger.dev:v3
    environment:
      SERVICE_FQDN_TRIGGER_3000: """"
      <<: *common-env
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
      electric:
        condition: service_healthy
    healthcheck:
      test: ""timeout 10s bash -c ':> /dev/tcp/127.0.0.1/3000' || exit 1""
      interval: 10s
      timeout: 5s
      retries: 5
  electric:
    image: electricsql/electric
    environment:
      <<: *common-env
    depends_on:
      postgresql:
        condition: service_healthy
    healthcheck:
      test:
        - CMD-SHELL
        - pwd
  redis:
    image: ""redis:7""
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    healthcheck:
      test:
        - CMD-SHELL
        - ""redis-cli -h localhost -p 6379 ping""
      interval: 5s
      timeout: 5s
      retries: 3
    volumes:
      - redis-data:/data
  postgresql:
    image: postgres:16-alpine
    volumes:
      - postgresql-data:/var/lib/postgresql/data
    environment:
      <<: *common-env
    command:
      - -c
      - wal_level=logical
    healthcheck:
      test: [""CMD-SHELL"", ""pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}""]
      interval: 5s
      timeout: 20s
      retries: 10
  docker-provider:
    image: ghcr.io/triggerdotdev/provider/docker:v3
    platform: linux/amd64
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    depends_on:
      trigger:
        condition: service_healthy
    environment:
      <<: *common-env
      PLATFORM_HOST: trigger
      PLATFORM_WS_PORT: 3030
      SECURE_CONNECTION: ""false""
      PLATFORM_SECRET: $PROVIDER_SECRET
  coordinator:
    image: ghcr.io/triggerdotdev/coordinator:v3
    platform: linux/amd64
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    depends_on:
      trigger:
        condition: service_healthy
    environment:
      <<: *common-env
      PLATFORM_HOST: trigger
      PLATFORM_WS_PORT: 3030
      SECURE_CONNECTION: ""false""
      PLATFORM_SECRET: $COORDINATOR_SECRET
    healthcheck:
      test:
        - CMD-SHELL
        - pwd
  ```
2. Create a new access token
3. Error will then trigger

### Additional information

Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
tokens:24 
        
        
       GET https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015 net::ERR_BLOCKED_BY_CLIENT
root-JWRAFXBJ.js:9 
        
        
       POST https://trigger.claasen.cc/account/tokens?_data=routes%2Faccount.tokens 400 (Bad Request)
window._fetchProxy @ root-JWRAFXBJ.js:9
window._highlightFetchPatch @ root-JWRAFXBJ.js:9
Fr @ chunk-JBSYHZX3.js:18
await in Fr
da @ chunk-JBSYHZX3.js:24
action @ chunk-JBSYHZX3.js:24
m @ chunk-JBSYHZX3.js:2
ot @ chunk-JBSYHZX3.js:2
wa @ chunk-JBSYHZX3.js:1
Ea @ chunk-JBSYHZX3.js:1
(anonymous) @ chunk-JBSYHZX3.js:2
w.createElement.ce.onSubmit @ chunk-JBSYHZX3.js:2
oc @ chunk-LYHQCUWL.js:5
ac @ chunk-LYHQCUWL.js:5
cc @ chunk-LYHQCUWL.js:5
po @ chunk-LYHQCUWL.js:5
As @ chunk-LYHQCUWL.js:5
(anonymous) @ chunk-LYHQCUWL.js:5
ku @ chunk-LYHQCUWL.js:8
cs @ chunk-LYHQCUWL.js:5
Fl @ chunk-LYHQCUWL.js:5
Xi @ chunk-LYHQCUWL.js:5
Nc @ chunk-LYHQCUWL.js:5
chunk-LYHQCUWL.js:8 TypeError: Cannot read properties of undefined (reading 'split')
    at L (chunk-4QLYPARN.js:1:2114)
    at chunk-GVVQJ7TX.js:1:1694
    at Object.pa [as useMemo] (chunk-LYHQCUWL.js:6:23795)
    at r.useMemo (chunk-FTYKMG53.js:1:6137)
    at oe (chunk-GVVQJ7TX.js:1:1644)
    at re (account.tokens-CBMHX44X.js:1:4940)
    at du (chunk-LYHQCUWL.js:6:19466)
    at _i (chunk-LYHQCUWL.js:8:3133)
    at Ba (chunk-LYHQCUWL.js:8:44432)
    at Ua (chunk-LYHQCUWL.js:8:39459)
overrideMethod @ hook.js:608
xi @ chunk-LYHQCUWL.js:8
i.componentDidCatch.t.callback @ chunk-LYHQCUWL.js:8
Co @ chunk-LYHQCUWL.js:6
Ao @ chunk-LYHQCUWL.js:8
Ra @ chunk-LYHQCUWL.js:8
If @ chunk-LYHQCUWL.js:8
Bf @ chunk-LYHQCUWL.js:8
hn @ chunk-LYHQCUWL.js:8
Fa @ chunk-LYHQCUWL.js:8
Sl @ chunk-LYHQCUWL.js:1
hl @ chunk-LYHQCUWL.js:1
Show 1 more frame
Show less
chunk-JBSYHZX3.js:2 React Router caught the following error during render TypeError: Cannot read properties of undefined (reading 'split')
    at L (chunk-4QLYPARN.js:1:2114)
    at chunk-GVVQJ7TX.js:1:1694
    at Object.pa [as useMemo] (chunk-LYHQCUWL.js:6:23795)
    at r.useMemo (chunk-FTYKMG53.js:1:6137)
    at oe (chunk-GVVQJ7TX.js:1:1644)
    at re (account.tokens-CBMHX44X.js:1:4940)
    at du (chunk-LYHQCUWL.js:6:19466)
    at _i (chunk-LYHQCUWL.js:8:3133)
    at Ba (chunk-LYHQCUWL.js:8:44432)
    at Ua (chunk-LYHQCUWL.js:8:39459) {componentStack: '\n    at re (https://trigger.claasen.cc/build/route…claasen.cc/build/_shared/chunk-DGKAL6G7.js:1:186)'}componentStack: ""\n    at re (https://trigger.claasen.cc/build/routes/account.tokens-CBMHX44X.js:1:4909)\n    at div\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:4583\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3130\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:2725\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-Y6JHH73C.js:1:384\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:3527\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:2339\n    at Ce (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7705)\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:2087\n    at div\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3130\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:2725\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7410\n    at Ce (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7705)\n    at u (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:996)\n    at se (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:1327)\n    at ee (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:4672)\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:5173\n    at u (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:996)\n    at ne (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:601)\n    at div\n    at j (https://trigger.claasen.cc/build/_shared/chunk-WZVPZJ3P.js:1:1895)\n    at div\n    at div\n    at div\n    at G (https://trigger.claasen.cc/build/_shared/chunk-WZVPZJ3P.js:1:1047)\n    at div\n    at fo (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3658)\n    at X (https://trigger.claasen.cc/build/routes/account.tokens-CBMHX44X.js:1:3588)\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at _n (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21220)\n    at div\n    at yt (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3548)\n    at div\n    at div\n    at vo (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3424)\n    at L\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at _n (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21220)\n    at body\n    at html\n    at rs (https://trigger.claasen.cc/build/root-JWRAFXBJ.js:14:109345)\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at dr (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:22722)\n    at Qo (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:30169)\n    at gr (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21257)\n    at Mn (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:28244)\n    at $t (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:14:2378)\n    at Ui (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:24:2690)\n    at x (https://trigger.claasen.cc/build/_shared/chunk-XEZL6SGQ.js:1:185)\n    at y (https://trigger.claasen.cc/build/_shared/chunk-DGKAL6G7.js:1:186)""[[Prototype]]: Object
overrideMethod @ hook.js:608
componentDidCatch @ chunk-JBSYHZX3.js:2
i.componentDidCatch.t.callback @ chunk-LYHQCUWL.js:8
Co @ chunk-LYHQCUWL.js:6
Ao @ chunk-LYHQCUWL.js:8
Ra @ chunk-LYHQCUWL.js:8
If @ chunk-LYHQCUWL.js:8
Bf @ chunk-LYHQCUWL.js:8
hn @ chunk-LYHQCUWL.js:8
Fa @ chunk-LYHQCUWL.js:8
Sl @ chunk-LYHQCUWL.js:1
hl @ chunk-LYHQCUWL.js:1
Show 1 more frame
Show less
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
root-JWRAFXBJ.js:9 
        
        
       POST https://trigger.claasen.cc/account/tokens?_data=routes%2Faccount.tokens 400 (Bad Request)
window._fetchProxy @ root-JWRAFXBJ.js:9
window._highlightFetchPatch @ root-JWRAFXBJ.js:9
Fr @ chunk-JBSYHZX3.js:18
await in Fr
da @ chunk-JBSYHZX3.js:24
action @ chunk-JBSYHZX3.js:24
m @ chunk-JBSYHZX3.js:2
ot @ chunk-JBSYHZX3.js:2
wa @ chunk-JBSYHZX3.js:1
Ea @ chunk-JBSYHZX3.js:1
(anonymous) @ chunk-JBSYHZX3.js:2
w.createElement.ce.onSubmit @ chunk-JBSYHZX3.js:2
oc @ chunk-LYHQCUWL.js:5
ac @ chunk-LYHQCUWL.js:5
cc @ chunk-LYHQCUWL.js:5
po @ chunk-LYHQCUWL.js:5
As @ chunk-LYHQCUWL.js:5
(anonymous) @ chunk-LYHQCUWL.js:5
ku @ chunk-LYHQCUWL.js:8
cs @ chunk-LYHQCUWL.js:5
Fl @ chunk-LYHQCUWL.js:5
Xi @ chunk-LYHQCUWL.js:5
Nc @ chunk-LYHQCUWL.js:5
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
",2496823578,"Hi there! I've analyzed your issue with Personal Access Token creation, and I think I can help resolve this.

The error you're experiencing appears to be related to known token handling issues that have been fixed in recent versions. Based on the error patterns and similar reported issues, here's what we need to do:

1. First, let's verify and upgrade your Trigger.dev version:
   - The token-related issues have been fixed in versions 3.1.1 and 3.2.1
   - Update your docker-compose configuration to use the latest v3 image:
   ```yaml
   image: ghcr.io/triggerdotdev/trigger.dev:latest-v3
   ```

2. Check your environment configuration:
   Make sure these environment variables are properly set:
   - SESSION_SECRET
   - ENCRYPTION_KEY
   - MAGIC_LINK_SECRET
   These are critical for token generation and authentication.

3. After upgrading, clean up your existing state:
   ```bash
   docker-compose down
   docker volume prune  # Be careful with this if you have other important volumes
   docker-compose up -d
   ```

4. When creating new tokens, ensure you're using the correct scope format:
   ```typescript
   const publicToken = await auth.createPublicToken({
     scopes: {
       read: {
         runs: true
       }
     }
   });
   ```

If you're still experiencing issues after implementing these changes, please provide:
- Your current Trigger.dev version
- The specific CLI error message
- Any error messages in the server logs

References:
- Issue #1477: Token permission fixes in v3.2.1
- Issue #1443: Token access improvements in v3.1.1

Important Notes:
- Backup your data before performing any upgrades
- Existing tokens may need to be regenerated after the upgrade
- Monitor the logs during the upgrade process for any migration errors

Let me know if you need any clarification or run into any issues during the upgrade process!"
2646926666,1465,bug: Creating Personal Access Tokens on selfhosted site creates undefined error,"### Provide environment information

  System:
    OS: Linux 6.8 Debian GNU/Linux 11 (bullseye) 11 (bullseye)
    CPU: (4) x64 Intel(R) N100
    Memory: 11.64 GB / 15.37 GB
    Container: Yes
    Shell: 5.1.4 - /bin/bash
  Binaries:
    Node: 20.11.1 - /usr/local/bin/node
    npm: 10.2.4 - /usr/local/bin/npm
    pnpm: 8.15.5 - /usr/local/bin/pnpm

### Describe the bug

After creating a Personal Access Tokens and adding the name (any string) I then trigger the following error: 
<img width=""359"" alt=""image"" src=""https://github.com/user-attachments/assets/5a69cb77-6a0e-4c4a-95e9-55b0130365cf"">


### Reproduction repo

not applicable 

### To reproduce

1. I am running this on a coolify project using the following docker compose: 
```
# documentation: https://trigger.dev
# slogan: The open source Background Jobs framework for TypeScript
# tags: trigger.dev, background jobs, typescript, trigger, jobs, cron, scheduler
# logo: svgs/trigger.png
# port: 3000
x-common-env: &common-env
  PORT: 3030
  REMIX_APP_PORT: 3000
  NODE_ENV: production
  RUNTIME_PLATFORM: docker-compose
  V3_ENABLED: true
  INTERNAL_OTEL_TRACE_DISABLED: 1
  INTERNAL_OTEL_TRACE_LOGGING_ENABLED: 0
  POSTGRES_USER: $SERVICE_USER_POSTGRES
  POSTGRES_PASSWORD: $SERVICE_PASSWORD_POSTGRES
  POSTGRES_DB: ${POSTGRES_DB:-trigger}
  MAGIC_LINK_SECRET: $SERVICE_PASSWORD_64_MAGIC
  SESSION_SECRET: $SERVICE_PASSWORD_64_SESSION
  ENCRYPTION_KEY: $SERVICE_PASSWORD_64_ENCRYPTION
  PROVIDER_SECRET: $SERVICE_PASSWORD_64_PROVIDER
  COORDINATOR_SECRET: $SERVICE_PASSWORD_64_COORDINATOR
  DATABASE_HOST: postgresql:5432
  DATABASE_URL: postgres://$SERVICE_USER_POSTGRES:$SERVICE_PASSWORD_POSTGRES@postgresql:5432/$POSTGRES_DB?sslmode=disable
  DIRECT_URL: postgres://$SERVICE_USER_POSTGRES:$SERVICE_PASSWORD_POSTGRES@postgresql:5432/$POSTGRES_DB?sslmode=disable
  REDIS_HOST: redis
  REDIS_PORT: 6379
  REDIS_TLS_DISABLED: true
  COORDINATOR_HOST: 127.0.0.1
  COORDINATOR_PORT: 9020
  WHITELISTED_EMAILS: """"
  ADMIN_EMAILS: """"
  DEFAULT_ORG_EXECUTION_CONCURRENCY_LIMIT: 300
  DEFAULT_ENV_EXECUTION_CONCURRENCY_LIMIT: 100
  DEPLOY_REGISTRY_HOST: docker.io
  DEPLOY_REGISTRY_NAMESPACE: trigger
  REGISTRY_HOST: ${DEPLOY_REGISTRY_HOST}
  REGISTRY_NAMESPACE: ${DEPLOY_REGISTRY_NAMESPACE}
  AUTH_GITHUB_CLIENT_ID: ${AUTH_GITHUB_CLIENT_ID}
  AUTH_GITHUB_CLIENT_SECRET: ${AUTH_GITHUB_CLIENT_SECRET}
  RESEND_API_KEY: ${RESEND_API_KEY}
  FROM_EMAIL: ${FROM_EMAIL}
  REPLY_TO_EMAIL: ${REPLY_TO_EMAIL}
  LOGIN_ORIGIN: $SERVICE_FQDN_TRIGGER_3000
  APP_ORIGIN: $SERVICE_FQDN_TRIGGER_3000
  DEV_OTEL_EXPORTER_OTLP_ENDPOINT: $SERVICE_FQDN_TRIGGER_3000/otel
  OTEL_EXPORTER_OTLP_ENDPOINT: ""http://trigger:3040/otel""
  ELECTRIC_ORIGIN: http://electric:3000
services:
  trigger:
    image: ghcr.io/triggerdotdev/trigger.dev:v3
    environment:
      SERVICE_FQDN_TRIGGER_3000: """"
      <<: *common-env
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
      electric:
        condition: service_healthy
    healthcheck:
      test: ""timeout 10s bash -c ':> /dev/tcp/127.0.0.1/3000' || exit 1""
      interval: 10s
      timeout: 5s
      retries: 5
  electric:
    image: electricsql/electric
    environment:
      <<: *common-env
    depends_on:
      postgresql:
        condition: service_healthy
    healthcheck:
      test:
        - CMD-SHELL
        - pwd
  redis:
    image: ""redis:7""
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    healthcheck:
      test:
        - CMD-SHELL
        - ""redis-cli -h localhost -p 6379 ping""
      interval: 5s
      timeout: 5s
      retries: 3
    volumes:
      - redis-data:/data
  postgresql:
    image: postgres:16-alpine
    volumes:
      - postgresql-data:/var/lib/postgresql/data
    environment:
      <<: *common-env
    command:
      - -c
      - wal_level=logical
    healthcheck:
      test: [""CMD-SHELL"", ""pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}""]
      interval: 5s
      timeout: 20s
      retries: 10
  docker-provider:
    image: ghcr.io/triggerdotdev/provider/docker:v3
    platform: linux/amd64
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    depends_on:
      trigger:
        condition: service_healthy
    environment:
      <<: *common-env
      PLATFORM_HOST: trigger
      PLATFORM_WS_PORT: 3030
      SECURE_CONNECTION: ""false""
      PLATFORM_SECRET: $PROVIDER_SECRET
  coordinator:
    image: ghcr.io/triggerdotdev/coordinator:v3
    platform: linux/amd64
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    user: root
    depends_on:
      trigger:
        condition: service_healthy
    environment:
      <<: *common-env
      PLATFORM_HOST: trigger
      PLATFORM_WS_PORT: 3030
      SECURE_CONNECTION: ""false""
      PLATFORM_SECRET: $COORDINATOR_SECRET
    healthcheck:
      test:
        - CMD-SHELL
        - pwd
  ```
2. Create a new access token
3. Error will then trigger

### Additional information

Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
tokens:24 
        
        
       GET https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015 net::ERR_BLOCKED_BY_CLIENT
root-JWRAFXBJ.js:9 
        
        
       POST https://trigger.claasen.cc/account/tokens?_data=routes%2Faccount.tokens 400 (Bad Request)
window._fetchProxy @ root-JWRAFXBJ.js:9
window._highlightFetchPatch @ root-JWRAFXBJ.js:9
Fr @ chunk-JBSYHZX3.js:18
await in Fr
da @ chunk-JBSYHZX3.js:24
action @ chunk-JBSYHZX3.js:24
m @ chunk-JBSYHZX3.js:2
ot @ chunk-JBSYHZX3.js:2
wa @ chunk-JBSYHZX3.js:1
Ea @ chunk-JBSYHZX3.js:1
(anonymous) @ chunk-JBSYHZX3.js:2
w.createElement.ce.onSubmit @ chunk-JBSYHZX3.js:2
oc @ chunk-LYHQCUWL.js:5
ac @ chunk-LYHQCUWL.js:5
cc @ chunk-LYHQCUWL.js:5
po @ chunk-LYHQCUWL.js:5
As @ chunk-LYHQCUWL.js:5
(anonymous) @ chunk-LYHQCUWL.js:5
ku @ chunk-LYHQCUWL.js:8
cs @ chunk-LYHQCUWL.js:5
Fl @ chunk-LYHQCUWL.js:5
Xi @ chunk-LYHQCUWL.js:5
Nc @ chunk-LYHQCUWL.js:5
chunk-LYHQCUWL.js:8 TypeError: Cannot read properties of undefined (reading 'split')
    at L (chunk-4QLYPARN.js:1:2114)
    at chunk-GVVQJ7TX.js:1:1694
    at Object.pa [as useMemo] (chunk-LYHQCUWL.js:6:23795)
    at r.useMemo (chunk-FTYKMG53.js:1:6137)
    at oe (chunk-GVVQJ7TX.js:1:1644)
    at re (account.tokens-CBMHX44X.js:1:4940)
    at du (chunk-LYHQCUWL.js:6:19466)
    at _i (chunk-LYHQCUWL.js:8:3133)
    at Ba (chunk-LYHQCUWL.js:8:44432)
    at Ua (chunk-LYHQCUWL.js:8:39459)
overrideMethod @ hook.js:608
xi @ chunk-LYHQCUWL.js:8
i.componentDidCatch.t.callback @ chunk-LYHQCUWL.js:8
Co @ chunk-LYHQCUWL.js:6
Ao @ chunk-LYHQCUWL.js:8
Ra @ chunk-LYHQCUWL.js:8
If @ chunk-LYHQCUWL.js:8
Bf @ chunk-LYHQCUWL.js:8
hn @ chunk-LYHQCUWL.js:8
Fa @ chunk-LYHQCUWL.js:8
Sl @ chunk-LYHQCUWL.js:1
hl @ chunk-LYHQCUWL.js:1
Show 1 more frame
Show less
chunk-JBSYHZX3.js:2 React Router caught the following error during render TypeError: Cannot read properties of undefined (reading 'split')
    at L (chunk-4QLYPARN.js:1:2114)
    at chunk-GVVQJ7TX.js:1:1694
    at Object.pa [as useMemo] (chunk-LYHQCUWL.js:6:23795)
    at r.useMemo (chunk-FTYKMG53.js:1:6137)
    at oe (chunk-GVVQJ7TX.js:1:1644)
    at re (account.tokens-CBMHX44X.js:1:4940)
    at du (chunk-LYHQCUWL.js:6:19466)
    at _i (chunk-LYHQCUWL.js:8:3133)
    at Ba (chunk-LYHQCUWL.js:8:44432)
    at Ua (chunk-LYHQCUWL.js:8:39459) {componentStack: '\n    at re (https://trigger.claasen.cc/build/route…claasen.cc/build/_shared/chunk-DGKAL6G7.js:1:186)'}componentStack: ""\n    at re (https://trigger.claasen.cc/build/routes/account.tokens-CBMHX44X.js:1:4909)\n    at div\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:4583\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3130\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:2725\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-Y6JHH73C.js:1:384\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:3527\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:2339\n    at Ce (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7705)\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:2087\n    at div\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3130\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:2725\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:3847\n    at https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7410\n    at Ce (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:7705)\n    at u (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:996)\n    at se (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:1327)\n    at ee (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:4672)\n    at https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:5173\n    at u (https://trigger.claasen.cc/build/_shared/chunk-HLDNCM5C.js:1:996)\n    at ne (https://trigger.claasen.cc/build/_shared/chunk-XJK4FH5I.js:1:601)\n    at div\n    at j (https://trigger.claasen.cc/build/_shared/chunk-WZVPZJ3P.js:1:1895)\n    at div\n    at div\n    at div\n    at G (https://trigger.claasen.cc/build/_shared/chunk-WZVPZJ3P.js:1:1047)\n    at div\n    at fo (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3658)\n    at X (https://trigger.claasen.cc/build/routes/account.tokens-CBMHX44X.js:1:3588)\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at _n (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21220)\n    at div\n    at yt (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3548)\n    at div\n    at div\n    at vo (https://trigger.claasen.cc/build/_shared/chunk-ALXCXKJV.js:1:3424)\n    at L\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at _n (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21220)\n    at body\n    at html\n    at rs (https://trigger.claasen.cc/build/root-JWRAFXBJ.js:14:109345)\n    at So (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:18639)\n    at dr (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:22722)\n    at Qo (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:30169)\n    at gr (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:21257)\n    at Mn (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:2:28244)\n    at $t (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:14:2378)\n    at Ui (https://trigger.claasen.cc/build/_shared/chunk-JBSYHZX3.js:24:2690)\n    at x (https://trigger.claasen.cc/build/_shared/chunk-XEZL6SGQ.js:1:185)\n    at y (https://trigger.claasen.cc/build/_shared/chunk-DGKAL6G7.js:1:186)""[[Prototype]]: Object
overrideMethod @ hook.js:608
componentDidCatch @ chunk-JBSYHZX3.js:2
i.componentDidCatch.t.callback @ chunk-LYHQCUWL.js:8
Co @ chunk-LYHQCUWL.js:6
Ao @ chunk-LYHQCUWL.js:8
Ra @ chunk-LYHQCUWL.js:8
If @ chunk-LYHQCUWL.js:8
Bf @ chunk-LYHQCUWL.js:8
hn @ chunk-LYHQCUWL.js:8
Fa @ chunk-LYHQCUWL.js:8
Sl @ chunk-LYHQCUWL.js:1
hl @ chunk-LYHQCUWL.js:1
Show 1 more frame
Show less
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
root-JWRAFXBJ.js:9 
        
        
       POST https://trigger.claasen.cc/account/tokens?_data=routes%2Faccount.tokens 400 (Bad Request)
window._fetchProxy @ root-JWRAFXBJ.js:9
window._highlightFetchPatch @ root-JWRAFXBJ.js:9
Fr @ chunk-JBSYHZX3.js:18
await in Fr
da @ chunk-JBSYHZX3.js:24
action @ chunk-JBSYHZX3.js:24
m @ chunk-JBSYHZX3.js:2
ot @ chunk-JBSYHZX3.js:2
wa @ chunk-JBSYHZX3.js:1
Ea @ chunk-JBSYHZX3.js:1
(anonymous) @ chunk-JBSYHZX3.js:2
w.createElement.ce.onSubmit @ chunk-JBSYHZX3.js:2
oc @ chunk-LYHQCUWL.js:5
ac @ chunk-LYHQCUWL.js:5
cc @ chunk-LYHQCUWL.js:5
po @ chunk-LYHQCUWL.js:5
As @ chunk-LYHQCUWL.js:5
(anonymous) @ chunk-LYHQCUWL.js:5
ku @ chunk-LYHQCUWL.js:8
cs @ chunk-LYHQCUWL.js:5
Fl @ chunk-LYHQCUWL.js:5
Xi @ chunk-LYHQCUWL.js:5
Nc @ chunk-LYHQCUWL.js:5
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-redemption'.
Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'private-state-token-issuance'.
Error with Permissions-Policy header: Unrecognized feature: 'browsing-topics'.
",2496833298,Thank you'll have a go at it.
2629782794,1454,Missing export tasks from `@trigger.dev/sdk/v3`,"This is happening because of our new [browser](https://github.com/triggerdotdev/trigger.dev/blob/58def055d0181e6aeaea5ea7b489e147acfa1fd6/packages/trigger-sdk/package.json#L86) export condition that doesn't export some things that aren't compatible with browsers, but apparently this is effecting edge runtimes (I'm guessing that bundle with the ""browser"" custom condition but have not confirmed this.

We should export more from the browser export, especially the `tasks` export, but currently it's not so simple because it will pull in stuff that isn't compatible (opentelemetry).",2452516273,A list of runtime keys: https://runtime-keys.proposal.wintercg.org/#workerd
2629782794,1454,Missing export tasks from `@trigger.dev/sdk/v3`,"This is happening because of our new [browser](https://github.com/triggerdotdev/trigger.dev/blob/58def055d0181e6aeaea5ea7b489e147acfa1fd6/packages/trigger-sdk/package.json#L86) export condition that doesn't export some things that aren't compatible with browsers, but apparently this is effecting edge runtimes (I'm guessing that bundle with the ""browser"" custom condition but have not confirmed this.

We should export more from the browser export, especially the `tasks` export, but currently it's not so simple because it will pull in stuff that isn't compatible (opentelemetry).",2452520946,"Yup, looks like Cloudflare workers will bundle with the ""browser"" condition:

https://github.com/cloudflare/workers-sdk/blob/3ee1353d317c0e137a14f3091b32eecd575cc7a4/packages/wrangler/src/deployment-bundle/bundle.ts#L56

If we added a ""workerd"" or ""worker"" condition that exports the same as the ""default"" export then this would probably fix the issue for CF workers. I'm guessing we could do a similar thing for Vercel Edge functions"
2628203191,1446,Issue on docs: useRealtime Batch does not exist.,"Path: /frontend/react-hooks 

I kept getting the following error when trying to import the function:

```The requested module '@trigger.dev/react-hooks' does not provide an export named 'useRealtimeBatch```. It's because the actual hook function in the library is defined as `useBatch` and not `useRealtimeBatch`.",2452628445,This has been fixed in 3.1.1
2626883047,1443,Auto-generated public token returned from `batchTrigger` doesn't have read access to individual runs,"We should add specific permissions to read each run, instead of just the batch. For now you can workaround this by creating another token that has access to each run in the batch:

```ts
import { auth, tasks } from ""@trigger.dev/sdk/v3"";

const handle = await tasks.batchTrigger(""my-task"", [ /* stuff here */]);

const publicToken = await auth.createPublicToken({
  scopes: { read: { runs: handle.runs.map((r) => r.id) } }
})
```

",2452628682,This has been fixed in 3.1.1
2624859521,1440,bug: SDK typings broken on v3.1.0,"### Provide environment information

  System:
    OS: macOS 15.0.1
    CPU: (10) arm64 Apple M1 Max
    Memory: 415.19 MB / 64.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 22.0.0 - ~/.nvm/versions/node/v22.0.0/bin/node
    Yarn: 4.5.0 - ~/.nvm/versions/node/v22.0.0/bin/yarn
    npm: 10.5.1 - ~/.nvm/versions/node/v22.0.0/bin/npm
    bun: 1.1.29 - ~/.bun/bin/bun

### Describe the bug

Typings are broken on the 3.1.0 SDK release. Working on 3.0.13.

<img width=""762"" alt=""Screenshot 2024-10-30 at 12 42 07 PM"" src=""https://github.com/user-attachments/assets/9f72b947-0714-4944-8365-b014f3ab7330"">


### Reproduction repo

...

### To reproduce

Install 3.1.0. In case it matters, I've got `""type"": ""module"",` in my `package.json` file.

### Additional information

_No response_",2447932179,What's your tsconfig.json?
2624859521,1440,bug: SDK typings broken on v3.1.0,"### Provide environment information

  System:
    OS: macOS 15.0.1
    CPU: (10) arm64 Apple M1 Max
    Memory: 415.19 MB / 64.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 22.0.0 - ~/.nvm/versions/node/v22.0.0/bin/node
    Yarn: 4.5.0 - ~/.nvm/versions/node/v22.0.0/bin/yarn
    npm: 10.5.1 - ~/.nvm/versions/node/v22.0.0/bin/npm
    bun: 1.1.29 - ~/.bun/bin/bun

### Describe the bug

Typings are broken on the 3.1.0 SDK release. Working on 3.0.13.

<img width=""762"" alt=""Screenshot 2024-10-30 at 12 42 07 PM"" src=""https://github.com/user-attachments/assets/9f72b947-0714-4944-8365-b014f3ab7330"">


### Reproduction repo

...

### To reproduce

Install 3.1.0. In case it matters, I've got `""type"": ""module"",` in my `package.json` file.

### Additional information

_No response_",2448685936,"🤦‍♂️  we've got `""customConditions"": [""workerd"", ""worker"", ""browser""]` in there because historically we've mostly working in cloudflare environments. That was the issue - feel free to close. Thanks!"
2624859521,1440,bug: SDK typings broken on v3.1.0,"### Provide environment information

  System:
    OS: macOS 15.0.1
    CPU: (10) arm64 Apple M1 Max
    Memory: 415.19 MB / 64.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 22.0.0 - ~/.nvm/versions/node/v22.0.0/bin/node
    Yarn: 4.5.0 - ~/.nvm/versions/node/v22.0.0/bin/yarn
    npm: 10.5.1 - ~/.nvm/versions/node/v22.0.0/bin/npm
    bun: 1.1.29 - ~/.bun/bin/bun

### Describe the bug

Typings are broken on the 3.1.0 SDK release. Working on 3.0.13.

<img width=""762"" alt=""Screenshot 2024-10-30 at 12 42 07 PM"" src=""https://github.com/user-attachments/assets/9f72b947-0714-4944-8365-b014f3ab7330"">


### Reproduction repo

...

### To reproduce

Install 3.1.0. In case it matters, I've got `""type"": ""module"",` in my `package.json` file.

### Additional information

_No response_",2452628859,This has been fixed in 3.1.1
2602560351,1422,"bug: TaskIndexingImportError: Could not load the ""sharp"" module using the linux-x64 runtime","### Provide environment information

  System:
    OS: Linux 6.6 Debian GNU/Linux 12 (bookworm) 12 (bookworm)
    CPU: (8) x64 unknown
    Memory: 5.85 GB / 7.66 GB
    Container: Yes
    Shell: 5.2.15 - /bin/bash
  Binaries:
    Node: 20.17.0 - /usr/local/bin/node
    Yarn: 1.22.22 - /usr/local/bin/yarn
    npm: 10.8.2 - /usr/local/bin/npm

### Describe the bug

Can't get the `sharp` module to work no matter what I do.

```
│         x Could not load the ""sharp"" module using the linux-x64 runtime
│         Possible solutions:
│         - Ensure optional dependencies can be installed:
│             npm install --include=optional sharp
│         - Ensure your package manager supports multi-platform installation:
│             See https://sharp.pixelplumbing.com/install#cross-platform
│         - Add platform-specific dependencies:
│             npm install --os=linux --cpu=x64 sharp
│         - Consult the installation documentation:
│             See https://sharp.pixelplumbing.com/install in src/blog/process_img.ts
```

It is possible that this is somewhat a red herring, as just adding the sharp module by itself to package.json (but not using it) did deploy correctly, however, with the full file it doesn't work.

I've tried all of the install suggestions, I've tried running from within docker (using `node:20`) in addition to my host (macos, m3). Spent over a day fighting with this.

### Reproduction repo

https://github.com/logimix-v/bug-trigger.dev-sharp

### To reproduce

Check out the above repo and run
```
npm i
cd pkgs/trigger
npx trigger.dev@3.0.13 deploy
```
(may need to change project ref)

### Additional information

I've also gotten TLS errors with `--log-level debug`, I'm not sure if they're related. I've tried lots of combinations of states, so this may be due to something else I changed trying to get this to work.

```
◓  Deploying version 20241021.17#1 [depot] launching amd64 machine
| 
◐  Deploying version 20241021.17#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| 
| #2 [depot] launching amd64 machine
| 
◑  Deploying version 20241021.17#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| ------
|  > [depot] launching amd64 machine:
| ------
| ------
|  > [depot] launching amd64 machine:
| ------
| 
◒  Deploying version 20241021.17.2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Build result {
|   ok: false,
|   error: 'Error building image',
|   logs: '#1 [depot] launching amd64 machine\n' +
|     '#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '#2 [depot] launching amd64 machine\n' +
|     '#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     'Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority'
| }
◇  Failed to deploy project
```

The trigger.dev project seems really cool and I'd love to use it! Appreciate any assistance with this.",2429066769,"I was able to make some progress here by promoting all of the dependencies used by my trigger.dev library to top-level workspace dependencies (which didn't seem to be enough) and then also list `sharp` in `additionalPackages: [""sharp""]`, as follows:
```ts
import { defineConfig } from ""@trigger.dev/sdk/v3"";

export default defineConfig({
  project: ""..."",
  runtime: ""node"",
  logLevel: ""log"",
  // Set the maxDuration to 300 seconds for all tasks. See https://trigger.dev/docs/runs/max-duration
  // maxDuration: 300, 
  retries: {
    enabledInDev: false,
    default: {
      maxAttempts: 3,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
      randomize: true,
    },
  },
  dirs: [""pkgs""],
  // HOLY ... LIFESAVER
  additionalPackages: [""sharp""]
});
```

I do get deprecation warnings but they just say to use the same field so I'm not sure if it is really an issue.

I still can't tell what the actual issue was or if this is the correct solution. It kind of seems like trigger doesn't work when run as a subpackage in a monorepo, but the docs seem to suggest that is an intended use case."
2602560351,1422,"bug: TaskIndexingImportError: Could not load the ""sharp"" module using the linux-x64 runtime","### Provide environment information

  System:
    OS: Linux 6.6 Debian GNU/Linux 12 (bookworm) 12 (bookworm)
    CPU: (8) x64 unknown
    Memory: 5.85 GB / 7.66 GB
    Container: Yes
    Shell: 5.2.15 - /bin/bash
  Binaries:
    Node: 20.17.0 - /usr/local/bin/node
    Yarn: 1.22.22 - /usr/local/bin/yarn
    npm: 10.8.2 - /usr/local/bin/npm

### Describe the bug

Can't get the `sharp` module to work no matter what I do.

```
│         x Could not load the ""sharp"" module using the linux-x64 runtime
│         Possible solutions:
│         - Ensure optional dependencies can be installed:
│             npm install --include=optional sharp
│         - Ensure your package manager supports multi-platform installation:
│             See https://sharp.pixelplumbing.com/install#cross-platform
│         - Add platform-specific dependencies:
│             npm install --os=linux --cpu=x64 sharp
│         - Consult the installation documentation:
│             See https://sharp.pixelplumbing.com/install in src/blog/process_img.ts
```

It is possible that this is somewhat a red herring, as just adding the sharp module by itself to package.json (but not using it) did deploy correctly, however, with the full file it doesn't work.

I've tried all of the install suggestions, I've tried running from within docker (using `node:20`) in addition to my host (macos, m3). Spent over a day fighting with this.

### Reproduction repo

https://github.com/logimix-v/bug-trigger.dev-sharp

### To reproduce

Check out the above repo and run
```
npm i
cd pkgs/trigger
npx trigger.dev@3.0.13 deploy
```
(may need to change project ref)

### Additional information

I've also gotten TLS errors with `--log-level debug`, I'm not sure if they're related. I've tried lots of combinations of states, so this may be due to something else I changed trying to get this to work.

```
◓  Deploying version 20241021.17#1 [depot] launching amd64 machine
| 
◐  Deploying version 20241021.17#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| 
| #2 [depot] launching amd64 machine
| 
◑  Deploying version 20241021.17#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| ------
|  > [depot] launching amd64 machine:
| ------
| ------
|  > [depot] launching amd64 machine:
| ------
| 
◒  Deploying version 20241021.17.2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Build result {
|   ok: false,
|   error: 'Error building image',
|   logs: '#1 [depot] launching amd64 machine\n' +
|     '#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '#2 [depot] launching amd64 machine\n' +
|     '#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     'Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority'
| }
◇  Failed to deploy project
```

The trigger.dev project seems really cool and I'd love to use it! Appreciate any assistance with this.",2434323719,"I get the exact same problem, thanks for the solution!

@logimix-v  I think this is what the err means, moving the setting to extensions:

```
  build: {
    extensions: [
      additionalPackages({ packages: [""sharp""] })
    ]
  },
```"
2602560351,1422,"bug: TaskIndexingImportError: Could not load the ""sharp"" module using the linux-x64 runtime","### Provide environment information

  System:
    OS: Linux 6.6 Debian GNU/Linux 12 (bookworm) 12 (bookworm)
    CPU: (8) x64 unknown
    Memory: 5.85 GB / 7.66 GB
    Container: Yes
    Shell: 5.2.15 - /bin/bash
  Binaries:
    Node: 20.17.0 - /usr/local/bin/node
    Yarn: 1.22.22 - /usr/local/bin/yarn
    npm: 10.8.2 - /usr/local/bin/npm

### Describe the bug

Can't get the `sharp` module to work no matter what I do.

```
│         x Could not load the ""sharp"" module using the linux-x64 runtime
│         Possible solutions:
│         - Ensure optional dependencies can be installed:
│             npm install --include=optional sharp
│         - Ensure your package manager supports multi-platform installation:
│             See https://sharp.pixelplumbing.com/install#cross-platform
│         - Add platform-specific dependencies:
│             npm install --os=linux --cpu=x64 sharp
│         - Consult the installation documentation:
│             See https://sharp.pixelplumbing.com/install in src/blog/process_img.ts
```

It is possible that this is somewhat a red herring, as just adding the sharp module by itself to package.json (but not using it) did deploy correctly, however, with the full file it doesn't work.

I've tried all of the install suggestions, I've tried running from within docker (using `node:20`) in addition to my host (macos, m3). Spent over a day fighting with this.

### Reproduction repo

https://github.com/logimix-v/bug-trigger.dev-sharp

### To reproduce

Check out the above repo and run
```
npm i
cd pkgs/trigger
npx trigger.dev@3.0.13 deploy
```
(may need to change project ref)

### Additional information

I've also gotten TLS errors with `--log-level debug`, I'm not sure if they're related. I've tried lots of combinations of states, so this may be due to something else I changed trying to get this to work.

```
◓  Deploying version 20241021.17#1 [depot] launching amd64 machine
| 
◐  Deploying version 20241021.17#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| 
| #2 [depot] launching amd64 machine
| 
◑  Deploying version 20241021.17#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| ------
|  > [depot] launching amd64 machine:
| ------
| ------
|  > [depot] launching amd64 machine:
| ------
| 
◒  Deploying version 20241021.17.2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Build result {
|   ok: false,
|   error: 'Error building image',
|   logs: '#1 [depot] launching amd64 machine\n' +
|     '#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '#2 [depot] launching amd64 machine\n' +
|     '#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     'Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority'
| }
◇  Failed to deploy project
```

The trigger.dev project seems really cool and I'd love to use it! Appreciate any assistance with this.",2437120997,"According to the document [here](https://trigger.dev/docs/config/config-file#external:~:text=Any%20packages%20that%20install%20or%20build%20a%20native%20binary%20should%20be%20added%20to%20external%2C%20as%20native%20binaries%20cannot%20be%20bundled.%20For%20example%2C%20re2%2C%20sharp%2C%20and%20sqlite3%20should%20be%20added%20to%20external.), the `sharp` package should be added as `external`."
2602560351,1422,"bug: TaskIndexingImportError: Could not load the ""sharp"" module using the linux-x64 runtime","### Provide environment information

  System:
    OS: Linux 6.6 Debian GNU/Linux 12 (bookworm) 12 (bookworm)
    CPU: (8) x64 unknown
    Memory: 5.85 GB / 7.66 GB
    Container: Yes
    Shell: 5.2.15 - /bin/bash
  Binaries:
    Node: 20.17.0 - /usr/local/bin/node
    Yarn: 1.22.22 - /usr/local/bin/yarn
    npm: 10.8.2 - /usr/local/bin/npm

### Describe the bug

Can't get the `sharp` module to work no matter what I do.

```
│         x Could not load the ""sharp"" module using the linux-x64 runtime
│         Possible solutions:
│         - Ensure optional dependencies can be installed:
│             npm install --include=optional sharp
│         - Ensure your package manager supports multi-platform installation:
│             See https://sharp.pixelplumbing.com/install#cross-platform
│         - Add platform-specific dependencies:
│             npm install --os=linux --cpu=x64 sharp
│         - Consult the installation documentation:
│             See https://sharp.pixelplumbing.com/install in src/blog/process_img.ts
```

It is possible that this is somewhat a red herring, as just adding the sharp module by itself to package.json (but not using it) did deploy correctly, however, with the full file it doesn't work.

I've tried all of the install suggestions, I've tried running from within docker (using `node:20`) in addition to my host (macos, m3). Spent over a day fighting with this.

### Reproduction repo

https://github.com/logimix-v/bug-trigger.dev-sharp

### To reproduce

Check out the above repo and run
```
npm i
cd pkgs/trigger
npx trigger.dev@3.0.13 deploy
```
(may need to change project ref)

### Additional information

I've also gotten TLS errors with `--log-level debug`, I'm not sure if they're related. I've tried lots of combinations of states, so this may be due to something else I changed trying to get this to work.

```
◓  Deploying version 20241021.17#1 [depot] launching amd64 machine
| 
◐  Deploying version 20241021.17#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| 
| #2 [depot] launching amd64 machine
| 
◑  Deploying version 20241021.17#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| ------
|  > [depot] launching amd64 machine:
| ------
| ------
|  > [depot] launching amd64 machine:
| ------
| 
◒  Deploying version 20241021.17.2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Build result {
|   ok: false,
|   error: 'Error building image',
|   logs: '#1 [depot] launching amd64 machine\n' +
|     '#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '#2 [depot] launching amd64 machine\n' +
|     '#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     'Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority'
| }
◇  Failed to deploy project
```

The trigger.dev project seems really cool and I'd love to use it! Appreciate any assistance with this.",2437273228,"We also have a Sharp example that recommends [marking it as external](https://trigger.dev/docs/guides/examples/sharp-image-processing#adding-the-build-configuration). This is required so the `sharp` package can install the (correct) binary. There are a few tricky packages like this which can't be bundled. Marking them as external is generally the solution.

@logimix-v Are you still getting the TLS cert deploy issue?"
2602560351,1422,"bug: TaskIndexingImportError: Could not load the ""sharp"" module using the linux-x64 runtime","### Provide environment information

  System:
    OS: Linux 6.6 Debian GNU/Linux 12 (bookworm) 12 (bookworm)
    CPU: (8) x64 unknown
    Memory: 5.85 GB / 7.66 GB
    Container: Yes
    Shell: 5.2.15 - /bin/bash
  Binaries:
    Node: 20.17.0 - /usr/local/bin/node
    Yarn: 1.22.22 - /usr/local/bin/yarn
    npm: 10.8.2 - /usr/local/bin/npm

### Describe the bug

Can't get the `sharp` module to work no matter what I do.

```
│         x Could not load the ""sharp"" module using the linux-x64 runtime
│         Possible solutions:
│         - Ensure optional dependencies can be installed:
│             npm install --include=optional sharp
│         - Ensure your package manager supports multi-platform installation:
│             See https://sharp.pixelplumbing.com/install#cross-platform
│         - Add platform-specific dependencies:
│             npm install --os=linux --cpu=x64 sharp
│         - Consult the installation documentation:
│             See https://sharp.pixelplumbing.com/install in src/blog/process_img.ts
```

It is possible that this is somewhat a red herring, as just adding the sharp module by itself to package.json (but not using it) did deploy correctly, however, with the full file it doesn't work.

I've tried all of the install suggestions, I've tried running from within docker (using `node:20`) in addition to my host (macos, m3). Spent over a day fighting with this.

### Reproduction repo

https://github.com/logimix-v/bug-trigger.dev-sharp

### To reproduce

Check out the above repo and run
```
npm i
cd pkgs/trigger
npx trigger.dev@3.0.13 deploy
```
(may need to change project ref)

### Additional information

I've also gotten TLS errors with `--log-level debug`, I'm not sure if they're related. I've tried lots of combinations of states, so this may be due to something else I changed trying to get this to work.

```
◓  Deploying version 20241021.17#1 [depot] launching amd64 machine
| 
◐  Deploying version 20241021.17#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| 
| #2 [depot] launching amd64 machine
| 
◑  Deploying version 20241021.17#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| ------
|  > [depot] launching amd64 machine:
| ------
| ------
|  > [depot] launching amd64 machine:
| ------
| 
◒  Deploying version 20241021.17.2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Build result {
|   ok: false,
|   error: 'Error building image',
|   logs: '#1 [depot] launching amd64 machine\n' +
|     '#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '#2 [depot] launching amd64 machine\n' +
|     '#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     'Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority'
| }
◇  Failed to deploy project
```

The trigger.dev project seems really cool and I'd love to use it! Appreciate any assistance with this.",2439586830,"@yingzhox Ah, thanks! That makes sense.

@JohnCido Thanks for the link, I swear I read through all of the docs but missed the help tip.

@nicktrn Haven't touched this since I got it working a few days ago, so can't comment. The TLS cert issue was harder to reproduce in the first place, but I got it a handful of times when I was first trying. Let's say I haven't seen it anymore, and I'll make a new ticket for it if I run into it again. Thanks for following up.

Noted. So the conclusion is that marking it `external` is preferable over using `additionalPackages`? Can you comment on the difference between these two things? Also it seems like `external` uses `package.json` and not `package-lock.json` - is my understanding correct? What is the best way to get reproducible builds?"
2602560351,1422,"bug: TaskIndexingImportError: Could not load the ""sharp"" module using the linux-x64 runtime","### Provide environment information

  System:
    OS: Linux 6.6 Debian GNU/Linux 12 (bookworm) 12 (bookworm)
    CPU: (8) x64 unknown
    Memory: 5.85 GB / 7.66 GB
    Container: Yes
    Shell: 5.2.15 - /bin/bash
  Binaries:
    Node: 20.17.0 - /usr/local/bin/node
    Yarn: 1.22.22 - /usr/local/bin/yarn
    npm: 10.8.2 - /usr/local/bin/npm

### Describe the bug

Can't get the `sharp` module to work no matter what I do.

```
│         x Could not load the ""sharp"" module using the linux-x64 runtime
│         Possible solutions:
│         - Ensure optional dependencies can be installed:
│             npm install --include=optional sharp
│         - Ensure your package manager supports multi-platform installation:
│             See https://sharp.pixelplumbing.com/install#cross-platform
│         - Add platform-specific dependencies:
│             npm install --os=linux --cpu=x64 sharp
│         - Consult the installation documentation:
│             See https://sharp.pixelplumbing.com/install in src/blog/process_img.ts
```

It is possible that this is somewhat a red herring, as just adding the sharp module by itself to package.json (but not using it) did deploy correctly, however, with the full file it doesn't work.

I've tried all of the install suggestions, I've tried running from within docker (using `node:20`) in addition to my host (macos, m3). Spent over a day fighting with this.

### Reproduction repo

https://github.com/logimix-v/bug-trigger.dev-sharp

### To reproduce

Check out the above repo and run
```
npm i
cd pkgs/trigger
npx trigger.dev@3.0.13 deploy
```
(may need to change project ref)

### Additional information

I've also gotten TLS errors with `--log-level debug`, I'm not sure if they're related. I've tried lots of combinations of states, so this may be due to something else I changed trying to get this to work.

```
◓  Deploying version 20241021.17#1 [depot] launching amd64 machine
| 
◐  Deploying version 20241021.17#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| 
| #2 [depot] launching amd64 machine
| 
◑  Deploying version 20241021.17#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| ------
|  > [depot] launching amd64 machine:
| ------
| ------
|  > [depot] launching amd64 machine:
| ------
| 
◒  Deploying version 20241021.17.2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority
| 
| Build result {
|   ok: false,
|   error: 'Error building image',
|   logs: '#1 [depot] launching amd64 machine\n' +
|     '#1 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '#2 [depot] launching amd64 machine\n' +
|     '#2 ERROR: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '------\n' +
|     '> [depot] launching amd64 machine:\n' +
|     '------\n' +
|     '2024/10/21 12:29:04 error releasing builder: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority\n' +
|     'Error: unavailable: tls: failed to verify certificate: x509: certificate signed by unknown authority'
| }
◇  Failed to deploy project
```

The trigger.dev project seems really cool and I'd love to use it! Appreciate any assistance with this.",2440001539,"Hey @logimix-v - I'll quote from our docs to answer this and provide a summary of the differences.

`additionalPackages`:
> This allows you to _include additional packages in the build that are not automatically included via imports_. This is useful if you want to install a package that includes a CLI tool that you want to invoke in your tasks via `exec`. We will try to automatically resolve the version of the package but **you can specify the version by using the `@` symbol**

`external`:
> When a package is _excluded from the bundle_, it will be added to a dynamically generated package.json file in the build directory. The version of the package **will be the same as the version found in your `node_modules` directory**.


In summary:
- `additionalPackages` is best used for external tools that you don't import but may use in scripts, e.g. wrangler. Due to this, you can also specify the version to use, unless you're happy with `latest`.
- `external` will only affect packages used via imports - we will exclude them from the bundle. This is useful if a package doesn't play well with bundling. Error messages like the one you received are good indicators here. We will use the correct version as per your package manager's _lockfile_ by checking the version found in `node_modules` after running install.
- In both cases we will add the package to the resulting `package.json` - the difference is where the version comes from.

For reproducible builds, marking packages as external will have no effect on versions used. The only important thing is to always use a specific version for additional packages, for example:

```ts
build: {
  extensions: [additionalPackages({ packages: [""wrangler@1.19.0""] })],
}
```"
2589198418,1411,[TRI-3867] Updating lots of environment variables at once fails with a transaction timeout,"When we bulk upsert environment variables we wrap the entire thing in a database transaction. If there are a lot of env vars (e.g. more than 100) then the transaction can timeout.

You can see in the current code that the transaction is wrapped around the for loop: https://github.com/triggerdotdev/trigger.dev/blob/feb4fcdac675aa6c18fde4b0a96e87abc80102e2/apps/webapp/app/v3/environmentVariables/environmentVariablesRepository.server.ts#L138

Instead we should move that transaction inside the for loop. We still need the transaction so we always create all the resources for each env var and don't leave any of them dangling.

<sub>[TRI-3867](https://linear.app/triggerdotdev/issue/TRI-3867/updating-lots-of-environment-variables-at-once-fails-with-a)</sub>",2416058702,hey @matt-aitken working in this issue
2589198418,1411,[TRI-3867] Updating lots of environment variables at once fails with a transaction timeout,"When we bulk upsert environment variables we wrap the entire thing in a database transaction. If there are a lot of env vars (e.g. more than 100) then the transaction can timeout.

You can see in the current code that the transaction is wrapped around the for loop: https://github.com/triggerdotdev/trigger.dev/blob/feb4fcdac675aa6c18fde4b0a96e87abc80102e2/apps/webapp/app/v3/environmentVariables/environmentVariablesRepository.server.ts#L138

Instead we should move that transaction inside the for loop. We still need the transaction so we always create all the resources for each env var and don't leave any of them dangling.

<sub>[TRI-3867](https://linear.app/triggerdotdev/issue/TRI-3867/updating-lots-of-environment-variables-at-once-fails-with-a)</sub>",2416122724,@matt-aitken Checkout this #1413  
2585755890,1406,"bug: TypeError: (0 , import_react.cache) is not a function","### Provide environment information

  System:
    OS: Linux 5.15 Ubuntu 22.04.2 LTS 22.04.2 LTS (Jammy Jellyfish)
    CPU: (32) x64 AMD Ryzen 9 7950X 16-Core Processor
    Memory: 84.82 GB / 93.87 GB
    Container: Yes
    Shell: 5.1.16 - /bin/bash
  Binaries:
    Node: 21.2.0 - ~/.nvm/versions/node/v21.2.0/bin/node
    Yarn: 1.22.21 - ~/.nvm/versions/node/v21.2.0/bin/yarn
    npm: 10.2.3 - ~/.nvm/versions/node/v21.2.0/bin/npm
    pnpm: 8.10.5 - ~/.nvm/versions/node/v21.2.0/bin/pnpm
    Watchman: 2023.12.04.00 - /home/linuxbrew/.linuxbrew/bin/watchman

### Describe the bug

I'm new to Trigger.dev, while trying to define the following task

`import { task } from ""@trigger.dev/sdk/v3"";
import { callReplicate } from '@/app/actions/replicate';
import { supabaseAdmin } from ""@/lib/supabase/admin"";

export const processImageTask = task({
    id: ""process-image-task"",
    run: async (payload: { jobId: string }, { ctx }) => {
      // Fetch the job details from Supabase
      const { data: job, error: jobError } = await supabaseAdmin
        .from('jobs')
        .select('*')
        .eq('id', payload.jobId)
        .single();

      console.log(`trigger/process-image.ts job: ${JSON.stringify(job)}`);
  
      if (jobError || !job) {
        throw new Error('Job not found or failed to fetch job details.');
      }
  
      // Update job status to 'processing'
      await supabaseAdmin
        .from('jobs')
        .update({ status: 'processing' })
        .eq('id', payload.jobId);
  
      // Call the Replicate API to process the image
      const { data: result, error } = await callReplicate({
        type: ""image-text-extractor"",
        input: {
          image: job.image_url,
        },
      });   

      console.log(`trigger/process-image.ts result: ${JSON.stringify(result)}`);
  
      if (error) {
        throw new Error(`Image processing failed: ${error}`);
      }
  
      // Return the extracted text as the output of the task
      return { result };
    },
    onSuccess: async (payload, output, { ctx }) => {
      // Update job status to 'complete' and save the result
      await supabaseAdmin
        .from('jobs')
        .update({
          status: 'complete',
          result: JSON.stringify(output.result),
          updated_at: new Date().toISOString(),
        })
        .eq('id', payload.jobId);
    },
    onFailure: async (payload, error, { ctx }) => {
      // Update job status to 'failed'
      await supabaseAdmin
        .from('jobs')
        .update({
          status: 'failed',
          updated_at: new Date().toISOString(),
        })
        .eq('id', payload.jobId);
    },
  });`

I receive the following error

`■  Error: Could not import trigger/process-image.ts
│  
│         TypeError: (0 , import_react.cache) is not a function
│             at file:///home/user/project/lib/supabase/admin.ts:25:32
│             at ModuleJob.run (node:internal/modules/esm/module_job:218:25)
│             at ModuleLoader.import (node:internal/modules/esm/loader:329:24)
│             at tryImport (file:///home/user/.pnpm-store/v3/tmp/dlx-36225/node_modules/.pnpm/trigger.dev@3.0.12/node_modules/trigger.dev/src/indexing/registerTasks.ts:54:20)
│             at registerTasks (file:///home/user/.pnpm-store/v3/tmp/dlx-36225/node_modules/.pnpm/trigger.dev@3.0.12/node_modules/trigger.dev/src/indexing/registerTasks.ts:8:29)
│             at bootstrap (file:///home/user/.pnpm-store/v3/tmp/dlx-36225/node_modules/.pnpm/trigger.dev@3.0.12/node_modules/trigger.dev/src/entryPoints/dev-index-worker.ts:88:24)
│             at file:///home/user/.pnpm-store/v3/tmp/dlx-36225/node_modules/.pnpm/trigger.dev@3.0.12/node_modules/trigger.dev/src/entryPoints/dev-index-worker.ts:98:49`

In file:///home/user/project/lib/supabase/admin.ts, I have

`import {cache} from ""react"";`

Why is this happening?


### Reproduction repo

I don't know how to provide Stackblitz/CodeSandbox, but this should be(?) easy to advice on.

### To reproduce

Use ``import {cache} from ""react"";`` in task definition.

### Additional information

_No response_",2411208185,"Which version of react are you using? If you are on React 18.x, unfortunately I don't think there's anything that can be done as that `cache` import is only available to experimental or canary releases of React (see [here](https://react.dev/reference/react/cache)). If you are using Next.js you will be on one of those releases, which is why this works. One thing you could try is adding the `react-server` import condition in your `trigger.config.ts` file:

https://trigger.dev/docs/config/config-file#conditions"
2585755890,1406,"bug: TypeError: (0 , import_react.cache) is not a function","### Provide environment information

  System:
    OS: Linux 5.15 Ubuntu 22.04.2 LTS 22.04.2 LTS (Jammy Jellyfish)
    CPU: (32) x64 AMD Ryzen 9 7950X 16-Core Processor
    Memory: 84.82 GB / 93.87 GB
    Container: Yes
    Shell: 5.1.16 - /bin/bash
  Binaries:
    Node: 21.2.0 - ~/.nvm/versions/node/v21.2.0/bin/node
    Yarn: 1.22.21 - ~/.nvm/versions/node/v21.2.0/bin/yarn
    npm: 10.2.3 - ~/.nvm/versions/node/v21.2.0/bin/npm
    pnpm: 8.10.5 - ~/.nvm/versions/node/v21.2.0/bin/pnpm
    Watchman: 2023.12.04.00 - /home/linuxbrew/.linuxbrew/bin/watchman

### Describe the bug

I'm new to Trigger.dev, while trying to define the following task

`import { task } from ""@trigger.dev/sdk/v3"";
import { callReplicate } from '@/app/actions/replicate';
import { supabaseAdmin } from ""@/lib/supabase/admin"";

export const processImageTask = task({
    id: ""process-image-task"",
    run: async (payload: { jobId: string }, { ctx }) => {
      // Fetch the job details from Supabase
      const { data: job, error: jobError } = await supabaseAdmin
        .from('jobs')
        .select('*')
        .eq('id', payload.jobId)
        .single();

      console.log(`trigger/process-image.ts job: ${JSON.stringify(job)}`);
  
      if (jobError || !job) {
        throw new Error('Job not found or failed to fetch job details.');
      }
  
      // Update job status to 'processing'
      await supabaseAdmin
        .from('jobs')
        .update({ status: 'processing' })
        .eq('id', payload.jobId);
  
      // Call the Replicate API to process the image
      const { data: result, error } = await callReplicate({
        type: ""image-text-extractor"",
        input: {
          image: job.image_url,
        },
      });   

      console.log(`trigger/process-image.ts result: ${JSON.stringify(result)}`);
  
      if (error) {
        throw new Error(`Image processing failed: ${error}`);
      }
  
      // Return the extracted text as the output of the task
      return { result };
    },
    onSuccess: async (payload, output, { ctx }) => {
      // Update job status to 'complete' and save the result
      await supabaseAdmin
        .from('jobs')
        .update({
          status: 'complete',
          result: JSON.stringify(output.result),
          updated_at: new Date().toISOString(),
        })
        .eq('id', payload.jobId);
    },
    onFailure: async (payload, error, { ctx }) => {
      // Update job status to 'failed'
      await supabaseAdmin
        .from('jobs')
        .update({
          status: 'failed',
          updated_at: new Date().toISOString(),
        })
        .eq('id', payload.jobId);
    },
  });`

I receive the following error

`■  Error: Could not import trigger/process-image.ts
│  
│         TypeError: (0 , import_react.cache) is not a function
│             at file:///home/user/project/lib/supabase/admin.ts:25:32
│             at ModuleJob.run (node:internal/modules/esm/module_job:218:25)
│             at ModuleLoader.import (node:internal/modules/esm/loader:329:24)
│             at tryImport (file:///home/user/.pnpm-store/v3/tmp/dlx-36225/node_modules/.pnpm/trigger.dev@3.0.12/node_modules/trigger.dev/src/indexing/registerTasks.ts:54:20)
│             at registerTasks (file:///home/user/.pnpm-store/v3/tmp/dlx-36225/node_modules/.pnpm/trigger.dev@3.0.12/node_modules/trigger.dev/src/indexing/registerTasks.ts:8:29)
│             at bootstrap (file:///home/user/.pnpm-store/v3/tmp/dlx-36225/node_modules/.pnpm/trigger.dev@3.0.12/node_modules/trigger.dev/src/entryPoints/dev-index-worker.ts:88:24)
│             at file:///home/user/.pnpm-store/v3/tmp/dlx-36225/node_modules/.pnpm/trigger.dev@3.0.12/node_modules/trigger.dev/src/entryPoints/dev-index-worker.ts:98:49`

In file:///home/user/project/lib/supabase/admin.ts, I have

`import {cache} from ""react"";`

Why is this happening?


### Reproduction repo

I don't know how to provide Stackblitz/CodeSandbox, but this should be(?) easy to advice on.

### To reproduce

Use ``import {cache} from ""react"";`` in task definition.

### Additional information

_No response_",2496839950,"Hi there! I understand you're running into an issue with the React cache function in your Trigger.dev task. Let me help you resolve this.

The error you're seeing is because the React `cache` function is part of React's Server Components features, which requires specific configuration to work properly in different contexts. For your Trigger.dev task, there are two ways to resolve this:

1. If you need to use React server components features, add the following to your `trigger.config.ts` file:

```typescript
export default {
  // ... other config
  conditions: {
    // Add react-server condition to support React Server Components
    import: [""react-server""]
  }
}
```

2. Alternatively, if you don't specifically need React's server components features, I recommend removing the React cache usage and implementing a different caching solution. For example:

```typescript
// Instead of React's cache
let cachedClient: SupabaseClient | null = null;

export const supabaseAdmin = (() => {
  if (cachedClient) return cachedClient;
  
  cachedClient = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
  );
  
  return cachedClient;
})();
```

This solution uses a simple module-level singleton pattern which achieves similar caching behavior without depending on React's experimental features.

The second approach is more reliable for Trigger.dev tasks since they run in a Node.js environment where React server components features aren't typically needed.

Let me know if you need any clarification or run into any other issues!

References:
- Similar issue resolved in [Trigger.dev GitHub issue #331](https://github.com/triggerdotdev/trigger.dev/issues/331)
- [Trigger.dev documentation on configuration](https://trigger.dev/docs/config/config-file#conditions)"
2554215276,1369,bug: TRIGGER_SECRET_KEY is being set to undefined when using Vite,"### Provide environment information

```
  System:
    OS: macOS 14.6.1
    CPU: (8) arm64 Apple M1 Pro
    Memory: 184.53 MB / 16.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 22.9.0 - /opt/homebrew/bin/node
    Yarn: 1.22.22 - /opt/homebrew/bin/yarn
    npm: 10.8.3 - /opt/homebrew/bin/npm
    pnpm: 9.11.0 - /opt/homebrew/bin/pnpm
```

### Describe the bug

Somehow my TRIGGER_SECRET_KEY is not getting passed through when using Vite.

Running:
```import { TRIGGER_SECRET_KEY, TRIGGER_SECRET_KEYY, TRIGGER_API_URL } from '$env/static/private';```

I get `undefined, tr_dev_xyz, http://127.0.0.1:3040` which is strange. If I call the secret key `TRIGGER_SECRET_KEYY` instead of `TRIGGER_SECRET_KEY` it passes through no problem. I've grepped my codebase and I'm not doing anything with this environment variable anywhere. 

### Reproduction repo

n/a

### To reproduce

Using SvelteKit to trigger a task, and Vite to load up my `.env` file.

### Additional information

_No response_",2478231037,"A temporary work around is to use [dotenv](https://www.npmjs.com/package/dotenv)

```js
// hooks.server.ts

import 'dotenv/config'
```"
2554215276,1369,bug: TRIGGER_SECRET_KEY is being set to undefined when using Vite,"### Provide environment information

```
  System:
    OS: macOS 14.6.1
    CPU: (8) arm64 Apple M1 Pro
    Memory: 184.53 MB / 16.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 22.9.0 - /opt/homebrew/bin/node
    Yarn: 1.22.22 - /opt/homebrew/bin/yarn
    npm: 10.8.3 - /opt/homebrew/bin/npm
    pnpm: 9.11.0 - /opt/homebrew/bin/pnpm
```

### Describe the bug

Somehow my TRIGGER_SECRET_KEY is not getting passed through when using Vite.

Running:
```import { TRIGGER_SECRET_KEY, TRIGGER_SECRET_KEYY, TRIGGER_API_URL } from '$env/static/private';```

I get `undefined, tr_dev_xyz, http://127.0.0.1:3040` which is strange. If I call the secret key `TRIGGER_SECRET_KEYY` instead of `TRIGGER_SECRET_KEY` it passes through no problem. I've grepped my codebase and I'm not doing anything with this environment variable anywhere. 

### Reproduction repo

n/a

### To reproduce

Using SvelteKit to trigger a task, and Vite to load up my `.env` file.

### Additional information

_No response_",2481351822,"Do you have a reproduction available? @Woolworths I can take a look if so, as it's SvelteKit related"
2550451335,1363,investigate adding module-sync export condition,"https://github.com/nodejs/node/pull/54648

We'll also want to keep an eye on how we should handle this in our build process (e.g. we might need /want to add module-sync to our esbuild conditions).",,
2550130085,1362,doc need: creating a new reference project and deploying it locally,"We're missing a doc in the repo (ideally at `references/README.md`) that details how to:

- Create a new reference project by copying the `hello-world` reference project
- Get the dev CLI command running against a local instance of Trigger.dev (e.g. the webapp)
- Get the deploy CLI command running against a local instance of Trigger.dev by setting up and running the webapp alongside the coordinator and docker-provider:

```sh
pnpm run dev --filter webapp --filter coordinator --filter docker-provider
```

Then deploying it like so:

```sh
pnpm exec trigger deploy --self-hosted --load-image
```

This README should also make sure the CONTRIBUTING.md guidelines are enough to get the webapp running locally.

This new README should be sufficient for a new contributor to come in from scratch and create a new reference project and both run it in dev and deploy it.",2376527888,"/attempt #1362

<div id=""algora-attempt"" />

| [Algora profile](https://console.algora.io/@/varshith257) | Completed bounties | Tech | Active attempts | Options |
| --- | --- | --- | --- | --- |
| @varshith257 | 13 bounties from 7 projects | <div align=""center"">TypeScript, Go</div> | <div align=""center""></div> | [Cancel attempt](https://console.algora.io/api/bounties/cm1j4t0640012kx03tegpcjvp/cancel-attempt) |"
2550106708,1361,Create a libreoffice build extension to allow docx/pptx to PDF conversion,"[Papermark](https://www.papermark.io/) is using Trigger.dev v3 but they have to resort to calling out to a separate service (gotenberg.dev) they are running on fly.io to do docx/pptx to PDF conversion (you can see the code [here](https://github.com/mfts/papermark/blob/ff90054a5ef94eb41a7a62374ebc954728afde47/lib/trigger/convert-files.ts#L86)).

It would be great if they could remove the gotenburg.dev call and do the conversion right there in their Trigger.dev task. For that, we will need a [Build extension](https://trigger.dev/docs/config/extensions/overview) that adds the libreoffice system packages and anything else that is necessary for the conversion (fonts, etc.), and then this package could be used: [libreoffice](https://www.npmjs.com/package/libreoffice-convert)

The extension should try to be as lightweight as possible (e.g. don't install X11). Is it possible to run LibreOffice in ""headless"" mode?

Whoever creates this extension should make sure and test it inside a new `references` project in the repo, and run against a local version of trigger.dev. You can copy the `hello-world` reference project to get something running quickly.",2416488838,"hi @ericallam , can i work on this. 
thanks

and, can i do this for installing libreoffice on the image?
```
apt-get install -y \
    libreoffice \
    --no-install-recommends
```
it's either that or:
```
apt-get install -y \
    libreoffice-writer \
    libreoffice-calc \
    libreoffice-impress \
    fonts-liberation \
    --no-install-recommends \
```

both of these work for pdf conversion but the latter might give out errors for some niche edge cases.

p.s.
libreoffice can indeed run in headless mode like thils:
`libreoffice --headless --convert-to pdf filename.docx`
but the libreoffice-convert library is doing the same underhood. ([reference](https://github.com/elwerene/libreoffice-convert/blob/master/index.js))

thanks again
"
2549826629,1358,Update the prisma extension to force binaryTarget of debian-openssl-3.0.x,"If you see this error:

```
PrismaClientInitializationError: 
Invalid `prisma.users.findUnique()` invocation:


Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".

This happened because Prisma Client was generated for ""debian-openssl-1.1.x"", but the actual deployment required ""debian-openssl-3.0.x"".
Add ""debian-openssl-3.0.x"" to `binaryTargets` in the ""schema.prisma"" file and run `prisma generate` after saving it:

generator client {
  provider      = ""prisma-client-js""
  binaryTargets = [""native"", ""debian-openssl-3.0.x""]
}

The following locations have been searched:
  /app/node_modules/.prisma/client
  /
  ```
  
You can fix it yourself by adding `""native"", ""debian-openssl-3.0.x""` to your `binaryTargets` array, like it says in the error above. Prisma allows generating many targets so this shouldn't impact your existing app that uses Prisma, it just means that Trigger.dev can also work.

## Prisma extension

We need to investigate whether we can solve this automatically without requiring any changes to the prisma schema file, by adding some code to our prisma extension somehow.
",2387263342,"Also seeing this on 3.0.9. Worked fine on 56 beta:

```
◇  Failed to deploy project
│
■  Error: PrismaClientInitializationError
│  
│         PrismaClientInitializationError: Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".
│         
│         This happened because Prisma Client was generated for ""darwin-arm64"", but the actual deployment required ""debian-openssl-3.0.x"".
│         Add ""debian-openssl-3.0.x"" to `binaryTargets` in the ""schema.prisma"" file and run `prisma generate` after saving it:
│         
│         generator client {
│           provider      = ""prisma-client-js""
│           binaryTargets = [""native"", ""debian-openssl-3.0.x""]
│         }
```"
2549826629,1358,Update the prisma extension to force binaryTarget of debian-openssl-3.0.x,"If you see this error:

```
PrismaClientInitializationError: 
Invalid `prisma.users.findUnique()` invocation:


Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".

This happened because Prisma Client was generated for ""debian-openssl-1.1.x"", but the actual deployment required ""debian-openssl-3.0.x"".
Add ""debian-openssl-3.0.x"" to `binaryTargets` in the ""schema.prisma"" file and run `prisma generate` after saving it:

generator client {
  provider      = ""prisma-client-js""
  binaryTargets = [""native"", ""debian-openssl-3.0.x""]
}

The following locations have been searched:
  /app/node_modules/.prisma/client
  /
  ```
  
You can fix it yourself by adding `""native"", ""debian-openssl-3.0.x""` to your `binaryTargets` array, like it says in the error above. Prisma allows generating many targets so this shouldn't impact your existing app that uses Prisma, it just means that Trigger.dev can also work.

## Prisma extension

We need to investigate whether we can solve this automatically without requiring any changes to the prisma schema file, by adding some code to our prisma extension somehow.
",2387266478,"Adding `binaryTargets = [""native"", ""debian-openssl-3.0.x""]` and running `prisma generate` results in this error:

```
Error: PrismaClientInitializationError
│  
│         PrismaClientInitializationError: Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".
│         
│         This is likely caused by a bundler that has not copied ""libquery_engine-debian-openssl-3.0.x.so.node"" next to the resulting bundle.
│         Ensure that ""libquery_engine-debian-openssl-3.0.x.so.node"" has been copied next to the bundle or in ""../node_modules/.pnpm/@prisma+client@5.20.0_prisma@5.20.0/node_modules/.prisma/client"".
│         
│         We would appreciate if you could take the time to share some information with us.
│         Please help us by answering a few questions: https://pris.ly/engine-not-found-bundler-investigation
│         
│         The following locations have been searched:
```

Reverting my Trigger package update for now."
2549826629,1358,Update the prisma extension to force binaryTarget of debian-openssl-3.0.x,"If you see this error:

```
PrismaClientInitializationError: 
Invalid `prisma.users.findUnique()` invocation:


Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".

This happened because Prisma Client was generated for ""debian-openssl-1.1.x"", but the actual deployment required ""debian-openssl-3.0.x"".
Add ""debian-openssl-3.0.x"" to `binaryTargets` in the ""schema.prisma"" file and run `prisma generate` after saving it:

generator client {
  provider      = ""prisma-client-js""
  binaryTargets = [""native"", ""debian-openssl-3.0.x""]
}

The following locations have been searched:
  /app/node_modules/.prisma/client
  /
  ```
  
You can fix it yourself by adding `""native"", ""debian-openssl-3.0.x""` to your `binaryTargets` array, like it says in the error above. Prisma allows generating many targets so this shouldn't impact your existing app that uses Prisma, it just means that Trigger.dev can also work.

## Prisma extension

We need to investigate whether we can solve this automatically without requiring any changes to the prisma schema file, by adding some code to our prisma extension somehow.
",2387272063,Can confirm that reverting to `3.0.0-beta.56` fixes the issues.
2549826629,1358,Update the prisma extension to force binaryTarget of debian-openssl-3.0.x,"If you see this error:

```
PrismaClientInitializationError: 
Invalid `prisma.users.findUnique()` invocation:


Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".

This happened because Prisma Client was generated for ""debian-openssl-1.1.x"", but the actual deployment required ""debian-openssl-3.0.x"".
Add ""debian-openssl-3.0.x"" to `binaryTargets` in the ""schema.prisma"" file and run `prisma generate` after saving it:

generator client {
  provider      = ""prisma-client-js""
  binaryTargets = [""native"", ""debian-openssl-3.0.x""]
}

The following locations have been searched:
  /app/node_modules/.prisma/client
  /
  ```
  
You can fix it yourself by adding `""native"", ""debian-openssl-3.0.x""` to your `binaryTargets` array, like it says in the error above. Prisma allows generating many targets so this shouldn't impact your existing app that uses Prisma, it just means that Trigger.dev can also work.

## Prisma extension

We need to investigate whether we can solve this automatically without requiring any changes to the prisma schema file, by adding some code to our prisma extension somehow.
",2387279402,I'm using a Turborepo btw. `prisma` is installed in the `web` app where I'm trying to run trigger deploy
2549826629,1358,Update the prisma extension to force binaryTarget of debian-openssl-3.0.x,"If you see this error:

```
PrismaClientInitializationError: 
Invalid `prisma.users.findUnique()` invocation:


Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".

This happened because Prisma Client was generated for ""debian-openssl-1.1.x"", but the actual deployment required ""debian-openssl-3.0.x"".
Add ""debian-openssl-3.0.x"" to `binaryTargets` in the ""schema.prisma"" file and run `prisma generate` after saving it:

generator client {
  provider      = ""prisma-client-js""
  binaryTargets = [""native"", ""debian-openssl-3.0.x""]
}

The following locations have been searched:
  /app/node_modules/.prisma/client
  /
  ```
  
You can fix it yourself by adding `""native"", ""debian-openssl-3.0.x""` to your `binaryTargets` array, like it says in the error above. Prisma allows generating many targets so this shouldn't impact your existing app that uses Prisma, it just means that Trigger.dev can also work.

## Prisma extension

We need to investigate whether we can solve this automatically without requiring any changes to the prisma schema file, by adding some code to our prisma extension somehow.
",2387303675,@elie222 did you use the [prisma extension](https://trigger.dev/docs/config/config-file#prisma) when using 3.0.9?
2549826629,1358,Update the prisma extension to force binaryTarget of debian-openssl-3.0.x,"If you see this error:

```
PrismaClientInitializationError: 
Invalid `prisma.users.findUnique()` invocation:


Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".

This happened because Prisma Client was generated for ""debian-openssl-1.1.x"", but the actual deployment required ""debian-openssl-3.0.x"".
Add ""debian-openssl-3.0.x"" to `binaryTargets` in the ""schema.prisma"" file and run `prisma generate` after saving it:

generator client {
  provider      = ""prisma-client-js""
  binaryTargets = [""native"", ""debian-openssl-3.0.x""]
}

The following locations have been searched:
  /app/node_modules/.prisma/client
  /
  ```
  
You can fix it yourself by adding `""native"", ""debian-openssl-3.0.x""` to your `binaryTargets` array, like it says in the error above. Prisma allows generating many targets so this shouldn't impact your existing app that uses Prisma, it just means that Trigger.dev can also work.

## Prisma extension

We need to investigate whether we can solve this automatically without requiring any changes to the prisma schema file, by adding some code to our prisma extension somehow.
",2387527569,"> @elie222 did you use the [prisma extension](https://trigger.dev/docs/config/config-file#prisma) when using 3.0.9?

Didn't try it. Will try tomorrow. Thanks!"
2549826629,1358,Update the prisma extension to force binaryTarget of debian-openssl-3.0.x,"If you see this error:

```
PrismaClientInitializationError: 
Invalid `prisma.users.findUnique()` invocation:


Prisma Client could not locate the Query Engine for runtime ""debian-openssl-3.0.x"".

This happened because Prisma Client was generated for ""debian-openssl-1.1.x"", but the actual deployment required ""debian-openssl-3.0.x"".
Add ""debian-openssl-3.0.x"" to `binaryTargets` in the ""schema.prisma"" file and run `prisma generate` after saving it:

generator client {
  provider      = ""prisma-client-js""
  binaryTargets = [""native"", ""debian-openssl-3.0.x""]
}

The following locations have been searched:
  /app/node_modules/.prisma/client
  /
  ```
  
You can fix it yourself by adding `""native"", ""debian-openssl-3.0.x""` to your `binaryTargets` array, like it says in the error above. Prisma allows generating many targets so this shouldn't impact your existing app that uses Prisma, it just means that Trigger.dev can also work.

## Prisma extension

We need to investigate whether we can solve this automatically without requiring any changes to the prisma schema file, by adding some code to our prisma extension somehow.
",2467264384,Tried the prisma extension on 3.1.2 and still seeing the issue
2543756538,1349,docs: make a note about zod-prisma-types generator,"Suggest updating to

```
generator zod {
  provider = ""npx --yes zod-prisma-types""
}
```",2374195427,"can I get a little more context here?
"
2543756538,1349,docs: make a note about zod-prisma-types generator,"Suggest updating to

```
generator zod {
  provider = ""npx --yes zod-prisma-types""
}
```",2401960847,"Hi @ericallam,

I would like to work on this issue. Could you please assign it to me?

Thanks!
YoosufAathil"
2542128461,1343,Make payload/output offloading threshold size and other limits customizable,"Right now everything is hardcoded, but we really need to make these env vars and document them for self-hosters:

https://github.com/triggerdotdev/trigger.dev/blob/04645e83293ab8a04a094a84697b20b2b08d6142/packages/core/src/v3/limits.ts#L3-L11",,
2541016383,1342,Bug on docs,"Path: /config/config-file

There is not such export from sdk v3

```ts
import { defineConfig } from ""@trigger.dev/sdk/v3"";
```

<img width=""760"" alt=""Screenshot 2024-09-22 at 4 20 31 PM"" src=""https://github.com/user-attachments/assets/1a710ac2-1c7c-4a12-b1d3-45a40102baa4"">

Due to this, I am not able to figure out how to get prisma running properly on trigger. Any help would be appreciated.

My current config looks like - 

```ts
import type { TriggerConfig } from ""@trigger.dev/sdk/v3"";
import { prismaExtension } from ""@trigger.dev/build/extensions/prisma"";

export const config: TriggerConfig = {
  project: ""..."",
  logLevel: ""log"",
  retries: {
    enabledInDev: true,
    default: {
      maxAttempts: 3,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
      randomize: true,
    },
  },
  dependenciesToBundle: [/.*/],
};
```",,
2539048957,1338,dev CLI should automatically load `dev.vars` file as an env var,"Should be added to the list here: 

https://github.com/triggerdotdev/trigger.dev/blob/35c8e35674c9776381eedfe6d1e25c4edd8ca12b/packages/cli-v3/src/utilities/dotEnv.ts/#L5",,
2538694290,1336,"During dev, fixing a typescript error in a single file leads to tasks in those files not getting indexed","I think this just happened (will need to reproduce properly):

- Running the dev command
- There were typescript errors in a file with tasks
- I fixed those typescript errors by editing a monorepo dependency (`@trigger.dev/core`)
- Those tasks failed to get indexed after the fix

I think it may be related to the contentHash on the background worker and this line:

https://github.com/triggerdotdev/trigger.dev/blob/764f03a3c50b1d0bb21a02e32a72a51823b62fba/apps/webapp/app/v3/services/createBackgroundWorker.server.ts#L52

It may be that we need to make sure the contentHash is updated in these cases. Not sure this is really an issue, but something I want to make sure doesn't happen not in the monorepo.",,
2538638893,1334,bug: audioWaveform extension breaks apt-get install for next extensions when building the docker image,"### Provide environment information

-   System:
    -  OS: macOS 15.0
    -  CPU: (8) arm64 Apple M3
    -  Memory: 95.38 MB / 16.00 GB
    -  Shell: 5.9 - /bin/zsh
-   Binaries:
    -  Node: 20.11.1 - ~/.nvm/versions/node/v20.11.1/bin/node
    -  npm: 10.2.4 - ~/.nvm/versions/node/v20.11.1/bin/npm
    -  pnpm: 8.15.5 - ~/.nvm/versions/node/v20.11.1/bin/pnpm
    -  bun: 1.1.24 - /opt/homebrew/bin/bun

### Describe the bug

The `audioWaveform` extension breaks the package installation (`apt-get install`) for the following extensions.  

### Reproduction repo

https://github.com/ThibautCuchet/trigger.dev/tree/issue-audiowaveform

### To reproduce

In `references/v3-catalog/trigger.config.ts`, I added a debug extension after `audioWaveform` : 
```typescript
      audioWaveform(),
      {
        name: ""debug"",
        onBuildComplete: (ctx) => {
          ctx.addLayer({
            id: ""debug"",
            image: {
              instructions: [""RUN apt-get update"", ""RUN apt-get install -y curl""],
            }
          })
        }
      },
```

Running `pnpm exec trigger deploy --profile local --self-hosted`, will raise an error during the build of the docker image : 
```shell
Containerfile:8
--------------------
6 |     RUN rm audiowaveform*.deb
7 |     RUN apt-get update
8 | >>> RUN apt-get install -y curl
9 |
10 |     ENV DEBIAN_FRONTEND=noninteractive
--------------------
ERROR: failed to solve: process ""/bin/sh -c apt-get install -y curl"" did not complete successfully: exit code: 100
```

Moving the `debug` extension before `audioWaveform`, doens't have this bug : 
```typescript
      {
        name: ""debug"",
        onBuildComplete: (ctx) => {
          ctx.addLayer({
            id: ""debug"",
            image: {
              instructions: [""RUN apt-get update"", ""RUN apt-get install -y curl""],
            }
          })
        }
      },
      audioWaveform(),
```

### Additional information

This error breaks the deployment of `references/v3-catalog` in production because the new `puppeteer` extension needs to install packages.
https://github.com/triggerdotdev/trigger.dev/blob/b999c86e2330cc106928c12c5cb4c95406cdbe10/references/v3-catalog/trigger.config.ts#L83

```shell
------
Containerfile:7
--------------------
5 |     RUN dpkg -i audiowaveform_1.10.1-1-12_amd64.deb || true
6 |     RUN rm audiowaveform*.deb
7 | >>> RUN apt-get update && apt-get install curl gnupg -y   && curl --location --silent https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add -   && sh -c 'echo ""deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main"" >> /etc/apt/sources.list.d/google.list'   && apt-get update   && apt-get install google-chrome-stable -y --no-install-recommends   && rm -rf /var/lib/apt/lists/*
8 |
9 |     ENV DEBIAN_FRONTEND=noninteractive
--------------------
ERROR: failed to solve: process ""/bin/sh -c apt-get update && apt-get install curl gnupg -y   && curl --location --silent https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add -   && sh -c 'echo \""deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\"" >> /etc/apt/sources.list.d/google.list'   && apt-get update   && apt-get install google-chrome-stable -y --no-install-recommends   && rm -rf /var/lib/apt/lists/*"" did not complete successfully: exit code: 100
```",,
2538632463,1333,Using import.meta.env fails inside of a trigger.dev build,"From what I can tell, `import.meta.env` is a vite thing that populates `import.meta.env` with environment variables.

https://import-meta-env.org/guide/getting-started/introduction.html

An example usage is here: 

https://github.com/usetonearm/core-web/blob/d178a6277306e9bfe0cde49c6550ceae33475292/packages/supabase/src/get-supabase-client-keys.ts#L6

They do have an esbuild plugin that we should look into seeing if it solves the issue. ",,
2535961274,1325,Build fails with TypedSQL enabled due to directory layout,"https://github.com/triggerdotdev/trigger.dev/blob/b3a6f4e0ac62f10f6c539c933e7ec46b8843c87e/packages/build/src/extensions/prisma.ts#L131

The code in the CLI expects the directory layout to be:
```
<project_root>/sql - sql files for TypedSQL
<project_root>/<prisma_dir> - prisma directory
<project_root>/<prisma_dir>/<schema_name> - Prisma schema
```
While in reality the directory layout is:
```
<project_root>/<prisma_dir> - prisma directory
<project_root>/<prisma_dir>/sql - sql files for TypedSQL
<project_root>/<prisma_dir>/<schema_name> - Prisma schema
```

This results in builds failing:
```
✘ [ERROR] Failed to apply extension PrismaExtension onBuildComplete Error: ENOENT: no such file or directory, scandir '/workspaces/mapanfz/sql'

      at async readdir (node:internal/fs/promises:950:18)
      at async PrismaExtension.onBuildComplete
  (/workspaces/mapanfz/node_modules/@trigger.dev/build/dist/commonjs/extensions/prisma.js:75:30)
      at async notifyExtensionOnBuildComplete
  (file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/build/extensions.js:16:17)
      at async buildWorker
  (file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/build/buildWorker.js:70:21)
      at async _deployCommand
  (file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/commands/deploy.js:120:27)
      at async
  file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/commands/deploy.js:77:16
      at async
  file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/cli/common.js:54:28
      at async wrapCommandAction
  (file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/cli/common.js:40:12)
      at async deployCommand
  (file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/commands/deploy.js:76:12)
      at async
  file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/commands/deploy.js:71:13
      at async handleTelemetry
  (file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/cli/common.js:30:9)
      at async Command.<anonymous>
  (file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/commands/deploy.js:69:9)
      at async Command.parseAsync
  (/home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/commander/lib/command.js:935:5)
      at async main
  (file:///home/vscode/.npm/_npx/f51a09bd0abf5f10/node_modules/trigger.dev/dist/esm/index.js:5:5) {
    errno: -2,
    code: 'ENOENT',
    syscall: 'scandir',
    path: '/workspaces/mapanfz/sql'
  }
```
As a workaround I've added `/sql` to my gitignore and before running the deploy i just copy over the sql folder from the prisma directory.",,
2433491166,1238,[TRI-3194] Dev command child runs don't execute (Windows WSL),"### Provide environment information

Running Windows with WSL.

System:
    OS: Linux 5.15 Ubuntu 22.04.3 LTS 22.04.3 LTS (Jammy Jellyfish)
    CPU: (16) x64 AMD Ryzen 7 PRO 7840HS w/ Radeon 780M Graphics
    Memory: 19.77 GB / 30.68 GB
    Container: Yes
    Shell: 5.8.1 - /usr/bin/zsh
  Binaries:
    Node: 18.19.1 - \~\~/.nvm/versions/node/v18.19.1/bin/node
    Yarn: 1.22.22 - /mnt/c/Program Files/nodejs/yarn
    npm: 10.2.4 - \~\~/.nvm/versions/node/v18.19.1/bin/npm
    pnpm: 8.15.3 - \~\~/.nvm/versions/node/v18.19.1/bin/pnpm

### Describe the bug

Child runs don't work, they just stay in the ""queued"" status until they expire. There are no other runs executing.

### Reproduction repo

–

### To reproduce

```ts
export const parentTask = task({
  id: 'parent'
  run: async (payload: { organizationId: string }) => {
    console.log(`Start parent`);
    
    await childTask.triggerAndWait({
       organizationId: payload.organizationId
    });
  }
});

const childTask = task({
  id: 'child',
  run: async (payload: { organizationId: string }) => {
    console.log(`Child task`);
  }
});
```

""Start parent"" is logged on the console. Child is stuck in ""Executing"" and also doesn't log anything. Config I have:

```ts
export const config: TriggerConfig = {
  project: 'proj_xx',
  logLevel: 'log',
  retries: {
    enabledInDev: true,
    default: {
      maxAttempts: 3,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
      randomize: true
    }
  }
};
```

### Additional information

*No response*

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-3194](https://linear.app/triggerdotdev/issue/TRI-3194/dev-command-child-runs-dont-execute-windows-wsl)</sub>",,
2419659113,1231,Allow specifying package manager for typecheck,"https://github.com/triggerdotdev/trigger.dev/blob/da592d867adc84f65855fc2f152a1ee1b48cc650/packages/cli-v3/src/commands/deploy.ts#L1660

Because I'm using pnpm, my Github action for deploys are failing because the typecheck step only uses npm. 

Possible solutions:
- Add a flag to the deploy command for specifying the package manager
- Detect the package manager used by the project by looking for a `pnpm-lock.yaml`/`npm-lock.yaml` file etc

I know I can fix this by making npm available, but I'd rather stick with pnpm since it's managing my monorepo deps.",,
2412978789,1223,bug: 25hX Error: @prisma/client did not initialize yet. ,"### Provide environment information

GitHub Actions

### Describe the bug

When running
```
  - name: Deploy Trigger.dev
    working-directory: apps/nextjs
    env:
      TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
    run: |
      npm run deploy:trigger-staging`
```

where

```
  ""scripts"": {
    ""dev"": ""prisma generate && next dev"",
    ""build"": ""prisma generate && next build"",
    ""postbuild"": ""npx next-sitemap"",
    ""start"": ""next start"",
    ""lint"": ""next lint"",
    ""prettier"": ""prettier --write ."",
    ""deploy:trigger-prod"": ""prisma generate && npx trigger.dev@3.0.0-beta.48 deploy"",
    ""deploy:trigger-staging"": ""prisma generate && npx trigger.dev@3.0.0-beta.48 deploy --env staging""
  },
  ```

I always get,
```
> studybuddy-web@1.0.0 deploy:trigger-staging
> prisma generate && npx trigger.dev@3.0.0-beta.4[8](https://github.com/studyspaceglobal/studyspace-monorepo/actions/runs/9970535527/job/27549644708#step:13:9) deploy --env staging

Environment variables loaded from .env
Prisma schema loaded from prisma/schema

✔ Generated Prisma Client (v5.16.2) to ./node_modules/@prisma/client in 6[9](https://github.com/studyspaceglobal/studyspace-monorepo/actions/runs/9970535527/job/27549644708#step:13:10)6ms

Start using Prisma Client in Node.js (See: https://pris.ly/d/client)
import { PrismaClient } from '@prisma/client'
const prisma = new PrismaClient()
import { PrismaClient } from '@prisma/client/edge'
const prisma = new PrismaClient()

See other ways of importing Prisma Client: http://pris.ly/d/importing-client

┌─────────────────────────────────────────────────────────────┐
│  Deploying your app to serverless or edge functions?        │
│  Try Prisma Accelerate for connection pooling and caching.  │
│  https://pris.ly/cli/--accelerate                           │
└─────────────────────────────────────────────────────────────┘

npm warn exec The following package was not found and will be installed: trigger.dev@3.0.0-beta.48

Trigger.dev (3.0.0-beta.48)
------------------------------------------------------
┌  Deploying project
│
◇  Preparing to deploy ""StudyBuddy"" (proj_zbkgcyupelzxtkkoxhpz) to staging
25l│
◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project.◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project..◑  Typechecking project..◒  Typechecking project..◐  Typechecking project..◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project...◒  Typechecking project...◐  Typechecking project...◓  Typechecking project...◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project◒  Typechecking project◐  Typechecking project◓  Typechecking project◑  Typechecking project.◒  Typechecking project.◐  Typechecking project.◇  Typechecking passed with 0 errors
25h25l│
◒  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs◐  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs◓  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs◑  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs◒  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs◐  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs◓  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs◑  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs◒  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs.◐  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs.◓  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs.◑  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs.◒  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs.◐  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs.◓  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs.◑  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs.◒  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs..◐  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs..◓  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs..◑  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs..◒  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs..◐  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs..◓  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs..◑  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs..◒  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs...◐  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs...◓  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs...◑  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs...◒  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs...◐  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs...◓  Building project in /home/runner/work/***-monorepo/***-monorepo/apps/nextjs...◇  Project built successfully
25h25l│
◒  Resolving dependencies◐  Resolving dependencies◓  Resolving dependencies◑  Resolving dependencies◒  Resolving dependencies◐  Resolving dependencies◓  Resolving dependencies◑  Resolving dependencies◒  Resolving dependencies.◐  Resolving dependencies.◓  Resolving dependencies.◑  Resolving dependencies.◒  Resolving dependencies.◐  Resolving dependencies.◓  Resolving dependencies.◑  Resolving dependencies.◒  Resolving dependencies..◐  Resolving dependencies..◓  Resolving dependencies..◑  Resolving dependencies..◒  Resolving dependencies..◐  Resolving dependencies..◓  Resolving dependencies..◑  Resolving dependencies..◒  Resolving dependencies...◐  Resolving dependencies...◓  Resolving dependencies...◑  Resolving dependencies...◒  Resolving dependencies...◐  Resolving dependencies...◓  Resolving dependencies...◑  Resolving dependencies...◒  Resolving dependencies...◐  Resolving dependencies◓  Resolving dependencies◑  Resolving dependencies◒  Resolving dependencies◐  Resolving dependencies◓  Resolving dependencies◑  Resolving dependencies◒  Resolving dependencies◐  Resolving dependencies.◓  Resolving dependencies.◑  Resolving dependencies.◒  Resolving dependencies.◐  Resolving dependencies.◓  Resolving dependencies.◑  Resolving dependencies.◒  Resolving dependencies.◐  Resolving dependencies..◓  Resolving dependencies..◑  Resolving dependencies..◒  Resolving dependencies..◐  Resolving dependencies..◓  Resolving dependencies..◑  Resolving dependencies..◒  Resolving dependencies..◐  Resolving dependencies...◓  Resolving dependencies...◑  Resolving dependencies...◒  Resolving dependencies...◐  Resolving dependencies...◓  Resolving dependencies...◑  Resolving dependencies...◒  Resolving dependencies...◐  Resolving dependencies...◓  Resolving dependencies◑  Resolving dependencies◒  Resolving dependencies◐  Resolving dependencies◓  Resolving dependencies◑  Resolving dependencies◒  Resolving dependencies◐  Resolving dependencies◓  Resolving dependencies.◑  Resolving dependencies.◒  Resolving dependencies.◐  Resolving dependencies.◓  Resolving dependencies.◑  Resolving dependencies.◒  Resolving dependencies.◐  Resolving dependencies.◓  Resolving dependencies..◑  Resolving dependencies..◒  Resolving dependencies..◐  Resolving dependencies..◓  Resolving dependencies..◑  Resolving dependencies..◒  Resolving dependencies..◐  Resolving dependencies..◓  Resolving dependencies...◑  Resolving dependencies...◒  Resolving dependencies...◐  Resolving dependencies...◓  Resolving dependencies...◑  Resolving dependencies...◇  Dependencies resolved
25h25l│
◒  Deploying version 202407[17](https://github.com/studyspaceglobal/studyspace-monorepo/actions/runs/9970535527/job/27549644708#step:13:18).4◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  Deploying version [20](https://github.com/studyspaceglobal/studyspace-monorepo/actions/runs/9970535527/job/27549644708#step:13:21)240717.4◒  Deploying version 20240717.4◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  Deploying version 20240717.4◒  Deploying version 20[24](https://github.com/studyspaceglobal/studyspace-monorepo/actions/runs/9970535527/job/27549644708#step:13:25)0717.4.◐  Deploying version 20240717.4.◓  Deploying version 20240717.4.◑  Deploying version 20240717.4.◒  Deploying version 20240717.4.◐  Deploying version 20240717.4.◓  Deploying version 20240717.4.◑  Deploying version 20240717.4.◒  Deploying version 20240717.4..◐  Deploying version 20240717.4..◓  Deploying version 20240717.4..◑  Deploying version 20240717.4..◒  Deploying version 20240717.4..◐  Deploying version 20240717.4..◓  Deploying version 20240717.4..◑  Deploying version 20240717.4..◒  Deploying version 20240717.4...◐  Deploying version 20240717.4...◓  Deploying version 20240717.4...◑  Deploying version 20240717.4...◒  Deploying version 20240717.4...◐  Deploying version 20240717.4...◓  Deploying version 20240717.4...◑  Deploying version 20240717.4...◒  Deploying version 20240717.4...◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  Deploying version 20240717.4◒  Deploying version 20240717.4◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  Deploying version 20240717.4◒  Deploying version 20240717.4◐  Deploying version 20240717.4.◓  Deploying version 20240717.4.◑  Deploying version 20240717.4.◒  Deploying version 20240717.4.◐  Deploying version 20240717.4.◓  Deploying version 20240717.4.◑  Deploying version 20240717.4.◒  Deploying version 20240717.4.◐  Deploying version 20240717.4..◓  Deploying version 20240717.4..◑  Deploying version 20240717.4..◒  Deploying version 20240717.4..◐  Deploying version 20240717.4..◓  Deploying version 20240717.4..◑  Deploying version 20240717.4..◒  Deploying version 20240717.4..◐  Deploying version 20240717.4...◓  Deploying version 20240717.4...◑  Deploying version 20240717.4...◒  Deploying version 20240717.4...◐  Deploying version 20240717.4...◓  Deploying version 20240717.4...◑  Deploying version 20240717.4...◒  Deploying version 20240717.4...◐  Deploying version 20240717.4...◓  Deploying version 20240717.4◑  Deploying version 20240717.4◒  Deploying version 20240717.4◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  Deploying version 20240717.4◒  Deploying version 20240717.4◐  Deploying version 20240717.4◓  Deploying version 20240717.4.◑  Deploying version 20240717.4.◒  Deploying version 20240717.4.◐  Deploying version 20240717.4.◓  Deploying version 20240717.4.◑  Deploying version 20240717.4.◒  Deploying version 20240717.4.◐  Deploying version 20240717.4.◓  Deploying version 20240717.4..◑  Deploying version 20240717.4..◒  Deploying version 20240717.4..◐  Deploying version 20240717.4..◓  Deploying version 20240717.4..◑  Deploying version 20240717.4..◒  Deploying version 20240717.4..◐  Deploying version 20240717.4..◓  Deploying version 20240717.4...◑  Deploying version 20240717.4...◒  Deploying version 20240717.4...◐  Deploying version 20240717.4...◓  Deploying version 20240717.4...◑  Deploying version 20240717.4...◒  Deploying version 20240717.4...◐  Deploying version 20240717.4...◓  Deploying version 20240717.4...◑  Deploying version 20240717.4◒  Deploying version 20240717.4◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  Deploying version 20240717.4◒  Deploying version 20240717.4◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  Deploying version 20240717.4.◒  Deploying version 20240717.4.◐  Deploying version 20240717.4.◓  Deploying version 20240717.4.◑  Deploying version 20240717.4.◒  Deploying version 20240717.4.◐  Deploying version 20240717.4.◓  Deploying version 20240717.4.◑  Deploying version 20240717.4..◒  Deploying version 20240717.4..◐  Deploying version 20240717.4..◓  Deploying version 20240717.4..◑  Deploying version 20240717.4..◒  Deploying version 20240717.4..◐  Deploying version 20240717.4..◓  Deploying version 20240717.4..◑  Deploying version 20240717.4...◒  Deploying version 20240717.4...◐  Deploying version 20240717.4...◓  Deploying version 20240717.4...◑  Deploying version 20240717.4...◒  Deploying version 20240717.4...◐  Deploying version 20240717.4...◓  Deploying version 20240717.4...◑  Deploying version 20240717.4...◒  Deploying version 20240717.4◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  Deploying version 20240717.4◒  Deploying version 20240717.4◐  Deploying version 20240717.4◓  Deploying version 20240717.4◑  20240717.4 image built, detecting deployed tasks◒  20240717.4 image built, detecting deployed tasks.◐  20240717.4 image built, detecting deployed tasks.◓  20240717.4 image built, detecting deployed tasks.◑  20240717.4 image built, detecting deployed tasks.◒  20240717.4 image built, detecting deployed tasks.◐  20240717.4 image built, detecting deployed tasks.◓  20240717.4 image built, detecting deployed tasks.◑  20240717.4 image built, detecting deployed tasks.◒  20240717.4 image built, detecting deployed tasks..◐  20240717.4 image built, detecting deployed tasks..◓  20240717.4 image built, detecting deployed tasks..◑  20240717.4 image built, detecting deployed tasks..◒  20240717.4 image built, detecting deployed tasks..◐  20240717.4 image built, detecting deployed tasks..◓  20240717.4 image built, detecting deployed tasks..◑  20240717.4 image built, detecting deployed tasks..◒  20240717.4 image built, detecting deployed tasks...◐  20240717.4 image built, detecting deployed tasks...◓  20240717.4 image built, detecting deployed tasks...◑  20240717.4 image built, detecting deployed tasks...◒  20240717.4 image built, detecting deployed tasks...◐  20240717.4 image built, detecting deployed tasks...◓  20240717.4 image built, detecting deployed tasks...◑  20240717.4 image built, detecting deployed tasks...◒  20240717.4 image built, detecting deployed tasks...◐  20240717.4 image built, detecting deployed tasks◓  20240717.4 image built, detecting deployed tasks◑  20240717.4 image built, detecting deployed tasks◒  20240717.4 image built, detecting deployed tasks◐  20240717.4 image built, detecting deployed tasks◓  20240717.4 image built, detecting deployed tasks◑  20240717.4 image built, detecting deployed tasks◒  20240717.4 image built, detecting deployed tasks◐  20240717.4 image built, detecting deployed tasks.◓  20240717.4 image built, detecting deployed tasks.◑  20240717.4 image built, detecting deployed tasks.◒  20240717.4 image built, detecting deployed tasks.◐  20240717.4 image built, detecting deployed tasks.◓  20240717.4 image built, detecting deployed tasks.◑  20240717.4 image built, detecting deployed tasks.◒  20240717.4 image built, detecting deployed tasks.◐  20240717.4 image built, detecting deployed tasks..◓  20240717.4 image built, detecting deployed tasks..◑  20240717.4 image built, detecting deployed tasks..◒  20240717.4 image built, detecting deployed tasks..◐  20240717.4 image built, detecting deployed tasks..◓  20240717.4 image built, detecting deployed tasks..◑  20240717.4 image built, detecting deployed tasks..◒  20240717.4 image built, detecting deployed tasks..◐  20240717.4 image built, detecting deployed tasks...◓  20240717.4 image built, detecting deployed tasks...◑  20240717.4 image built, detecting deployed tasks...◒  20240717.4 image built, detecting deployed tasks...◐  20240717.4 image built, detecting deployed tasks...◓  20240717.4 image built, detecting deployed tasks...◑  20240717.4 image built, detecting deployed tasks...◒  20240717.4 image built, detecting deployed tasks...◐  20240717.4 image built, detecting deployed tasks...◓  20240717.4 image built, detecting deployed tasks◑  20240717.4 image built, detecting deployed tasks◒  20240717.4 image built, detecting deployed tasks◐  20240717.4 image built, detecting deployed tasks◓  20240717.4 image built, detecting deployed tasks◑  20240717.4 image built, detecting deployed tasks◒  20240717.4 image built, detecting deployed tasks◐  20240717.4 image built, detecting deployed tasks◓  20240717.4 image built, detecting deployed tasks.◑  20240717.4 image built, detecting deployed tasks.◒  20240717.4 image built, detecting deployed tasks.◐  20240717.4 image built, detecting deployed tasks.◓  20240717.4 image built, detecting deployed tasks.◑  20240717.4 image built, detecting deployed tasks.◒  20240717.4 image built, detecting deployed tasks.◐  20240717.4 image built, detecting deployed tasks.◓  20240717.4 image built, detecting deployed tasks..◑  20240717.4 image built, detecting deployed tasks..◒  20240717.4 image built, detecting deployed tasks..◐  20240717.4 image built, detecting deployed tasks..◓  20240717.4 image built, detecting deployed tasks..◇  Deployment encountered an error. View deployment https://cloud.trigger.dev/projects/v3/proj_zbkgcyupelzxtkkoxhpz/deployments/rdhy2mxw
[25](https://github.com/studyspaceglobal/studyspace-monorepo/actions/runs/9970535527/job/27549644708#step:13:26)hX Error: @prisma/client did not initialize yet. Please run ""prisma generate"" and try to import it again.
Error: Process completed with exit code 1.
```

where the last 2 lines are,
```
Error: @prisma/client did not initialize yet. Please run ""prisma generate"" and try to import it again.
Error: Process completed with exit code 1.
```
  
  

### Reproduction repo

N/A

### To reproduce

Run
```
  - name: Deploy Trigger.dev
    working-directory: apps/nextjs
    env:
      TRIGGER_ACCESS_TOKEN: ${{ secrets.TRIGGER_ACCESS_TOKEN }}
    run: |
      npm run deploy:trigger-staging`
```

in a project that uses a Prisma client inside any Trigger.dev tasks or schedules.

### Additional information

_No response_",,
2411377894,1221,bug: Typescript typedef errors in v3 SDK,"### Provide environment information

  System:
    OS: macOS 12.7.5
    CPU: (10) arm64 Apple M1 Pro
    Memory: 75.05 MB / 32.00 GB
    Shell: 5.8.1 - /bin/zsh
  Binaries:
    Node: 20.7.0 - ~/.asdf/installs/nodejs/20.7.0/bin/node
    Yarn: 1.22.19 - ~/.asdf/installs/nodejs/20.7.0/bin/yarn
    npm: 10.1.0 - ~/.asdf/plugins/nodejs/shims/npm
    Watchman: 2024.04.08.00 - /opt/homebrew/bin/watchman

### Describe the bug

Using version `""@trigger.dev/sdk"": ""3.0.0-beta.48""`

When I import anything (like `task`: `import { task } from '@trigger.dev/sdk/v3';`) from the SDK, my Typescript compiler picks up errors in the SDK's Typedefs file ad `node_modules/@trigger.dev/sdk/dist/v3/index.d.ts`.

```
 npx tsc -noEmit

node_modules/@trigger.dev/sdk/dist/v3/index.d.ts:173:40 - error TS2536: Type 'K' cannot be used to index type 'TRunHandle extends RunHandle<infer THandleOutput> ? Omit<{ status: ""CANCELED"" | ""COMPLETED"" | ""FAILED"" | ""WAITING_FOR_DEPLOY"" | ""QUEUED"" | ""EXECUTING"" | ... 6 more ... | ""EXPIRED""; ... 23 more ...; expiredAt?: Date | undefined; }, ""output""> & { ...; } : Omit<...> & { ...; }'.

173 }) extends infer T ? { [K in keyof T]: (TRunHandle extends RunHandle<infer THandleOutput> ? Omit<{
                                           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
174     status: ""CANCELED"" | ""COMPLETED"" | ""FAILED"" | ""WAITING_FOR_DEPLOY"" | ""QUEUED"" | ""EXECUTING"" | ""REATTEMPTING"" | ""FROZEN"" | ""CRASHED"" | ""INTERRUPTED"" | ""SYSTEM_FAILURE"" | ""DELAYED"" | ""EXPIRED"";
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
...
270     output?: TRunHandle | undefined;
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
271 })[K]; } : never>;
    ~~~~~

node_modules/@trigger.dev/sdk/dist/v3/index.d.ts:898:63 - error TS2693: 'CreateEnvironmentVariableParams' only refers to a type, but is being used as a value here.

898 declare const envvars_CreateEnvironmentVariableParams: typeof CreateEnvironmentVariableParams;
                                                                  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

node_modules/@trigger.dev/sdk/dist/v3/index.d.ts:899:64 - error TS2693: 'ImportEnvironmentVariablesParams' only refers to a type, but is being used as a value here.

899 declare const envvars_ImportEnvironmentVariablesParams: typeof ImportEnvironmentVariablesParams;
                                                                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Found 3 errors in the same file, starting at: node_modules/@trigger.dev/sdk/dist/v3/index.d.ts:173
```


Here's my Typescript configuration

```
{
  ""ts-node"": {
    ""files"": true
  },
  ""files"": [""src/global.d.ts""],
  ""compilerOptions"": {
    ""target"": ""es6"",
    ""module"": ""commonjs"",
    ""rootDir"": ""./src"",
    ""outDir"": ""./dist"",
    ""esModuleInterop"": true,
    ""moduleResolution"": ""node"",
    ""strict"": true,
    ""noImplicitAny"": false,
    ""resolveJsonModule"": true
  },
  ""include"": [""src/**/*""],
  ""exclude"": [""./node_modules""]
}
```

### Reproduction repo

-

### To reproduce

Set up a Node project with the included Typescript config. Import something from the SDK.

### Additional information

Additionally when importing from the SDK, my linter cannot resolve the module, even though Typescript can. I get around that by disabling a rule. I'm not sure if this is related to the main issue.

```
// eslint-disable-next-line import/no-unresolved
import { logger, task } from '@trigger.dev/sdk/v3';
```

Error: `Unable to resolve path to module '@trigger.dev/sdk/v3'.     eslint(import/no-unresolved)`",,
2388291681,1196,[TRI-2840] Allow `TRIGGER_ACCESS_TOKEN` to be used with the dev command,"## Problem
Using the `TRIGGER_ACCESS_TOKEN` works with the deploy command, which is used in CI (like GitHub Actions).

That token is not currently read from for the `dev` command which means you can't do things like end-to-end tests.

## Solution

We need to read from the access token before we look at the auth config file.

We currently call `isLoggedIn` here: https://github.com/triggerdotdev/trigger.dev/blob/7976d924fb31dcbdcf4698cbbad0a189d799fc2d/packages/cli-v3/src/commands/dev.tsx#L113

But that doesn't use the access token.

Whereas the `login` function does: https://github.com/triggerdotdev/trigger.dev/blob/7976d924fb31dcbdcf4698cbbad0a189d799fc2d/packages/cli-v3/src/commands/login.ts#L78

We might be able to just call the `login` function instead of `isLoggedIn`?

<sub>[TRI-2840](https://linear.app/triggerdotdev/issue/TRI-2840/allow-trigger-access-token-to-be-used-with-the-dev-command)</sub>",,
2366798111,1174,[TRI-2755] v3 run log outputs with empty array inside objects aren't shown,"This task:

```ts
export const myTask = task({
  id: 'some-id',
  run: async () => {
    return {
      hooks: [],
    };
});
```

Has the correct output:

```json
{
  ""hooks"": [],
}
```

But in the log data/on the run page is shows just an empty object. This is a bug with the flattenAttributes/unflattenAttributes code we use with our OpenTelemetry pipeline.

<sub>[TRI-2755](https://linear.app/triggerdotdev/issue/TRI-2755/v3-run-log-outputs-with-empty-array-inside-objects-arent-shown)</sub>",,
2347742954,1161,feat: support cloudfront timeouts,"### Is your feature request related to a problem? Please describe.

A nextjs app hosted on cloudfront does work on with trigger.dev because it doesn't catch the 504 response codes.


https://open-next.js.org/

### Describe the solution you'd like to see

```patch
diff --git a/apps/webapp/app/models/endpoint.server.ts b/apps/webapp/app/models/endpoint.server.ts
index e5c1c21..649f86a 100644
--- a/apps/webapp/app/models/endpoint.server.ts
+++ b/apps/webapp/app/models/endpoint.server.ts
@@ -27,6 +27,7 @@ export function detectResponseIsTimeout(rawBody: string, response?: Response) {
 
   return (
     isResponseVercelTimeout(response) ||
+    isResponseCloudfrontTimeout(response) ||
     isResponseDenoDeployTimeout(rawBody, response) ||
     isResponseCloudflareTimeout(rawBody, response)
   );
@@ -50,3 +51,7 @@ function isResponseVercelTimeout(response: Response) {
 function isResponseDenoDeployTimeout(rawBody: string, response: Response) {
   return response.status === 502 && rawBody.includes(""TIME_LIMIT"");
 }
+
+function isResponseCloudfrontTimeout(response: Response) {
+  return response.status === 504 && typeof response.headers.get(""x-amz-cf-id"") === ""string"";
+}
```


### Describe alternate solutions

None

### Additional information

Example Response from cloudfront

```json
{
  ""status"": 504,
  ""runId"": ""[REDACTED]"",
  ""endpoint"": ""https://[REDACTED]/api/trigger"",
  ""headers"": {
    ""connection"": ""keep-alive"",
    ""content-length"": ""1033"",
    ""content-type"": ""text/html"",
    ""date"": ""Wed, 12 Jun 2024 03:30:51 GMT"",
    ""server"": ""CloudFront"",
    ""via"": ""1.1 [REDACTED].cloudfront.net (CloudFront)"",
    ""x-amz-cf-id"": ""[REDCATED]"",
    ""x-amz-cf-pop"": ""[REDACTED]"",
    ""x-cache"": ""Error from cloudfront""
  },
  ""rawBody"": ""<!DOCTYPE HTML PUBLIC \""-//W3C//DTD HTML 4.01 Transitional//EN\"" \""http://www.w3.org/TR/html4/loose.dtd\"">\n<HTML><HEAD><META HTTP-EQUIV=\""Content-Type\"" CONTENT=\""text/html; charset=iso-8859-1\"">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>504 ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\""1px\"">\nCloudFront attempted to establish a connection with the origin, but either the attempt failed or the origin closed the connection.\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\""all\"">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\""all\"">\n<HR noshade size=\""1px\"">\n<PRE>\nGenerated by cloudfront (CloudFront)\nRequest ID: [REDACTED]\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>"",
  ""timestamp"": ""2024-06-12T03:30:51.138Z"",
  ""name"": ""webapp"",
  ""message"": ""Endpoint responded with non-200 status code"",
  ""level"": ""debug""
}

```",,
2346042491,1158,bug: Error when starting trigger.dev with docker-compose connecting to supabase project,"### Provide environment information

```
  System:
    OS: macOS 14.1
    CPU: (8) arm64 Apple M3
    Memory: 2.66 GB / 24.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 18.16.0 - ~/.nvm/versions/node/v18.16.0/bin/node
    Yarn: 1.22.21 - /opt/homebrew/bin/yarn
    npm: 9.5.1 - ~/.nvm/versions/node/v18.16.0/bin/npm
    pnpm: 8.8.0 - ~/.nvm/versions/node/v18.16.0/bin/pnpm
    bun: 1.1.4 - ~/.nvm/versions/node/v18.16.0/bin/bun
```

### Describe the bug

When trying to start the Trigger.dev service using Docker and docker-compose, an error occurs during the deployment of Prisma migrations. The error mentions that there are failed migrations and missing columns in the database.

### Reproduction repo

No reproduction repository is available, but it can be reproduced using the following configuration files and commands.

### To reproduce

1. Run the following command to pull the Docker image:

`docker pull ghcr.io/triggerdotdev/trigger.dev:main`

2. Use the following docker-compose.yml file using valids params for POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB, DATABASE_HOST:

```
version: ""3.8""

services:
  triggerdotdev:
    image: ghcr.io/triggerdotdev/trigger.dev:main
    container_name: triggerdotdev
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - 3030:3030
```

3. Use the following .env file:

```
LOGIN_ORIGIN=http://localhost:3030
APP_ORIGIN=http://localhost:3030
PORT=3030
REMIX_APP_PORT=3030

# Encryption key that will be used to encrypt magic link tokens
MAGIC_LINK_SECRET=e7bbbffd751b749f4710d529c6964d5d
# Encryption key that will be used to encrypt session cookies
SESSION_SECRET=7acbf2cf1bdb5b43b306bafa03780f9a
# Must be a random 16 byte hex string. You can generate an encryption key by running `openssl rand -hex 16` in your terminal
# WARNING: YOU MUST SET THIS TO A RANDOM VALUE IN PRODUCTION
ENCRYPTION_KEY=8c8e8cec45aeeaf0e01984350f73e1b9

POSTGRES_USER=******
POSTGRES_PASSWORD=******
POSTGRES_DB=******
DATABASE_HOST=******
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${DATABASE_HOST}/${POSTGRES_DB}?schema=triggerdotdev

# This sets the URL used for direct connections to the database and should only be needed in limited circumstances
# See: https://www.prisma.io/docs/reference/api-reference/prisma-schema-reference#fields:~:text=the%20shadow%20database.-,directUrl,-No
DIRECT_URL=${DATABASE_URL}

# Github sign in OAUTH client id and secret (Optional)
# AUTH_GITHUB_CLIENT_ID=
# AUTH_GITHUB_CLIENT_SECRET=

# E-mail settings, ensure the FROM_EMAIL matches what you setup with Resend.com.
# If these are not set, emails will be printed to the console.
# FROM_EMAIL=
# REPLY_TO_EMAIL=
# RESEND_API_KEY=

NODE_ENV=production
RUNTIME_PLATFORM=docker-compose
```


4. Run the command:

`docker-compose up`

### Additional information

```
triggerdotdev  | + [ -n ******]
triggerdotdev  | + scripts/wait-for-it.sh  ****** -- echo database is up
triggerdotdev  | Unknown argument: ******
triggerdotdev  | Usage:
triggerdotdev  |   scripts/wait-for-it.sh host:port|url [-t timeout] [-- command args]
triggerdotdev  |   -q | --quiet                        Do not output any status messages
triggerdotdev  |   -t TIMEOUT | --timeout=timeout      Timeout in seconds, zero for no timeout
triggerdotdev  |   -- COMMAND ARGS                     Execute command with args after the test finishes
triggerdotdev  | + pnpm --filter @trigger.dev/database db:migrate:deploy
triggerdotdev  | 
triggerdotdev  | > @trigger.dev/database@0.0.1 db:migrate:deploy /triggerdotdev/packages/database
triggerdotdev  | > prisma migrate deploy
triggerdotdev  | 
triggerdotdev  | Prisma schema loaded from prisma/schema.prisma
triggerdotdev  | Datasource ""db"": PostgreSQL database ""postgres"", schema ""triggerdotdev"" at ******
triggerdotdev  | 
triggerdotdev  | 508 migrations found in prisma/migrations
triggerdotdev  | 
triggerdotdev  | Error: P3009
triggerdotdev  | 
triggerdotdev  | migrate found failed migrations in the target database, new migrations will not be applied. Read more about how to resolve migration issues in a production database: https://pris.ly/d/migrate-resolve
triggerdotdev  | The `20240130165343_add_composite_index_to_job_run_for_job_id_and_created_at` migration started at 2024-06-11 09:59:01.840235 UTC failed
triggerdotdev  | 
triggerdotdev  | 
triggerdotdev  | /triggerdotdev/packages/database:
triggerdotdev  |  ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  @trigger.dev/database@0.0.1 db:migrate:deploy: `prisma migrate deploy`
triggerdotdev  | Exit status 1
triggerdotdev  | + cp packages/database/prisma/schema.prisma apps/webapp/prisma/
triggerdotdev  | + cp node_modules/@prisma/engines/libquery_engine-linux-arm64-openssl-1.1.x.so.node apps/webapp/prisma/
triggerdotdev  | + pnpm --filter webapp db:seed
triggerdotdev  | 
triggerdotdev  | > webapp@1.0.0 db:seed /triggerdotdev/apps/webapp
triggerdotdev  | > node prisma/seed.js
triggerdotdev  | 
triggerdotdev  | 🔌 setting up prisma client to postgresql://******@******/******?schema=triggerdotdev&connection_limit=10&pool_timeout=60
triggerdotdev  | 🔌 prisma client connected
triggerdotdev  | 🔌 No database replica, using the regular client
triggerdotdev  | prisma:info Starting a postgresql pool with 10 connections.
triggerdotdev  | Upserting auth method airtable.oauth2
triggerdotdev  | Upserting auth method github.oauth2
triggerdotdev  | Upserting auth method linear.oauth2
triggerdotdev  | Upserting auth method slack.oauth2Bot
triggerdotdev  | Upserting auth method slack.oauth2User
triggerdotdev  | Upserting auth method supabase-management.oauth2
triggerdotdev  | Running data migration 2023-09-27-AddStagingEnvironments
triggerdotdev  | prisma:error 
triggerdotdev  | Invalid `prisma.project.findMany()` invocation:
triggerdotdev  | 
triggerdotdev  | 
triggerdotdev  | The column `Project.deletedAt` does not exist in the current database.
triggerdotdev  | PrismaClientKnownRequestError: 
triggerdotdev  | Invalid `prisma.project.findMany()` invocation:
triggerdotdev  | 
triggerdotdev  | 
triggerdotdev  | The column `Project.deletedAt` does not exist in the current database.
triggerdotdev  |     at Cn.handleRequestError (/triggerdotdev/apps/webapp/prisma/seed.js:123:6809)
triggerdotdev  |     at Cn.handleAndLogRequestError (/triggerdotdev/apps/webapp/prisma/seed.js:123:6198)
triggerdotdev  |     at Cn.request (/triggerdotdev/apps/webapp/prisma/seed.js:123:5918)
triggerdotdev  |     at async d (/triggerdotdev/apps/webapp/prisma/seed.js:128:9968)
triggerdotdev  |     at async /triggerdotdev/apps/webapp/prisma/seed.js:632:90313
triggerdotdev  |     at async Proxy._transactionWithCallback (/triggerdotdev/apps/webapp/prisma/seed.js:128:8631)
triggerdotdev  |     at async ny (/triggerdotdev/apps/webapp/prisma/seed.js:632:90028)
triggerdotdev  |     at async iy (/triggerdotdev/apps/webapp/prisma/seed.js:632:89993)
triggerdotdev  |     at async ly (/triggerdotdev/apps/webapp/prisma/seed.js:632:90855) {
triggerdotdev  |   code: 'P2022',
triggerdotdev  |   clientVersion: '5.4.1',
triggerdotdev  |   meta: { column: 'Project.deletedAt' }
triggerdotdev  | }
triggerdotdev  | + cd /triggerdotdev/apps/webapp
triggerdotdev  | + NODE_PATH=/triggerdotdev/node_modules/.pnpm/node_modules exec dumb-init node --max-old-space-size=8192 ./build/server.js
triggerdotdev  | 🔌 setting up prisma client to postgresql://******@******/postgres?schema=triggerdotdev&connection_limit=10&pool_timeout=60
triggerdotdev  | 🔌 prisma client connected
triggerdotdev  | 🔌 No database replica, using the regular client
triggerdotdev  | 🔦 Tracer: Logger exporter enabled (sampling = 0.05)
triggerdotdev  | Could not initialize MarQS because process.env.REDIS_HOST and process.env.REDIS_PORT are required to be set. Trigger.dev v3 will not work without this.
triggerdotdev  | /triggerdotdev/apps/webapp/build/index.js:14414
triggerdotdev  |     throw new Error(
triggerdotdev  |     ^
triggerdotdev  | 
triggerdotdev  | Error: Could not initialize auto-increment counter because process.env.REDIS_HOST and process.env.REDIS_PORT are required to be set. 
triggerdotdev  |     at getAutoIncrementCounter (/triggerdotdev/apps/webapp/build/index.js:14414:11)
triggerdotdev  |     at singleton (/triggerdotdev/apps/webapp/build/index.js:3073:84)
triggerdotdev  |     at Object.<anonymous> (/triggerdotdev/apps/webapp/build/index.js:14411:27)
triggerdotdev  |     at Module._compile (node:internal/modules/cjs/loader:1376:14)
triggerdotdev  |     at Module._extensions..js (node:internal/modules/cjs/loader:1435:10)
triggerdotdev  |     at Module.load (node:internal/modules/cjs/loader:1207:32)
triggerdotdev  |     at Module._load (node:internal/modules/cjs/loader:1023:12)
triggerdotdev  |     at Module.require (node:internal/modules/cjs/loader:1235:19)
triggerdotdev  |     at require (node:internal/modules/helpers:176:18)
triggerdotdev  |     at Object.<anonymous> (/triggerdotdev/apps/webapp/build/server.js:37:15)
triggerdotdev  | 
triggerdotdev  | Node.js v20.11.1
triggerdotdev exited with code 1
```",,
2342155710,1156,[TRI-2668] logger.trace should have the output as attributes,"If you return data from `logger.trace` it should appear in the OTEL attributes from the span.

```ts
const bar = await logger.trace('key', async() => { return foo });
```

The same as we do for attempts.

<sub>[TRI-2668](https://linear.app/triggerdotdev/issue/TRI-2668/loggertrace-should-have-the-output-as-attributes)</sub>",,
2309820652,1118,bug: Missing Adaptor for Shopify Integration,"### Provide environment information

  System:
    OS: Linux 5.15 Ubuntu 22.04.4 LTS 22.04.4 LTS (Jammy Jellyfish)
    CPU: (16) x64 AMD Ryzen 7 3800X 8-Core Processor
    Memory: 4.98 GB / 7.73 GB
    Container: Yes
    Shell: 5.1.16 - /bin/bash
  Binaries:
    Node: 20.9.0 - /run/user/1000/fnm_multishells/360_1716363433225/bin/node
    Yarn: 1.22.21 - /run/user/1000/fnm_multishells/360_1716363433225/bin/yarn
    npm: 10.1.0 - /run/user/1000/fnm_multishells/360_1716363433225/bin/npm
    pnpm: 9.1.2 - ~/.local/share/pnpm/pnpm

### Describe the bug

There is an issue with the current shopify integration version `beta.33` where there is no adaptor implementation. This issue happens both on the cloud enviroment and self hosted (fly.io - docker image) version.

![image](https://github.com/triggerdotdev/trigger.dev/assets/55840806/f982ae56-eeb8-491d-b5aa-7cce577d6617)

Patching the adaptor with pnpm fixes this issue

<details>
<summary>Patch File</summary>

```js
diff --git a/dist/index.mjs b/dist/index.mjs
index 8ac687e936ae2bf87663942406bf927a1e9075b4..0d8e7e9bce9238d49c61f07e974d36ebb45baf5f 100644
--- a/dist/index.mjs
+++ b/dist/index.mjs
@@ -1,3 +1,4 @@
+import '@shopify/shopify-api/adapters/node';
 import { WebhookTrigger, WebhookSource, verifyRequestSignature, retry, slugifyId } from '@trigger.dev/sdk';
 import { ShopifyError, HttpRetriableError, HttpThrottlingError, shopifyApi, LATEST_API_VERSION, LogSeverity } from '@shopify/shopify-api';
 import { restResources } from '@shopify/shopify-api/rest/admin/2023-10';
```

</details>

### Reproduction repo

https://cloud.trigger.dev/orgs/webified-994c/projects/sz-erp-QAr9/jobs/webhook.register.shopify-aea7b74/runs/clwgmgl4edhqhn6305yh861tc/trigger

### To reproduce

Example run on the cloud instance:
https://cloud.trigger.dev/orgs/webified-994c/projects/sz-erp-QAr9/jobs/webhook.register.shopify-aea7b74/runs/clwgmgl4edhqhn6305yh861tc/trigger


### Additional information

More info about shopify js runtime adaptors can be found [here](https://github.com/Shopify/shopify-app-js/tree/main/packages/apps/shopify-api#readme).",,
2304334446,1112,feat: V3 - Add a `getEnvVars` function,"### Is your feature request related to a problem? Please describe.

No

### Describe the solution you'd like to see

A function that a user can define called `getEnvVars` in the config. This function would be run on `deploy` (with `process.env.NODE_ENV === 'production'`  and `dev`. Whatever the function returns is used as env vars for that deployment

Example function:

```js
async function getEnvVars() {
  if (process.env.NODE_ENV === 'development') {
    return process.env // i use direnv to load env vars, this would expose those to trigger
  }
  
  const vars = await infisicalSDK.getEnvVars() // fake function, can be any third party service
  return vars
}
```

### Describe alternate solutions

N/A

### Additional information

https://discord.com/channels/1066956501299777596/1222172315152945283/1234572031803265166",,
2246430433,1035,bug: Broken installation following quick start steps,"### Provide environment information

```
  System:
    OS: Linux 5.15 Ubuntu 22.04.2 LTS 22.04.2 LTS (Jammy Jellyfish)
    CPU: (24) x64 12th Gen Intel(R) Core(TM) i9-12900HX
    Memory: 6.74 GB / 15.47 GB
    Container: Yes
    Shell: 5.1.16 - /bin/bash
  Binaries:
    Node: 18.16.0 - ~/.nvm/versions/node/v18.16.0/bin/node
    npm: 9.5.1 - ~/.nvm/versions/node/v18.16.0/bin/npm
```

### Describe the bug

After following the [v3 quick start guide](https://trigger.dev/docs/v3/quick-start) in an existing next.js app and setting up a call to trigger a job, I get two different kinds of errors when I run the next app:

1. **Broken OpenTelemetry**
```
 ⚠ ./node_modules/@opentelemetry/instrumentation/build/src/platform/node/instrumentation.js
Critical dependency: the request of a dependency is an expression

Import trace for requested module:
./node_modules/@opentelemetry/instrumentation/build/src/platform/node/instrumentation.js
./node_modules/@opentelemetry/instrumentation/build/src/platform/node/index.js
./node_modules/@opentelemetry/instrumentation/build/src/platform/index.js
./node_modules/@opentelemetry/instrumentation/build/src/index.js
./node_modules/@trigger.dev/core/dist/v3/index.mjs
./node_modules/@trigger.dev/sdk/dist/v3/index.mjs
./trigger/some-job.ts
./app/api/…/route.ts

./node_modules/@opentelemetry/instrumentation/build/src/platform/node/instrumentation.js
```

These can errors can be silenced with the workaround [posted here](https://github.com/open-telemetry/opentelemetry-js/issues/4173#issuecomment-1822938936), but it's unclear to me whether there's actually a problem.

2. **Broken invocations**
  Trying to invoke a Trigger job results in an error:
```
 ⚠ ./node_modules/engine.io-client/node_modules/ws/lib/buffer-util.js
Module not found: Can't resolve 'bufferutil' in './node_modules/engine.io-client/node_modules/ws/lib'

Import trace for requested module:
./node_modules/engine.io-client/node_modules/ws/lib/buffer-util.js
./node_modules/engine.io-client/node_modules/ws/lib/sender.js
./node_modules/engine.io-client/node_modules/ws/wrapper.mjs
./node_modules/engine.io-client/build/esm-debug/transports/websocket-constructor.js
./node_modules/engine.io-client/build/esm-debug/index.js
./node_modules/socket.io-client/build/esm-debug/url.js
./node_modules/socket.io-client/build/esm-debug/index.js
./node_modules/@trigger.dev/core/dist/v3/index.mjs
./node_modules/@trigger.dev/sdk/dist/v3/index.mjs
./trigger/some-job.ts
./app/api/…/route.ts

./node_modules/engine.io-client/node_modules/ws/lib/validation.js
Module not found: Can't resolve 'utf-8-validate' in './node_modules/engine.io-client/node_modules/ws/lib'

Import trace for requested module:
./node_modules/engine.io-client/node_modules/ws/lib/validation.js
./node_modules/engine.io-client/node_modules/ws/lib/sender.js
./node_modules/engine.io-client/node_modules/ws/wrapper.mjs
./node_modules/engine.io-client/build/esm-debug/transports/websocket-constructor.js
./node_modules/engine.io-client/build/esm-debug/index.js
./node_modules/socket.io-client/build/esm-debug/url.js
./node_modules/socket.io-client/build/esm-debug/index.js
./node_modules/@trigger.dev/core/dist/v3/index.mjs
./node_modules/@trigger.dev/sdk/dist/v3/index.mjs
./trigger/some-job.ts
./app/api/…/route.ts
```

Running `npm install bufferutil utf-8-validate` seems to solve the problem.

### Reproduction repo

-

### To reproduce

In an existing next.js app, follow the steps in the [quick start guide](https://trigger.dev/docs/v3/quick-start).  Specifically, `npx trigger.dev@beta init`.

Occurred with `@trigger.dev/sdk` `3.0.0-beta.12`.

### Additional information

_No response_",,
2242089730,1031,bug: Request with GET/HEAD method cannot have body.,"### Provide environment information

```shell
System:
    OS: macOS 14.4.1
    CPU: (10) arm64 Apple M2 Pro
    Memory: 571.42 MB / 32.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 20.12.1 - ~/Library/pnpm/node
    Yarn: 1.22.22 - /opt/homebrew/bin/yarn
    npm: 10.5.0 - ~/Library/pnpm/npm
    pnpm: 8.15.4 - ~/Library/pnpm/pnpm
    bun: 1.1.2 - /opt/homebrew/bin/bun
```

### Describe the bug

I try to access the trigger url from my server: http://localhost:3000/api/trigger
I know it does not support GET request for the api, but Is there any way that make the error does not sound like `Internal error`?

### Reproduction repo

N/A

### To reproduce

Create a new project and deploy with pages folder (nextjs 12). I am using trigger v2

`pages/api/trigger.tsx`

```tsx
import { createPagesRoute } from ""@trigger.dev/nextjs"";
import { trigger } from ""@utils/trigger"";

import ""@jobs/index"";

// this route is used to send and receive data with Trigger.dev
const { handler, config } = createPagesRoute(trigger);

export { config };
export default handler;
```

### Additional information

_No response_",,
2235097001,1017,[TRI-2209] CLI init: If there's no `include` in the `tsconfig.ts` file then don't add `trigger.config.ts` to it (v3),"If you don't have `include` in your `tsconfig.json` TypeScript includes all TypeScript files inside the project directory.

Currently our CLI adds `trigger.config.ts` to `include` always.

```json
{
  ""extends"": ""@tsconfig/node18/tsconfig.json"",
  ""compilerOptions"": {
    ""module"": ""esnext"",
    ""moduleResolution"": ""node"",
    ""resolveJsonModule"": true,
    ""jsx"": ""preserve"",
    ""noUncheckedIndexedAccess"": true
  },
  ""include"": [""trigger.config.ts""] // <= this is the newly added line
}
```

This breaks TypeScript for every other files because now they don't match anymore.

## Fix
If there's no existing include then don't add `trigger.config.ts`.


<sub>[TRI-2209](https://linear.app/triggerdotdev/issue/TRI-2209/cli-init-if-theres-no-include-in-the-tsconfigts-file-then-dont-add)</sub>",,
2235077555,1016,[TRI-2208] Bulk import environment variables (v3),"The ability to copy+paste a load of environment variables at once.

Important considerations
- We have multiple environments, so you'll want to select an environment (or possibly multiple? Possibly a bit weird given they're normally different across environments).
- What should we do if there's an existing env var in that environment with the same key? Just override? Or possibly it should have a red warning next to it so you can choose to remove it before you confirm?

<sub>[TRI-2208](https://linear.app/triggerdotdev/issue/TRI-2208/bulk-import-environment-variables-v3)</sub>",,
2235066778,1015,"[TRI-2207] If you hit the API rate limit, the estimate of when it will retry is incorrect","Possible the values are in nanoseconds or something. It's using the Upstash RateLimit package (but attached to regular Redis). Code here: [https://github.com/triggerdotdev/trigger.dev/blob/a5aed0d1395814234ff25347c43b0f71f4a15ab2/apps/webapp/app/services/apiRateLimit.server.ts#L166](https://github.com/triggerdotdev/trigger.dev/blob/a5aed0d1395814234ff25347c43b0f71f4a15ab2/apps/webapp/app/services/apiRateLimit.server.ts#L166)

![CleanShot 2024-04-10 at 09 42 32](https://uploads.linear.app/80a884b1-f84c-49d6-91db-07a391663d20/d8259a4c-d9c9-4b9d-a5ba-8525ebc714d1/2f8b8c5e-a7d2-47e2-b21a-3a586602a3e5?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzgwYTg4NGIxLWY4NGMtNDlkNi05MWRiLTA3YTM5MTY2M2QyMC9kODI1OWE0Yy1kOWM5LTRiOWQtYTViYS04NTI1ZWJjNzE0ZDEvMmY4YjhjNWUtYTdkMi00N2UyLWIyMWEtM2E1ODY2MDJhM2U1IiwiaWF0IjoxNzEyNzM4Njg0LCJleHAiOjE3MTI4MjUwODR9.FQ1ZLrJ97cMoeCV_EPbcvrc6pFwIQ0CQkKXMHES6Z5U)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-2207](https://linear.app/triggerdotdev/issue/TRI-2207/if-you-hit-the-api-rate-limit-the-estimate-of-when-it-will-retry-is)</sub>",,
2177414538,935,[TRI-2048] Better handle `fetch` throwing errors in our ApiClient,"As you can see in the code below, we aren't handling any thrown errors by fetch:

https://github.com/triggerdotdev/trigger.dev/blob/5d78bba5e3fda2668bbd1d3d67f8ba4c4479c559/packages/trigger-sdk/src/apiClient.ts#L888

This can lead to issues when the fetch times out and throws an error. We should fix this and also investigate which other errors can be thrown and handle those with retries (if it makes sense).

<sub>[TRI-2048](https://linear.app/triggerdotdev/issue/TRI-2048/better-handle-fetch-throwing-errors-in-our-apiclient)</sub>",,
2175571258,930,bug: `TriggerProvider` throws error in pages directory,"### Provide environment information

```sh
System:
    OS: macOS 14.2.1
    CPU: (12) arm64 Apple M2 Max
    Memory: 7.36 GB / 64.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 20.8.0 - ~/.pkgx/nodejs.org/v20.8.0/bin/node
    npm: 10.1.0 - ~/.pkgx/npmjs.com/v10.1.0/bin/npm
  Managers:
    pip3: 23.2.1 - ~/.pkgx/pip.pypa.io/v23.2.1/bin/pip3
    RubyGems: 3.0.3.1 - /usr/bin/gem
  Utilities:
    Make: 3.81 - /usr/bin/make
    GCC: 15.0.0 - /usr/bin/gcc
    Git: 2.42.0 - /Users/mfts/.pkgx/git-scm.org/v2.42.0/bin/git
    Clang: 15.0.0 - /usr/bin/clang
    Curl: 8.3.0 - /Users/mfts/.pkgx/curl.se/v8.3.0/bin/curl
  Servers:
    Apache: 2.4.56 - /usr/sbin/apachectl
  Virtualization:
    Docker: 24.0.6 - /usr/local/bin/docker
  IDEs:
    VSCode: 1.87.0 - /usr/local/bin/code
    Vim: 9.0 - /usr/bin/vim
    Xcode: /undefined - /usr/bin/xcodebuild
  Languages:
    Bash: 3.2.57 - /bin/bash
    Perl: 5.38.0 - /Users/mfts/.pkgx/perl.org/v5.38.0/bin/perl
    Python: 3.11.6 - /Users/mfts/.pkgx/python.org/v3.11.6/bin/python
    Python3: 3.11.6 - /Users/mfts/.pkgx/python.org/v3.11.6/bin/python3
    Ruby: 2.6.10 - /usr/bin/ruby
  Databases:
    PostgreSQL: 15.6 - /Applications/Postgres.app/Contents/Versions/latest/bin/postgres
    SQLite: 3.39.2 - /Users/mfts/.pkgx/sqlite.org/v3.43.1/bin/sqlite3
  Browsers:
    Chrome: 122.0.6261.112
    Safari: 17.2.1
```

### Describe the bug

Getting an error when adding `TriggerProvider` to my `pages/_app.tsx` page 

```sh
 ⨯ /Users/mfts/dev/mfts/papermark-main/node_modules/@trigger.dev/react/dist/TriggerProvider.js:2
import React from ""react"";
^^^^^^

SyntaxError: Cannot use import statement outside a module
    at internalCompileFunction (node:internal/vm:73:18)
    at wrapSafe (node:internal/modules/cjs/loader:1153:20)
    at Module._compile (node:internal/modules/cjs/loader:1205:27)
    at Module._extensions..js (node:internal/modules/cjs/loader:1295:10)
    at Module.load (node:internal/modules/cjs/loader:1091:32)
    at Module._load (node:internal/modules/cjs/loader:938:12)
    at Module.require (node:internal/modules/cjs/loader:1115:19)
    at mod.require (/Users/mfts/dev/mfts/papermark-main/node_modules/next/dist/server/require-hook.js:65:28)
    at require (node:internal/modules/helpers:130:18)
    at Object.<anonymous> (/Users/mfts/dev/mfts/papermark-main/node_modules/@trigger.dev/react/dist/index.cjs:18:25)
    at Module._compile (node:internal/modules/cjs/loader:1241:14)
    at Module._extensions..js (node:internal/modules/cjs/loader:1295:10)
    at Module.load (node:internal/modules/cjs/loader:1091:32)
    at Module._load (node:internal/modules/cjs/loader:938:12)
    at Module.require (node:internal/modules/cjs/loader:1115:19) {
  page: '/documents'
}
```

### Reproduction repo

github.com/mfts/papermark

### To reproduce

```tsx
// pages/_app.tsx

import { TriggerProvider } from ""@trigger.dev/react""
...

export default function App({
  Component,
  pageProps: { session, ...pageProps },
}: AppProps<{ session: Session }>) {
  return (
      <SessionProvider session={session}>
              <main className={inter.className}>
                    <TeamProvider>
                      <TriggerProvider publicApiKey={""...""}>
                        <Component {...pageProps} />
                      </TriggerProvider>
                    </TeamProvider>
              </main>
      </SessionProvider>
  ...
  );
}      


### Additional information

_No response_",,
2153929057,912,[TRI-1996] A failed run isn't resuming properly from the UI,"When you ""Rerun"" job from the UI you get given two options IF the run has failed.

![CleanShot 2024-02-26 at 11 17 26@2x](https://github.com/triggerdotdev/trigger.dev/assets/10635986/ea372618-2072-42ec-8c2e-4ee47ed6ba69)

""Run again"" works as designed, it creates a new run with the same payload.

But ""Retry Job run"" should continue the run and retry failed tasks. 

## To reproduce
1. Run this job, it will fail where the error is thrown.

```ts
client.defineJob({
  id: ""test"",
  name: ""test error handling"",
  version: ""0.0.1"",
  trigger: eventTrigger({
    name: ""test.event"",
  }),
  run: async (payload, io, ctx) => {
    const result = await io.runTask(""todo"", async (client) => {
      throw new Error(""I'm broken"");
      await io.logger.info(""I fixed it"");
    });

    await io.logger.info(""Afterwards"");
  },
});
```

2. Modify the code by commenting out the thrown error.
3. Press the ""Retry Job run"" button in the UI.
4. Notice that the run fails again with the error cached.

## What might be happening?
- Check that errors are not being cached in `runTask`. Only successful results should be.
- Check that the `ContinueRunService` is working correctly.

<sub>[TRI-1996](https://linear.app/triggerdotdev/issue/TRI-1996/a-failed-run-isnt-resuming-properly-from-the-ui)</sub>",,
2151718729,909,feat: support async `io.runTask` error callback,"### Is your feature request related to a problem? Please describe.

When `io.runTask` runs, it has an `onError` callback option. This is great!
But I have some `async` logic that I would like to run in this error callback. This is currently not supported since the error callback cannot return a promise.

### Describe the solution you'd like to see

Update `RunTaskErrorCallback` type to allow returning a promise, and update `io.runTask` to `await onError(error, task, this)`

### Describe alternate solutions

Do nothing and tell developers to `try`/`catch` inside the `io.runTask` (where it is `async`):

```
io.runTask(
  ""name"",
  async (task) => {
    try {
      // ...
    } catch (error) {
      await sendErrorNotification(payload)
    }
  },
)
```

### Additional information

_No response_",,
2128987044,897,bug: Replicate example keeps waiting,"### Provide environment information

```bash
  System:
    OS: macOS 14.1.2
    CPU: (8) arm64 Apple M1 Pro
    Memory: 57.72 MB / 16.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 20.10.0 - /usr/local/bin/node
    npm: 10.2.3 - /usr/local/bin/npm
```

### Describe the bug

Hi,

I'm currently running the example provided at Replicate integration [docs](https://trigger.dev/docs/integrations/apis/replicate#usage) and the image generation task keeps waiting for the result even though I can see the generated result in Replicate dashboard.

<img width=""1285"" alt=""image"" src=""https://github.com/triggerdotdev/trigger.dev/assets/1565547/676b8183-af39-4a23-9f95-b0b1f50a6a99"">


### Reproduction repo

https://trigger.dev/docs/integrations/apis/replicate#usage

### To reproduce

I have written a simple job as follows:

```ts
import { eventTrigger } from ""@trigger.dev/sdk"";
import { Replicate } from ""@trigger.dev/replicate"";
import { client } from ""@/trigger"";
import z from ""zod"";

const replicate = new Replicate({
  id: ""replicate"",
  apiKey: process.env.REPLICATE_API_KEY!,
});

client.defineJob({
  id: ""replicate-create-prediction"",
  name: ""Replicate - Create Prediction"",
  version: ""0.1.0"",
  integrations: { replicate },
  trigger: eventTrigger({
    name: ""replicate.predict"",
    schema: z.object({
      prompt: z
      .string()
      .default(""rick astley riding a harley through post-apocalyptic miami""),
      version: z
      .string()
      .default(""af1a68a271597604546c09c64aabcd7782c114a63539a4a8d14d1eeda5630c33""),
    }),
  }),
  run: async (payload, io, ctx) => {
    return io.replicate.predictions.createAndAwait(""await-prediction"", {
      version: payload.version,
      input: { prompt: payload.prompt },
    });
  },
});
```

### Additional information

_No response_",,
2125554587,889,feat: runTaskSuperjson,"### Is your feature request related to a problem? Please describe.

When running custom task with `io.runTask` the return value of the callback is piped through `JSON.parse(JSON.stringify(value))`. I understand that this is necessary to serialize the value for caching. In Typescript this is also reflected by doing `JSON<T>` with the return-type.

For me, this was cumbersome as I wanted to pass object with for example Dates and DX would fall apart.

### Describe the solution you'd like to see

I created the following function to serialize the value with [superjson](https://www.npmjs.com/package/superjson). Superjson is similar to JSON.stringify and JSON.parse but allow for dates etc to survive.
For me and my team this function solves the Issue, but maybe there is way for this to end up directly in the `@trigger.dev/sdk`:

```ts
import { IO, RunTaskOptions } from '@trigger.dev/sdk'
import superjson from 'superjson'

type ServerTask = Parameters<Parameters<IO['runTask']>[1]>[0]

export const runTaskSuperjson = async <T>(
  io: IO,
  cacheKey: string,
  callback: (task: ServerTask, io: IO) => Promise<T>,
  options?: RunTaskOptions,
) => {
  const encodedResponse = await io.runTask(
    cacheKey,
    async (task, io) => {
      const response = await callback(task, io)
      const encoded = superjson.stringify(response)
      return encoded
    },
    options,
  )
  const response = superjson.parse<T>(encodedResponse)
  return response
}
```

### Describe alternate solutions

Alternatively this little helper function could be hinted at in the docs.

### Additional information

_No response_",,
2123157692,886,"Self-hosting migration fails if not using the default ""public"" schema",https://github.com/triggerdotdev/trigger.dev/blob/336029b8428a826bfc92932a61653979a0e1fb79/apps/webapp/app/presenters/JobListPresenter.server.ts#L125,,
2120905239,884,[TRI-1923] React hooks should return basic metadata about the Job,"If you want to build a UI that shows runs across multiple jobs it's difficult because the hooks return no info about the job.

I suggest we return the job ""id"" from them (which is actually the `slug` in the database).

```ts
{
  job {
   //note that this is what we call the ""slug"" in the database
    id: ""......"",
  },
  //rest of the payload
}
```

This would creating `v3` versions of the following API endpoints that return the job.id
1. https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/routes/api.v2.runs.%24runId.ts
2. https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/routes/api.v2.runs.%24runId.statuses.ts
3. https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/routes/api.v2.events.%24eventId.ts

Core schema updates (add job.id)
- GetRunStatusesSchema: https://github.com/triggerdotdev/trigger.dev/blob/29edcd3df96e333b123c0124c764588db71fb382/packages/core/src/schemas/api.ts#L1061
- GetRunSchema: https://github.com/triggerdotdev/trigger.dev/blob/29edcd3df96e333b123c0124c764588db71fb382/packages/core/src/schemas/runs.ts#L107
- GetEventSchema: https://github.com/triggerdotdev/trigger.dev/blob/29edcd3df96e333b123c0124c764588db71fb382/packages/core/src/schemas/events.ts#L4

The SDK API client URLs need updating to be `v3` instead of `v2`
- `getEvent`
- `getRun`
- `getRunStatuses`
https://github.com/triggerdotdev/trigger.dev/blob/main/packages/trigger-sdk/src/apiClient.ts#L446

The React package URLs need updating to be `v3` instead of `v2`:
- https://github.com/triggerdotdev/trigger.dev/blob/main/packages/react/src/events.ts
- https://github.com/triggerdotdev/trigger.dev/blob/main/packages/react/src/runs.ts
- https://github.com/triggerdotdev/trigger.dev/blob/main/packages/react/src/statuses.ts


<sub>[TRI-1923](https://linear.app/triggerdotdev/issue/TRI-1923/react-hooks-should-return-basic-metadata-about-the-job)</sub>",,
2120735366,883,[TRI-1922] Add all the EventFilter patterns to the docs,"We have a docs page for EventFilters: https://trigger.dev/docs/documentation/guides/event-filter#boolean-filters

But it doesn't include all the filters we support. The full options can be found in the source code: https://github.com/triggerdotdev/trigger.dev/blob/main/packages/core/src/schemas/eventFilter.ts

It would be good to add a table that has the ""operator"" and a description of what it does.

<sub>[TRI-1922](https://linear.app/triggerdotdev/issue/TRI-1922/add-all-the-eventfilter-patterns-to-the-docs)</sub>",,
2113333320,881,bug: CLI Init Commands don't Work OOTB in PowerShell,"### Provide environment information

System:
- OS: Windows 11 10.0.22621
- CPU: (16) x64 AMD Ryzen 7 7800X3D 8-Core Processor
- Memory: 27.07 GB / 63.15 GB

Binaries:
- Node: 18.19.0 - C:\Program Files\nodejs\node.EXE
- npm: 10.2.3 - C:\Program Files\nodejs\npm.CMD
- pnpm: 8.15.1 - ~\AppData\Roaming\npm\pnpm.CMD

### Describe the bug

In PowerShell, a token beginning with the '@' character is used for [splatting](https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_splatting?view=powershell-7.4), and is invalid for use when calling a standard executable.

For a (trivially) better DX, the package name in that command should be enclosed in quotes so that the command doesn't need to be edited before execution in PowerShell.

![image](https://github.com/triggerdotdev/trigger.dev/assets/75811601/e4afcdb4-4581-4cf8-9d8e-d468564638e7)

![image](https://github.com/triggerdotdev/trigger.dev/assets/75811601/ca8ed424-e3f7-4888-9656-6cd014840b7c)



### Reproduction repo

n/a

### To reproduce

1. Go to Framework Setup and select a framework
2. Copy and paste the ""Run the CLI 'init' command..."" step into a PowerShell window

### Additional information

_No response_",,
2102319758,871,[TRI-1907] Add documentation for `standardBackoff` and `exponentialBackoff`,"When using `io.runTask` you can specify retry settings (for when an error is thrown). The default is that no retrying happens.

We provide a lot of settings and figuring out good ones can be tricky. So we export two useful ones here: https://github.com/triggerdotdev/trigger.dev/blob/0b657b33f9a634376a4c4be031b111f9c3c4d914/packages/core/src/retry.ts#L11

We should add documentation to the SDK reference about this. And probably also link to it from here: https://trigger.dev/docs/sdk/io/runtask

<sub>[TRI-1907](https://linear.app/triggerdotdev/issue/TRI-1907/add-documentation-for-standardbackoff-and-exponentialbackoff)</sub>",,
2101334586,870,bug: missing infos for the `useRunDetails` hook,"### Provide environment information


  System:
    OS: macOS 14.2.1
    CPU: (10) arm64 Apple M2 Pro
    Memory: 227.30 MB / 16.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 20.10.0 - ~/.nvm/versions/node/v20.10.0/bin/node
    Yarn: 1.22.21 - ~/.nvm/versions/node/v20.10.0/bin/yarn
    npm: 10.2.3 - ~/.nvm/versions/node/v20.10.0/bin/npm
    bun: 1.0.25 - ~/.bun/bin/bun

### Describe the bug

- `data.subtasks` are in the typescript but the hook doesn't spit them out
- `status` are not showing WAITING... haven't tested the others


### Reproduction repo

https://discord.com/channels/1066956501299777596/1066956844553207828/1200203785457377390

### To reproduce

basically
```tsx
  const {data, error} = useRunDetails(runId)
  return  <pre>{JSON.stringify(data, null, 2)}</pre>
```

and this job
https://trigger.dev/docs/documentation/concepts/tasks#extracting-common-tasks





### Additional information

_No response_",,
2086991112,856,bug: Unable to Add OAuth Integrations when Self-Hosting,"### Provide environment information

This environment is running using the docker-compose file from `https://github.com/triggerdotdev/docker`

```
  System:
    OS: Linux 5.15 Debian GNU/Linux 11 (bullseye) 11 (bullseye)
    CPU: (16) x64 AMD Ryzen 7 7800X3D 8-Core Processor
    Memory: 29.29 GB / 30.93 GB
    Container: Yes
    Shell: 5.1.4 - /bin/bash
  Binaries:
    Node: 18.18.2 - /usr/local/bin/node
    npm: 9.8.1 - /usr/local/bin/npm
    pnpm: 7.18.1 - /usr/local/bin/pnpm
```

### Describe the bug

When self-hosting Trigger.dev, an error is encountered when attempting to set up integrations using OAuth2 tokens.

![image](https://github.com/triggerdotdev/trigger.dev/assets/75811601/211c5a8b-d428-40bf-a8b4-d69b9236bda6)
![image](https://github.com/triggerdotdev/trigger.dev/assets/75811601/79023451-0757-4f3e-ab47-b2846540ca7f)
![image](https://github.com/triggerdotdev/trigger.dev/assets/75811601/6e129be1-3efc-48ec-9d55-9d274e9401cd)



### Reproduction repo

https://github.com/triggerdotdev/docker

### To reproduce

1. Deploy the compose file from `https://github.com/triggerdotdev/docker`
2. Authenticate and navigate to the integrations page
3. Select a Trigger.dev integration which supports OAuth2 (such as Slack)
4. Select OAuth2 (Bot), Developers and then fill in any value for ID, Name and Client ID/Secret
5. Click the ""Connect to __"" button
6. Note that an error is presented instead of being navigated to the service for authentication.

### Additional information

This issue appears to be related to how the `hasCustomClient` field is not sent with the form submission to the server. If that field isn't present, the route handler doesn't pass the provided client ID & secret to the auth repository for the rest of the process.

![image](https://github.com/triggerdotdev/trigger.dev/assets/75811601/a7b192f6-2817-471f-805e-351aa92b10ac)

https://github.com/triggerdotdev/trigger.dev/blob/2c328ba93df5167aa74712866979561307017008/apps/webapp/app/routes/resources.connection.%24organizationId.oauth2.ts#L70-L74
https://github.com/triggerdotdev/trigger.dev/blob/2c328ba93df5167aa74712866979561307017008/apps/webapp/app/routes/resources.connection.%24organizationId.oauth2.ts#L177-L184

---

If I simply remove the disabled flag on the ""Use my OAuth App"" checkbox using Chrome Devtools, the ""hasCustomClient"" field appears on the submission, and I am correctly redirected to Slack for the rest of the authentication process.

![image](https://github.com/triggerdotdev/trigger.dev/assets/75811601/ff74b88f-0095-4396-8574-1de98c72d4f9)

https://github.com/triggerdotdev/trigger.dev/blob/2c328ba93df5167aa74712866979561307017008/apps/webapp/app/components/integrations/ConnectToOAuthForm.tsx#L126-L134



",,
2076965769,834,[TRI-1861] Runs can permanently get stuck in queued status if the Redis server is unreachable in some circumstances ,"We use Redis to handle rate limiting run executions (by org, job, or concurrency group), and there is a specific scenario where runs can get stuck for an org, job, or concurrency group if the Redis server is unreachable between calling the [beforeTask](https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/services/runExecutionRateLimiter.server.ts/#L94) and [afterTask](https://github.com/triggerdotdev/trigger.dev/blob/5bf125be0d9e39d4bb9aa8f49f517b8c2bb1d13c/apps/webapp/app/services/runExecutionRateLimiter.server.ts#L130) Lua scripts. 

If the `beforeTask` script adds the flag to the forbidden flags Redis set (`tr:exec:forbiddenFlags`) which prevents graphile jobs from running that include any members of the set, but then the Redis server becomes unreachable before the `afterTask` script is invoked, then the flag will never be removed from the `tr:exec:forbiddenFlags` Redis set and runs associated with the org/job/concurrency group will never get executed.

We've had this happen once when we changed the instance size on our Redis cluster in the Trigger.dev Cloud and our Redis server had a brief (< 30s) period of downtime. 

## The fix

This could be fixed in a couple ways:

- Retry the afterTask script if invoking it throws an error, with a backoff up to 1 minute
- Use a sorted set for the `tr:exec:forbiddenFlags` key and give each forbidden flag a ""score"" that is the timestamp, and then only include the forbidden flags that are fresh enough when determining which graphile jobs should be be ignored (something like 5 minutes). Then we'd have a ""vacuum"" job that would remove any forbidden flags older than 60 minutes to keep the set size small.

<sub>[TRI-1861](https://linear.app/triggerdotdev/issue/TRI-1861/runs-can-permanently-get-stuck-in-queued-status-if-the-redis-server-is)</sub>",,
2069077837,828,feat: Websocket support for status APIs,"### Is your feature request related to a problem? Please describe.

I am surprised that old-school HTTP pooling is used in [react](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/react/src/fetch.ts) package instead of something like websockets. 

### Describe the solution you'd like to see

Websockets could provide faster updates (but ofc there is some architecture overhead).  Is this something that is on your roadmap?

### Describe alternate solutions

-

### Additional information

_No response_",,
2053755814,810,[TRI-1795] Add $not to eventFilters,"EventFilters support lots of different nice matching, but they don't support `not`.

Add it to the schema:
https://github.com/triggerdotdev/trigger.dev/blob/main/packages/core/src/schemas/eventFilter.ts

Add the implementation:
https://github.com/triggerdotdev/trigger.dev/blob/main/packages/core/src/eventFilterMatches.ts

Add tests:
https://github.com/triggerdotdev/trigger.dev/blob/main/packages/core/test/eventFilterMatches.test.ts

<sub>[TRI-1795](https://linear.app/triggerdotdev/issue/TRI-1795/add-dollarnot-to-eventfilters)</sub>",,
2053742573,809,[TRI-1794] Digital Ocean self-hosting docs,"A customer kindly provided this information when they got Trigger.dev working on Digital Ocean:

> Everything is the exact same as fly except for needing to have your own dockerhub image (perhaps fixed in the future) and needing to set NODE_TLS_REJECT_UNAUTHORIZED='0'. Without that env var, you get the following error from graphile: 

```
[2023-12-22 10:08:56] Error: self-signed certificate in certificate chain
[2023-12-22 10:08:56]     at TLSSocket.onConnectSecure (node:_tls_wrap:1600:34)
[2023-12-22 10:08:56]     at TLSSocket.emit (node:events:517:28)
[2023-12-22 10:08:56]     at TLSSocket._finishInit (node:_tls_wrap:1017:8)
[2023-12-22 10:08:56]     at ssl.onhandshakedone (node:_tls_wrap:803:12) {
[2023-12-22 10:08:56]   code: 'SELF_SIGNED_CERT_IN_CHAIN'
[2023-12-22 10:08:56] }
```

<sub>[TRI-1794](https://linear.app/triggerdotdev/issue/TRI-1794/digital-ocean-self-hosting-docs)</sub>",,
2053058174,808,feat: Read more files in ENV_FILES_FALLBACK,"### Is your feature request related to a problem? Please describe.

I'm currently trying to setup the self hosted version of trigger.dev with a Next.js docker standalone site. Environment variables in Next.js + Docker are notoriously difficult, so I have a setup utilizing env.development and env.production files.

Going through the initial setup of trigger.dev I've gotten to the point of running `npx @trigger.dev/cli@latest dev` to set everything up, but I kept getting the error `You must add TRIGGER_API_KEY to your .env file or set as runtime environment variable.`

Looking through the source of trigger.dev, I found in [readEnvVariables.ts](https://github.com/triggerdotdev/trigger.dev/blob/03703af682ab452a57a0c0e21e7b829eda564d4e/packages/cli/src/utils/readEnvVariables.ts#L5) it's not reading from the env.development and env.production files.

### Describe the solution you'd like to see

update [readEnvVariables.ts](https://github.com/triggerdotdev/trigger.dev/blob/03703af682ab452a57a0c0e21e7b829eda564d4e/packages/cli/src/utils/readEnvVariables.ts#L5) from

```typescript
const ENV_FILES_FALLBACK = ["".env"", "".env.local"", "".env.development.local""];
```

to be

```typescript
const ENV_FILES_FALLBACK = ["".env"", "".env.local"", "".env.development.local"", "".env.development"", "".env.production""];
```

### Describe alternate solutions

Change how I setup and use environment variables.

### Additional information

_No response_",,
2050201909,804,[TRI-1791] client.getRuns() doesn't return runs if you pass cursor: undefined.,"The issue is with this code:
https://github.com/triggerdotdev/trigger.dev/blob/5359af12426fad3576af2aa4a3abb5f4b0c25fa1/packages/core/src/searchParams.ts#L11

It doesn't check in the loop for undefined, and `string(undefined)` evaluates to `""undefined""` which obviously isn't a valid cursor.

It should do an undefined check in the loop and `continue`.

<sub>[TRI-1791](https://linear.app/triggerdotdev/issue/TRI-1791/clientgetruns-doesnt-return-runs-if-you-pass-cursor-undefined)</sub>",,
2046500209,799,[TRI-1772] Allow defining Zod schemas for HTTP Endpoints,"It would be nice to be able to attach a Zod schema on a HTTP endpoint which would then correctly type the results of `request.json`:

```ts
const endpoint = client.defineHttpEndpoint({
  id: ""tRPC"",
  source: ""unkey.dev"",
  verify: async (req) => {
     // verify here
  },
  schema: z.object({ }) // schema here
})
```



<sub>[TRI-1772](https://linear.app/triggerdotdev/issue/TRI-1772/allow-defining-zod-schemas-for-http-endpoints)</sub>",,
2038426110,792,bug: tests not running in isolation,"### Provide environment information

System:
    OS: Linux 6.4 Debian GNU/Linux 11 (bullseye) 11 (bullseye)
    CPU: (10) arm64 unknown
    Memory: 4.29 GB / 7.76 GB
    Container: Yes
    Shell: 5.1.4 - /bin/bash
  Binaries:
    Node: 20.9.0 - /usr/local/share/nvm/versions/node/v20.9.0/bin/node
    Yarn: 1.22.19 - /usr/bin/yarn
    npm: 10.1.0 - /usr/local/share/nvm/versions/node/v20.9.0/bin/npm
    pnpm: 8.10.5 - /usr/local/share/nvm/versions/node/v20.9.0/bin/pnpm

### Describe the bug

When using the testing package, mocked tasks are not reset and carry their value from the first declaration. 

### Reproduction repo

*

### To reproduce

Below are two example tests where the task sum should return a number.

```ts
import { createJobTester, toHaveSucceeded } from ""@trigger.dev/testing"";
import { afterEach, beforeEach, describe, expect, it, vi } from ""vitest"";

expect.extend({ toHaveSucceeded });
const testJob = createJobTester(vi);

describe(""test 1"", () => {
  it(""input date is rounded to the hour"", async () => {
    ....

    const testRun = await testJob(history, {
      payload: {
        debug: true,
      },
      tasks: {
        sum: 4
      }
    });
  
    // job run was successful
    expect(testRun).toHaveSucceeded();
    // check output
    expect(testRun.output.message).toEqual('4');
  });

it(""test 2"", async () => {
    ....

    const testRun = await testJob(history, {
      payload: {
        debug: true
      },
      tasks: {
        sum: 5
      }
    });
    // job run was successful
    expect(testRun).toHaveSucceeded();
    // check output
    expect(testRun.output.message).toEqual('5');
  });
});
```

When you run the test, the output of the test 2 is 4, upon further debugging you find that the output of the sum task is 4 not 5 for test 2. 

### Additional information

_No response_",,
2022013628,769,Shopify webhook  - Failed sha256 verification,"I opened this originally in discussions, but unsure if this is better suited as an issue so re-opening it here. Feel free to close one and continue conversation in the other. Discussion https://github.com/triggerdotdev/trigger.dev/discussions/768

---

Hey there,

I've been trying to get up an going with the Shopify integration, however every time I trigger an event through Shopify it leads to a ""Failed sha256 verification"" error.

![image](https://github.com/triggerdotdev/trigger.dev/assets/27323317/d5924c04-9cd4-4822-a9a4-961f20e54fa2)

The webhook succeeds obviously when using the test event in Trigger, and it returns the payload (using the example below). I have set up webhook in Shopify, and I am also using the correct secrets/env vars.

I am self-hosting Trigger, and have input the DEV URL to Shopify as the app is not hosted yet.

Seeing as Shopify doesn't have a way to insert the secret that Trigger gives you, and they instead give us one, I assume Trigger registers this automatically when registering the trigger? Still, with the correct URL set in Shopify it fails to verify.

Here's an example piece of code that doesn't work:

```ts
import ""@shopify/shopify-api/adapters/node""
import { Shopify } from ""@trigger.dev/shopify""
import { client } from ""../""

const shopify = new Shopify({
  id: ""shopify"",
  apiKey: process.env.SHOPIFY_API_KEY!,
  apiSecretKey: process.env.SHOPIFY_API_SECRET_KEY!,
  adminAccessToken: process.env.SHOPIFY_ADMIN_ACCESS_TOKEN!,
  hostName: process.env.SHOPIFY_SHOP_DOMAIN!
})

client.defineJob({
  id: ""shopify/on-order-created"",
  name: ""Shopify: On Order Created"",
  version: ""0.1.0"",
  trigger: shopify.on(""orders/create""),
  run: async (payload, io, ctx) => {
    return { payload }
  }
})
```",,
2015056501,759,bug: Headers filter does not work on HTTP endpoint,"### Provide environment information

NA

### Describe the bug

Headers filter does not work on HTTP endpoint `respondWith` function.

This is because, `Headers` object does not allow indexed access which is used in [eventFilterMatches](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/core/src/eventFilterMatches.ts#L17) to get the key value.

### Reproduction repo

NA

### To reproduce

1. Create an HTTP trigger with a `headers` filter.
2. Notice that it is not honoured.

### Additional information

### Solution
Convert the `Headers` object to a `Record` type.",,
2007885628,747,[TRI-1642] Add Stripe invoice triggers,"## How to add a new trigger

1. Add an event specification for each: https://github.com/triggerdotdev/trigger.dev/blob/main/integrations/stripe/src/events.ts
2. Add a function for each, referencing the event: https://github.com/triggerdotdev/trigger.dev/blob/131d0dbea420b3174f6a6ea11de1fbb844853d91/integrations/stripe/src/index.ts#L848
3. Test the trigger works by adding it to the job-catalog, running it and triggering a webhook using Stripe's CLI: https://github.com/triggerdotdev/trigger.dev/blob/131d0dbea420b3174f6a6ea11de1fbb844853d91/references/job-catalog/src/stripe.ts#L165

## List of events to add:
**invoice.created**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever a new invoice is created. To learn how webhooks can be used with this event, and how they can affect it, see [Using Webhooks with Subscriptions](https://stripe.com/docs/subscriptions/webhooks).

**invoice.deleted**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever a draft invoice is deleted.

**invoice.finalization_failed**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever a draft invoice cannot be finalized. See the invoice’s [last finalization error](https://stripe.com/docs/api/invoices/object#invoice_object-last_finalization_error) for details.

**invoice.finalized**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever a draft invoice is finalized and updated to be an open invoice.

**invoice.marked_uncollectible**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever an invoice is marked uncollectible.

**invoice.paid**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever an invoice payment attempt succeeds or an invoice is marked as paid out-of-band.

**invoice.payment_action_required**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever an invoice payment attempt requires further user action to complete.

**invoice.payment_failed**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever an invoice payment attempt fails, due either to a declined payment or to the lack of a stored payment method.

**invoice.payment_succeeded**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever an invoice payment attempt succeeds.

**invoice.sent**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever an invoice email is sent out.

**invoice.upcoming**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs X number of days before a subscription is scheduled to create an invoice that is automatically charged—where X is determined by your [subscriptions settings](https://dashboard.stripe.com/account/billing/automatic). Note: The received Invoice object will not have an invoice ID.

**invoice.updated**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever an invoice changes (e.g., the invoice amount).

**invoice.voided**
data.object is an[ invoice](https://stripe.com/docs/api/events/types#invoice_object)
Occurs whenever an invoice is voided.

**invoiceitem.created**
data.object is an[ invoiceitem](https://stripe.com/docs/api/events/types#invoiceitem_object)
Occurs whenever an invoice item is created.

**invoiceitem.deleted**
data.object is an[ invoiceitem](https://stripe.com/docs/api/events/types#invoiceitem_object)
Occurs whenever an invoice item is deleted.

<sub>[TRI-1642](https://linear.app/triggerdotdev/issue/TRI-1642/add-stripe-invoice-triggers)</sub>",,
2000436226,740,bug: TypeScript type reduced to 'never' (GitHub integration),"### Provide environment information

System:
    OS: Linux 5.15 Ubuntu 20.04.4 LTS (Focal Fossa)
    CPU: (20) x64 12th Gen Intel(R) Core(TM) i7-12700K
    Memory: 6.85 GB / 9.71 GB
    Container: Yes
    Shell: 5.8 - /usr/bin/zsh
  Binaries:
    Node: 18.17.1 - ~/.nvm/versions/node/v18.17.1/bin/node
    Yarn: 1.22.19 - ~/.yarn/bin/yarn
    npm: 9.6.7 - ~/.nvm/versions/node/v18.17.1/bin/npm
    pnpm: 8.10.4 - ~/.local/share/pnpm/pnpm
    bun: 1.0.0 - ~/.bun/bin/bun

### Describe the bug

Trying to use the GitHub integration and saw this error appear.  This happens when trying to access anything on the issue property.

![image](https://github.com/triggerdotdev/trigger.dev/assets/27323317/66c873af-f7dc-4751-9b67-613abbf0b5df)

```
Property 'number' does not exist on type 'never'.
  The intersection 'Issue & { state: ""open""; closed_at: null; }' was reduced to 'never' because property 'closed_at' has conflicting types in some constituents.
  ```

### Reproduction repo

N/A

### To reproduce

Create a new job with a GitHub integration, and attempt to use a method that relies on Issue type.

### Additional information

_No response_",,
1985308484,727,bug: Typescript Error for Invoke Trigger with Zod schema ,"### Provide environment information

  System:
    OS: macOS 11.7.5
    CPU: (8) x64 Intel(R) Xeon(R) CPU E5-1620 v2 @ 3.70GHz
    Memory: 153.83 MB / 32.00 GB
    Shell: 3.2.57 - /bin/bash
  Binaries:
    Node: 18.17.1 - /usr/local/bin/node
    Yarn: 1.22.4 - /usr/local/bin/yarn
    npm: 9.6.7 - /usr/local/bin/npm
    Watchman: 2023.02.27.00 - /usr/local/bin/watchman

### Describe the bug

TypeScript: Type instantiation is excessively deep and possibly infinite
![Screenshot 2023-11-09 at 11 19 23](https://github.com/triggerdotdev/trigger.dev/assets/1077455/c092c462-5d8d-42dc-9630-912f0a8345a2)


### Reproduction repo

N/A

### To reproduce

Create a new job with invokeTrigger and provide Zod schema to it

### Additional information

_No response_",,
1977674975,723,Bug: `cannot read properties of undefined (reading: defaultQuery)` in OpenAI integration,"### Provide environment information

  ```bash
  System:
    OS: Windows 11 10.0.22621
    CPU: (20) x64 12th Gen Intel(R) Core(TM) i7-12700H
    Memory: 4.67 GB / 15.73 GB
  Binaries:
    Node: 18.14.2 - C:\Program Files\nodejs\node.EXE
    Yarn: 1.22.19 - ~\AppData\Roaming\npm\yarn.CMD
    npm: 9.6.3 - C:\Program Files\nodejs\npm.CMD
    pnpm: 8.9.2 - ~\AppData\Local\pnpm\pnpm.CMD
```

### Describe the bug

When trying to register a job using OpenAI specific it throws an error with `cannot read properties of undefined (reading: defaultQuery)`

![openai_error_trigger](https://github.com/triggerdotdev/trigger.dev/assets/76906722/6d2d938a-fbd3-47e4-b85b-e3beecafe259)

This is the exact job file that uses OpenAI integration: https://github.com/shricodev/blog-resume-builder/blob/e53603127225a7ceed156a3b8235bd2d9caed817/jobs/openAIClient.ts





### Reproduction repo

https://github.com/shricodev/blog-resume-builder/tree/e53603127225a7ceed156a3b8235bd2d9caed817

### To reproduce

- Clone the repo in this committed state: https://github.com/shricodev/blog-resume-builder/tree/e53603127225a7ceed156a3b8235bd2d9caed817
- Setup `.env.local` with the API keys
- Run the dev server along with `npx @trigger.dev/cli@latest dev`
- In the Jobs section in the Trigger dashboard, run the job `jobs\openAIClient.ts` and that should trigger the error.

### Additional information

I tried checking if the error is on any other integrations and not just the OpenAI integrations but the Slack integration seems to work fine.

![Screenshot 2023-11-05 132151](https://github.com/triggerdotdev/trigger.dev/assets/76906722/331032ee-55e3-4f96-9c10-a7e56deba88f)
",,
1964908530,693,bug: PrismaClientInitializationError: Error querying the database: FATAL: Max client connections reached,"### Provide environment information

 System:
    OS: Windows 10 10.0.22621
    CPU: (20) x64 12th Gen Intel(R) Core(TM) i7-12700H
    Memory: 1.37 GB / 15.71 GB
  Binaries:
    Node: 18.18.2 - ~\scoop\apps\nvm\current\nodejs\nodejs\node.EXE
    Yarn: 1.22.19 - ~\scoop\apps\nvm\current\nodejs\nodejs\yarn.CMD
    npm: 9.8.1 - ~\scoop\apps\nvm\current\nodejs\nodejs\npm.CMD
    pnpm: 8.9.2 - ~\AppData\Local\pnpm\pnpm.CMD

### Describe the bug

In a self-deployed setup, when a job file is modified and saved frequently, your file watcher makes new connection to a postgres every time it is reloaded.
Until the limit hits: `Error querying the database: FATAL: Max client connections reached`.

### Reproduction repo

WIP

### To reproduce

1. Deploy self-hosted trigger.dev, docker image hash dafc2775627f8f627b1bc95b1671b506480132736c46da86efb5aef9ec5320a0 (tag: latest as of 27.10.2023) with supabase (following https://trigger.dev/docs/documentation/guides/self-hosting/supabase)
2. Use this .env for trigger.dev docker container:
```dotenv
LOGIN_ORIGIN=http://localhost:3030
APP_ORIGIN=http://localhost:3030
PORT=3030
REMIX_APP_PORT=3030
MAGIC_LINK_SECRET=<ARBITRARY KEY1>
SESSION_SECRET=<ARBITRARY KEY2>
ENCRYPTION_KEY=<ARBITRARY KEY3>
DATABASE_URL=postgres://postgres.<ID>:<PASSWORD>@aws-0-eu-central-1.pooler.supabase.com:6543/postgres?schema=triggerdotdev&pgbouncer=true
DIRECT_URL=postgresql://postgres:<PASSWORD>@db.<ID>.supabase.co:5432/postgres?schema=triggerdotdev
NODE_ENV=development
RUNTIME_PLATFORM=docker-compose
```
3. Run `next dev` in terminal `A`.
4. Run `pnpx @trigger.dev/cli@latest dev` in terminal `B`. 
5. Open `docker-compose logs -f triggerdotdev` in a separate terminal `C` to observe logs.
6. Open any job under `/src/jobs` (`/src/jobs/example.ts`) in your favorite code editor.
7. Violently press CTRL+S many times while having the job file open. File watcher at terminal `B` should restart every time you click CTRL+S.
8. After <30 sec observe that `triggerdotdev` container fails with this message:
```log
github-profile-triggerdotdev-1  | Invalid `prisma.runtimeEnvironment.findUnique()` invocation in
github-profile-triggerdotdev-1  | /triggerdotdev/apps/webapp/build/index.js:7720:42
github-profile-triggerdotdev-1  |
github-profile-triggerdotdev-1  |   7717
github-profile-triggerdotdev-1  |   7718 // app/models/runtimeEnvironment.server.ts
github-profile-triggerdotdev-1  |   7719 async function findEnvironmentByApiKey(apiKey) {
github-profile-triggerdotdev-1  | → 7720   return await prisma.runtimeEnvironment.findUnique(
github-profile-triggerdotdev-1  | Error querying the database: FATAL: Max client connections reached
github-profile-triggerdotdev-1  | PrismaClientInitializationError:
github-profile-triggerdotdev-1  | Invalid `prisma.runtimeEnvironment.findUnique()` invocation in
github-profile-triggerdotdev-1  | /triggerdotdev/apps/webapp/build/index.js:7720:42
github-profile-triggerdotdev-1  |
github-profile-triggerdotdev-1  |   7717
github-profile-triggerdotdev-1  |   7718 // app/models/runtimeEnvironment.server.ts
github-profile-triggerdotdev-1  |   7719 async function findEnvironmentByApiKey(apiKey) {
github-profile-triggerdotdev-1  | → 7720   return await prisma.runtimeEnvironment.findUnique(
github-profile-triggerdotdev-1  | Error querying the database: FATAL: Max client connections reached
github-profile-triggerdotdev-1  |     at Cn.handleRequestError (/triggerdotdev/node_modules/.pnpm/@prisma+client@5.4.1/node_modules/@prisma/client/runtime/library.js:123:7090)
github-profile-triggerdotdev-1  |     at Cn.handleAndLogRequestError (/triggerdotdev/node_modules/.pnpm/@prisma+client@5.4.1/node_modules/@prisma/client/runtime/library.js:123:6206)
github-profile-triggerdotdev-1  |     at Cn.request (/triggerdotdev/node_modules/.pnpm/@prisma+client@5.4.1/node_modules/@prisma/client/runtime/library.js:123:5926)
github-profile-triggerdotdev-1  |     at l (/triggerdotdev/node_modules/.pnpm/@prisma+client@5.4.1/node_modules/@prisma/client/runtime/library.js:128:9968)
github-profile-triggerdotdev-1  |     at findEnvironmentByApiKey (/triggerdotdev/apps/webapp/build/index.js:7720:10)
github-profile-triggerdotdev-1  |     at authenticateApiRequest (/triggerdotdev/apps/webapp/build/index.js:7748:25)
github-profile-triggerdotdev-1  |     at loader32 (/triggerdotdev/apps/webapp/build/index.js:35960:30)        
github-profile-triggerdotdev-1  |     at Object.callRouteLoaderRR (/triggerdotdev/node_modules/.pnpm/@remix-run+server-runtime@1.19.2/node_modules/@remix-run/server-runtime/dist/data.js:52:16)
github-profile-triggerdotdev-1  |     at callLoaderOrAction (/triggerdotdev/node_modules/.pnpm/@remix-run+router@1.7.2/node_modules/@remix-run/router/router.ts:3671:16)
github-profile-triggerdotdev-1  |     at async Promise.all (index 0) {
github-profile-triggerdotdev-1  |   clientVersion: '5.4.1',
github-profile-triggerdotdev-1  |   errorCode: undefined
github-profile-triggerdotdev-1  | }
github-profile-triggerdotdev-1  |
github-profile-triggerdotdev-1  | /triggerdotdev/node_modules/.pnpm/@prisma+client@5.4.1/node_modules/@prisma/client/runtime/library.js:114
github-profile-triggerdotdev-1  | You may have to run ${Ge(""prisma generate"")} for your changes to take effect.`,this.config.clientVersion);return r}parseEngineResponse(r){if(!r)throw new K(""Response from the Engine was empty"",{clientVersion:this.config.clientVersion});try{return JSON.parse(r)}catch{throw new K(""Unable to JSON.parse response from engine"",{clientVersion:this.config.clientVersion})}}async loadEngine(){if(!this.engine){this.QueryEngineConstructor||(this.library=await this.libraryLoader.loadLibrary(),this.QueryEngineConstructor=this.library.QueryEngine);try{let r=new WeakRef(this),{adapter:n}=this.config;n&&Ce(""Using driver adapter: %O"",n),this.engine=new this.QueryEngineConstructor({datamodel:this.datamodel,env:process.env,logQueries:this.config.logQueries??!1,ignoreEnvVarErrors:!0,datasourceOverrides:this.datasourceOverrides??{},logLevel:this.logLevel,configDir:this.config.cwd,engineProtocol:""json""},i=>{r.deref()?.logger(i)},n),ja++}catch(r){let n=r,i=this.parseInitError(n.message);throw typeof i==""string""?n:new F(i.message,this.config.clientVersion,i.error_code)}}}logger(r){let n=this.parseEngineResponse(r);if(n){if(""span""in n){this.config.tracingHelper.createEngineSpan(n);return}n.level=n?.level.toLowerCase()??""unknown"",md(n)?this.logEmitter.emit(""query"",{timestamp:new Date,query:n.query,params:n.params,duration:Number(n.duration_ms),target:n.module_path}):fd(n)?this.loggerRustPanic=new ue(this.getErrorMessageWithLink(`${n.message}: ${n.reason} in ${n.file}:${n.line}:${n.column}`),this.config.clientVersion):this.logEmitter.emit(n.level,{timestamp:new Date,message:n.message,target:n.module_path})}}getErrorMessageWithLink(r){return ka({platform:this.platform,title:r,version:this.config.clientVersion,engineVersion:this.versionInfo?.commit,database:this.config.activeProvider,query:this.lastQuery})}parseInitError(r){try{return JSON.parse(r)}catch{}return r}parseRequestError(r){try{return JSON.parse(r)}catch{}return r}on(r,n){if(r===""beforeExit"")throw new Error('""beforeExit"" hook is not applicable to the library engine since Prisma 5.0.0, it is only relevant and implemented for the binary engine. Please add your event listener to the `process` object directly instead.');this.logEmitter.on(r,n)}async start(){if(await this.libraryInstantiationPromise,await this.libraryStoppingPromise,this.libraryStartingPromise)return Ce(`library already starting, this.libraryStarted: ${this.libraryStarted}`),this.libraryStartingPromise;if(this.libraryStarted)return;let r=async()=>{Ce(""library starting"");try{let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.connect(JSON.stringify(n)),this.libraryStarted=!0,Ce(""library started"")}catch(n){let i=this.parseInitError(n.message);throw typeof i==""string""?n:new F(i.message,this.config.clientVersion,i.error_code)}finally{this.libraryStartingPromise=void 0}};return this.libraryStartingPromise=this.config.tracingHelper.runInChildSpan(""connect"",r),this.libraryStartingPromise}async stop(){if(await this.libraryStartingPromise,await this.executingQueryPromise,this.libraryStoppingPromise)return Ce(""library is already stopping""),this.libraryStoppingPromise;if(!this.libraryStarted)return;let r=async()=>{await new Promise(i=>setTimeout(i,5)),Ce(""library stopping"");let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.disconnect(JSON.stringify(n)),this.libraryStarted=!1,this.libraryStoppingPromise=void 0,Ce(""library stopped"")};return this.libraryStoppingPromise=this.config.tracingHelper.runInChildSpan(""disconnect"",r),this.libraryStoppingPromise}version(){return this.versionInfo=this.library?.version(),this.versionInfo?.version??""unknown""}debugPanic(r){return this.library?.debugPanic(r)}async request(r,{traceparent:n,interactiveTransaction:i}){Ce(`sending request, this.libraryStarted: ${this.libraryStarted}`);let o=JSON.stringify({traceparent:n}),s=JSON.stringify(r);try{await this.start(),this.executingQueryPromise=this.engine?.query(s,o,i?.id),this.lastQuery=s;let a=this.parseEngineResponse(await this.executingQueryPromise);if(a.errors)throw a.errors.length===1?this.buildQueryError(a.errors[0]):new K(JSON.stringify(a.errors),{clientVersion:this.config.clientVersion});if(this.loggerRustPanic)throw this.loggerRustPanic;return{data:a,elapsed:0}}catch(a){if(a instanceof F)throw a;if(a.code===""GenericFailure""&&a.message?.startsWith(""PANIC:""))throw new ue(this.getErrorMessageWithLink(a.message),this.config.clientVersion);let l=this.parseRequestError(a.message);throw typeof l==""string""?a:new K(`${l.message}
github-profile-triggerdotdev-1  |                                                                             
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                                                                                                              
                       ^
github-profile-triggerdotdev-1  | PrismaClientInitializationError: Error querying the database: FATAL: Max client connections reached
github-profile-triggerdotdev-1  |     at r (/triggerdotdev/node_modules/.pnpm/@prisma+client@5.4.1/node_modules/@prisma/client/runtime/library.js:114:2740)
```



### Additional information

As a result, container tiggerdotdev stops. ",,
1964164530,691,[TRI-1449] Display warning message when duplicate job IDs are detected,"It's quite easy to accidentally reuse a job ID:

```ts
// foo.ts
client.defineJob({
  id: ""do-something"",
});

// bar.ts
client.defineJob({
  id: ""do-something"",
})
```

We should detect when this happens and display a warning in the users local server console.

<sub>[TRI-1449](https://linear.app/triggerdotdev/issue/TRI-1449/display-warning-message-when-duplicate-job-ids-are-detected)</sub>",,
1961650082,685,[TRI-1444] Only allow logins from whitelisted_emails (for self-hosting),"Currently there isn't a convenient way to lock down logins to a self-hosted Trigger.dev service.

We should add a new ENV var which allows a regex pattern to be used to only allow certain emails.

```
WHITELISTED_EMAILS=""matt@gmail\.com|jane@yahoo\.com""
```

Only emails that match this would be able to sign-up or login.

It must be added to `env.server.ts` file, and it needs to be optional. Probably the easiest way to implement this would be to modify the `findOrCreateUser()` function in `user.server.ts` to first check the whitelist if it exists and just throw an error.

<sub>[TRI-1444](https://linear.app/triggerdotdev/issue/TRI-1444/only-allow-logins-from-whitelisted-emails-for-self-hosting)</sub>",,
1953967359,665,[TRI-1431] Improve the Airtable integration documentation,"## Overview:

Update the [Airtable integration documentation](https://trigger.dev/docs/integrations/apis/airtable) so it is much easier to use as a reference.

We have just overhauled our [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) and would like all of the rest of our integrations to follow the same structure.

*Please use the references and resources at the bottom of this post to complete this issue.*

## Pages to add:

### Airtable overview & authentication:

This page is currently [this](https://trigger.dev/docs/integrations/apis/airtable).

* **Page Title:** Airtable overview & authentication
* **Sidebar title:** Overview & authentication
* **Page content**: authentication with Airtable, in the same format as [this](https://trigger.dev/docs/integrations/apis/github). If there is no overview, write one. You can use their company website for inspiration.

### Airtable Tasks:

* **Page title:** Airtable tasks
* **Sidebar title:** Tasks
* **Page content:** all the tasks available from our Airtable integration, in the same format as this: [https://trigger.dev/docs/integrations/apis/github-tasks](https://trigger.dev/docs/integrations/apis/github-tasks). Please include code comments in all of the code examples. Also include one example at the bottom with clear comments. See references below for sample code.

### References & resources:

* [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) to reference
* Our current [Airtable documentation](https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/apis/airtable.mdx) in the GitHub repo.
* Example job code to use - [job catalog](https://github.com/triggerdotdev/trigger.dev/blob/main/references/job-catalog/src/airtable.ts) and [jobs showcase](https://trigger.dev/showcase?tags=&integrations=airtable).
* We use Mintlify for our docs, [documentation here](https://mintlify.com/docs/quickstart)

> \[!IMPORTANT\]
> Please include a video or screenshots of the pages when you submit a PR for us to check

<sub>[TRI-1431](https://linear.app/triggerdotdev/issue/TRI-1431/improve-the-airtable-integration-documentation)</sub>",,
1953960759,664,[TRI-1430] Improve the OpenAI integration documentation,"## Overview:

Update the [OpenAI integration documentation](https://trigger.dev/docs/integrations/apis/openai) so it is much easier to use as a reference.

We have just overhauled our [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) and would like all of the rest of our integrations to follow the same structure.

*Please use the references and resources at the bottom of this post to complete this issue.*

## Pages to add:

### OpenAI overview & authentication:

This page is currently [this](https://trigger.dev/docs/integrations/apis/openai).

* **Page Title:** OpenAI overview & authentication
* **Sidebar title:** Overview & authentication
* **Page content**: authentication with OpenAI, in the same format as [this](https://trigger.dev/docs/integrations/apis/github). If there is no overview, write one. You can use their company website for inspiration.

### OpenAI Tasks:

* **Page title:** OpenAI tasks
* **Sidebar title:** Tasks
* **Page content:** all the tasks available from our OpenAI integration, in the same format as this: [https://trigger.dev/docs/integrations/apis/github-tasks](https://trigger.dev/docs/integrations/apis/github-tasks). Please include code comments in all of the code examples. Also include one example at the bottom with clear comments. See references below for sample code.

### References & resources:

* [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) to reference
* Our current [OpenAI documentation](https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/apis/openai.mdx) in the GitHub repo.
* Example job code to use - [job catalog](https://github.com/triggerdotdev/trigger.dev/blob/main/references/job-catalog/src/openai.ts) and [jobs showcase](https://trigger.dev/showcase?tags=&integrations=openai).
* We use Mintlify for our docs, [documentation here](https://mintlify.com/docs/quickstart)

> \[!IMPORTANT\]
> Please include a video or screenshots of the pages when you submit a PR for us to check

<sub>[TRI-1430](https://linear.app/triggerdotdev/issue/TRI-1430/improve-the-openai-integration-documentation)</sub>",,
1953950439,663,[TRI-1429] Improve the Slack integration documentation,"## Overview:

Update the [Slack integration documentation](https://trigger.dev/docs/integrations/apis/slack) so it is much easier to use as a reference.

We have just overhauled our [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) and would like all of the rest of our integrations to follow the same structure.

*Please use the references and resources at the bottom of this post to complete this issue.*

## Pages to add:

### Slack overview & authentication:

This page is currently [this](https://trigger.dev/docs/integrations/apis/slack).

* **Page Title:** Slack overview & authentication
* **Sidebar title:** Overview & authentication
* **Page content**: authentication with Slack, in the same format as [this](https://trigger.dev/docs/integrations/apis/github). If there is no overview, write one. You can use their company website for inspiration.

### Slack Tasks:

* **Page title:** Slack tasks
* **Sidebar title:** Tasks
* **Page content:** all the tasks available from our Slack integration, in the same format as this: [https://trigger.dev/docs/integrations/apis/github-tasks](https://trigger.dev/docs/integrations/apis/github-tasks). Please include code comments in all of the code examples. Also include one example at the bottom with clear comments. See references below for sample code.

### References & resources:

* Our current [Slack documentation](https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/apis/slack.mdx) in the GitHub repo.
* Example job code to use - [job catalog](https://github.com/triggerdotdev/trigger.dev/blob/main/references/job-catalog/src/slack.ts) and [jobs showcase](https://trigger.dev/showcase?tags=&integrations=slack).
* We use Mintlify for our docs, [documentation here](https://mintlify.com/docs/quickstart)

> \[!IMPORTANT\]
> Please include a video or screenshots of the pages when you submit a PR for us to check

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1429](https://linear.app/triggerdotdev/issue/TRI-1429/improve-the-slack-integration-documentation)</sub>",,
1953947498,662,[TRI-1428] Improve the SendGrid integration documentation,"## Overview:

Update the [SendGrid integration documentation](https://trigger.dev/docs/integrations/apis/sendgrid) so it is much easier to use as a reference.

We have just overhauled our [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) and would like all of the rest of our integrations to follow the same structure.

*Please use the references and resources at the bottom of this post to complete this issue.*

## Pages to add:

### SendGrid overview & authentication:

This page is currently [this](https://trigger.dev/docs/integrations/apis/sendgrid).

* **Page Title:** SendGrid overview & authentication
* **Sidebar title:** Overview & authentication
* **Page content**: authentication with SendGrid, in the same format as [this](https://trigger.dev/docs/integrations/apis/github). If there is no overview, write one. You can use their company website for inspiration.

### SendGrid Tasks:

* **Page title:** SendGrid tasks
* **Sidebar title:** Tasks
* **Page content:** all the tasks available from our SendGrid integration, in the same format as this: [https://trigger.dev/docs/integrations/apis/github-tasks](https://trigger.dev/docs/integrations/apis/github-tasks). Please include code comments in all of the code examples. Also include one example at the bottom with clear comments. See references below for sample code.

### References & resources:

* Our current [SendGrid documentation](https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/apis/sendgrid.mdx) in the GitHub repo.
* Example job code to use - [job catalog](https://github.com/triggerdotdev/trigger.dev/blob/main/references/job-catalog/src/sendgrid.ts) and [jobs showcase](https://trigger.dev/showcase?tags=&integrations=sendgrid).
* We use Mintlify for our docs, [documentation here](https://mintlify.com/docs/quickstart)

> \[!IMPORTANT\]
> Please include a video or screenshots of the pages when you submit a PR for us to check

<sub>[TRI-1426](https://linear.app/triggerdotdev/issue/TRI-1426/improve-the-sendgrid-documentation)</sub>

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1428](https://linear.app/triggerdotdev/issue/TRI-1428/improve-the-sendgrid-integration-documentation)</sub>",,
1953941615,661,[TRI-1426] Improve the Resend integration documentation,"## Overview:

Update the [Resend integration documentation](https://trigger.dev/docs/integrations/apis/resend) so it is much easier to use as a reference.

We have just overhauled our [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) and would like all of the rest of our integrations to follow the same structure.

*Please use the references and resources at the bottom of this post to complete this issue.*

## Pages to add:

### Resend overview & authentication:

This page is currently [this](https://trigger.dev/docs/integrations/apis/resend).

* **Page Title:** Resend overview & authentication
* **Sidebar title:** Overview & authentication
* **Page content**: authentication with Resend, in the same format as [this](https://trigger.dev/docs/integrations/apis/github). If there is no overview, write one. You can use their company website for inspiration.

### Resend Tasks:

* **Page title:** Resend tasks
* **Sidebar title:** Tasks
* **Page content:** all the tasks available from our Resend integration, in the same format as this: [https://trigger.dev/docs/integrations/apis/github-tasks](https://trigger.dev/docs/integrations/apis/github-tasks). Please include code comments in all of the code examples. Also include one example at the bottom with clear comments. See references below for sample code.

### References & resources:

* Our current [Resend documentation](https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/apis/resend.mdx) in the GitHub repo.
* Example job code to use - [job catalog](https://github.com/triggerdotdev/trigger.dev/blob/main/references/job-catalog/src/resend.ts) and [jobs showcase](https://trigger.dev/showcase?tags=&integrations=resend).
* We use Mintlify for our docs, [documentation here](https://mintlify.com/docs/quickstart)

> \[!IMPORTANT\]
> Please include a video or screenshots of the pages when you submit a PR for us to check

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1426](https://linear.app/triggerdotdev/issue/TRI-1426/improve-the-resend-integration-documentation)</sub>",,
1952672881,657,[TRI-1425] Improve the Plain integration documentation,"## Overview:

Update the [Plain integration documentation](https://trigger.dev/docs/integrations/apis/plain) so it is much easier to use as a reference.

We have just overhauled our [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) and would like all of the rest of our integrations to follow the same structure.

*Please use the references and resources at the bottom of this post to complete this issue.*

## Pages to add:

### Plain overview & authentication:

This page is currently [this](https://trigger.dev/docs/integrations/apis/plain).

* **Page Title:** Plain overview & authentication
* **Sidebar title:** Overview & authentication
* **Page content**: authentication with Plain, in the same format as this: [https://trigger.dev/docs/integrations/apis/github](https://trigger.dev/docs/integrations/apis/github)

### Plain Tasks:

* **Page title:** Plain tasks
* **Sidebar title:** Tasks
* **Page content:** all the tasks available from our Plain integration, in the same format as this: [https://trigger.dev/docs/integrations/apis/github-tasks](https://trigger.dev/docs/integrations/apis/github-tasks). Also include one example at the bottom with clear comments. See references below for sample code.

### References & resources:

* Our current [Plain documentation](https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/apis/plain.mdx) in the GitHub repo.
* Example job code to use - [job catalog](https://github.com/triggerdotdev/trigger.dev/blob/main/references/job-catalog/src/plain.ts) and [jobs showcase](https://trigger.dev/showcase/jobs/plainUpdateCustomer).
* We use Mintlify for our docs, [documentation here](https://mintlify.com/docs/quickstart)

> \[!IMPORTANT\]
> Please include screenshots of the pages when you submit a PR for us to check

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1425](https://linear.app/triggerdotdev/issue/TRI-1425/improve-the-plain-integration-documentation)</sub>",,
1949588122,645,bug: `AirtableFieldSet` does not expose type matching Airtable Formula fields with error,"### Provide environment information

❯ npx envinfo --system --binaries

  System:
    OS: macOS 13.5
    CPU: (8) x64 Intel(R) Core(TM) i7-1068NG7 CPU @ 2.30GHz
    Memory: 34.34 MB / 32.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 20.8.0 - ~/.volta/tools/image/node/20.8.0/bin/node
    npm: 10.1.0 - ~/.volta/tools/image/node/20.8.0/bin/npm
    pnpm: 8.7.6 - ~/.volta/bin/pnpm
    Watchman: 2023.09.04.00 - /usr/local/bin/watchman

### Describe the bug

`AirtableFieldSet` does not expose correct type for Airtable Formula fields with errors.

When creating a type/interface to represent an Airtable record with formulas - if the formula inside Airtable has errors, this cannot be typed through `@trigger.dev/airtable`.

E.g.: 

```ts
type FormulaFieldType = string;
type FormulaFieldErrorType  = { error: string; };

export interface MyTable extends AirtableFieldSet {
    ID: number;
    MyFormulaField: FormulaFieldType | FormulaFieldErrorType
}
```

Gives:
```
TS2411: Property  MyFormulaField  of type  string | FormulaFieldErrorType  is not assignable to  string  index type
string | number | boolean | Collaborator | Collaborator[] | string[] | Attachment[] | undefined
```

The actual response data looks like this from within Trigger.dev:
```json
[
  {
    ""id"": ""recXXX"",
    ""fields"": {
      ""ID"": 1,
      ""ValidFormulaField"": ""Some value"",
      ""InvalidFormulaField"": {
        ""error"": ""#ERROR!""
      },
      ...
    }
  }
]
```

### Reproduction repo

n/a

### To reproduce

* Create a table in Airtable, containing a formula field with an error
* Create a TypeScript interface that represents the formula field as type `string`
* Fetch the data through `@trigger.dev/airtable`
* The result should contain an error object
* Try update the TypeScript interface with a type that can handle both a valid value and the error object


### Additional information

Suggested fix: Add `| {key: string}` to `AirtableFieldSet` field type.",,
1943335448,621,feat: allow ngrok --domain,"### Is your feature request related to a problem? Please describe.

In development for webhooks in various services, I have to go to each of them & update the URL with the new tunnel URL from `pnpm dlx @trigger.dev/cli@latest dev`.

ngrok allows for a single, free, dedicated hostname associated with your account.

I'd like Trigger to take advantage of this somehow.



### Describe the solution you'd like to see

Support ngrok's `--domain` flag:

```shell
ngrok http --domain=i-love-me-some-trigger.ngrok-free.app 3000
```

could be passed via:

```
pnpm dlx @trigger.dev/cli@latest dev --ngrok-domain=i-love-me-some-trigger.ngrok-free.app
```



### Describe alternate solutions

1. Have a flag like `dev --public-url=i-love-me-some-trigger.ngrok-free.app` that's not ngrok-specific. Internally, it'd be used by ngrok, but if it eventually became localtunnel.me or an alternative, the flag won't need deprecation.

1. If ngrok is already running, use the current URL instead of making a new tunnel:

	```js
	const fetch = require('node-fetch')
	const tunnelUrl = fetch('http://localhost:4040/api/tunnels')
	  .then(res => res.json())
	  .then(json => json.tunnels.find(tunnel => tunnel.proto === 'https'))
	  .then(secureTunnel => secureTunnel.public_url)
	  .catch(err => {
		// Tunnel like normal
	    return createTunnel(...);
	  })
	```
	
	(ngrok has a limit to 1 connection on the free tier)

	This would work seamlessly if someone has a custom `ngrok service`


3. It would be a tighter coupling with ngrok (risky!) and start a `trigger` tunnel (`ngrok start trigger` if there's an ngrok config for it – https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config/.

4. Have a JS hook in `trigger.ts` for developers to programmatically update their other service APIs (through _those_ APIs) with the new URL.  This seems like a stupidly high level of friction TBH:

```js
new TriggerClient({
  onCreateTunnel({ url }) {
	// Update all backends with the new dev tunnel URL, assuming they have an API 🙏
  }
})
```

### Additional information

_No response_",,
1941923998,616,[TRI-1401] feat: Add support for tabler-icons when using the `icon` for Tasks,"## Problem

When you use `io.runTask` you can provide an `icon` in the options. (Docs: https://trigger.dev/docs/sdk/io/runtask).

This property is a string and we currently have support for:
- Some company names (used by our integrations), such as ""github"". This uses the `@trigger.dev/companyicons` package: https://github.com/triggerdotdev/companyicons
- Some internal icons (https://github.com/triggerdotdev/trigger.dev/blob/ebe78017efdf7bd53c0e4414a8302b7f0ff2648d/apps/webapp/app/components/primitives/NamedIcon.tsx#L73)

We want to add lots more icons, that are open source friendly. 

https://tabler-icons.io/ is the perfect fit for this.

## Solution

Add support for passing in a `tabler-icons` named to the `NamedIcon` component. Somewhere like here: https://github.com/triggerdotdev/trigger.dev/blob/ebe78017efdf7bd53c0e4414a8302b7f0ff2648d/apps/webapp/app/components/primitives/NamedIcon.tsx#L218

This means it would first try and render an internal icon, or a company icon. If they fail then it would render a tabler-icon.

There are so many icons in this set, we need to be careful how we accomplish this. I think the best way would be to use their sprite sheet, as it can be cached and tends to be efficient for rendering: https://github.com/tabler/tabler-icons#svg-sprite

## To test
1. Add an icon name from tabler-icons to this runTask in the catalog: https://github.com/triggerdotdev/trigger.dev/blob/ebe78017efdf7bd53c0e4414a8302b7f0ff2648d/references/job-catalog/src/events.ts#L26
2. Test that it comes through correctly
3. Test that ""github"" still works (that uses companyicons)

## Tasks
- [ ] Add support for tabler-icons
- [ ] Update the docs with a mention and link to tabler-icons instead of font-awesome




<sub>[TRI-1401](https://linear.app/triggerdotdev/issue/TRI-1401/feat-add-support-for-tabler-icons-when-using-the-icon-for-tasks)</sub>",,
1941868788,615,[TRI-1400] Create a Gadget adapter,"@edlaver has written up a detailed guide on how to use Trigger.dev with [Gadget.dev](https://gadget.dev/) that we should use to create an official adapter package at `@trigger.dev/gadget`.

https://gist.github.com/edlaver/e9e0f9bf48e2b5674659c2eb091b6f7b

**_Please make sure to use Typescript for all code_**

### Task 1 - Gadget.dev Adaptor
- [ ] Create a new folder in `packages` called `gadget`
- [ ] Create the adaptor for Gadget following the gist above
- [ ] Create a basic Gadget.dev project that uses the adaptor in `references/gadget` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/gadget` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference gadget.dev where needed, including updating the the URLs.

### Task 3 – Write the documentation
- [ ] Create the `manual-setup-gadget.mdx` file in `/docs/_snippets/`. Use this file to write your documentation. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

<sub>[TRI-1400](https://linear.app/triggerdotdev/issue/TRI-1400/create-a-gadget-adapter)</sub>",,
1941699718,614,[TRI-1399] feat: Add ability to display images in the Run dashboard using image properties,"### Is your feature request related to a problem? Please describe.

We currently support task properties with text and an optional URL (that renders the property as a link). It would be really cool to be able to support previewing image urls in Task Properties, especially for OpenAI image tasks (and for Dalle 3 once API support is released).

### Describe the solution you'd like to see

Add another field to [DisplayPropertySchema](https://github.com/triggerdotdev/trigger.dev/blob/29ca09e42df3a8e5a34e00054ccc808826ca645d/packages/core/src/schemas/properties.ts#L4) called `image` that is either a string url or an array of strings:

```
export const DisplayPropertySchema = z.object({
  /** The label for the property */
  label: z.string(),
  /** The value of the property */
  text: z.string(),
  /** The URL to link to when the property is clicked */
  url: z.string().optional(),
  image: z.string().or(z.string().array()).optional()
});
```

Then we would use that to display the images in the task in a photo carousel

![CleanShot 2023-10-13 at 11 36 54](https://github.com/triggerdotdev/trigger.dev/assets/534/507b668c-488e-4581-b2cc-35548ed53fcd)


### Describe alternate solutions

N/A

### Additional information

_No response_

<sub>[TRI-1399](https://linear.app/triggerdotdev/issue/TRI-1399/feat-add-ability-to-display-images-in-the-run-dashboard-using-image)</sub>",,
1941675124,613,[TRI-1398] feat: CLI init should add maxDuration to the api/trigger route for Next.js,"On Vercel, even if you're on a paid plan, the max duration of an API route is not what you're paying unless you configure it.

The api/trigger file:

```ts
import { createAppRoute } from ""@trigger.dev/nextjs"";
import { client } from ""@/trigger"";

import ""@/jobs"";

//this route is used to send and receive data with Trigger.dev
export const { POST, dynamic } = createAppRoute(client);

//uncomment this to set a higher max duration (it must be inside your plan limits). Full docs: https://vercel.com/docs/functions/serverless-functions/runtimes#max-duration
//export const maxDuration = 60;
```

There are two different ways to specify the max duration, it depends on which version of Next.js you're on. Info here: https://vercel.com/docs/functions/serverless-functions/runtimes#max-duration

## Tasks
- [ ] For the appropriate Next.js versions add commented out lines to the api/trigger file (as in the above) using CLI init
- [ ] Log out a message to the console using `boxen` with a link to the docs. We do this elsewhere in the CLI. This will cover people who need to uncomment the lines or add it to their vercel.json file

<sub>[TRI-1398](https://linear.app/triggerdotdev/issue/TRI-1398/feat-cli-init-should-add-maxduration-to-the-apitrigger-route-for)</sub>",,
1938322906,609,feat: Cannot use `Table` as type from ``@trigger.dev/airtable``,"### Is your feature request related to a problem? Please describe.

Currently `@trigger.dev/airtable` does not export `declare class Table<TFields extends AirtableFieldSet> { ` causing issues when splitting code in to multiple functions for reusability. E.g.:

```ts
const table = io.airtableClient.base(AIRTABLE_BASE_ID).table<AirtableOrder>(AIRTABLE_TABLE_ID);
await runCreateAirtableOrder(table, shopifyOrderResponse.order);
```

Where the function that wants to use `Table` as type is defined such as
```ts
export async function runCreateAirtableOrder(table: Table<AirtableOrder>, shopifyOrder: ShopifyOrder) {
```

### Describe the solution you'd like to see

Export `Table` from `@trigger.dev/airtable`

### Describe alternate solutions

Perhaps documentation / guidelines on how to separate long jobs in to smaller functions.

### Additional information

_No response_",,
1937338345,603,[TRI-1394] Improve the Linear integration documentation,"## Overview:

Update the [Linear integration documentation](https://trigger.dev/docs/integrations/apis/linear) so it is much easier to use as a reference.

We have just overhauled our [GitHub documentation](https://trigger.dev/docs/integrations/apis/github) and would like all of the rest of our integrations to follow the same structure. 

_Please use the references and resources at the bottom of this post to complete this issue._

## Pages to add:

### Linear overview & authentication:

This page is currently [this](https://trigger.dev/docs/integrations/apis/linear).

- **Page Title:** Linear overview & authentication 
- **Sidebar title:** Overview & authentication 
- **Page content**: authentication with Linear, in the same format as this: https://trigger.dev/docs/integrations/apis/github

### Linear Triggers & events:

- **Page title:** Linear triggers & events 
- **Sidebar title:** Triggers & events 
- **Page content:** all the triggers and events available from our Linear integration, in the same format as this: https://trigger.dev/docs/integrations/apis/github-triggers

### Linear Tasks:

- **Page title:** Linear tasks 
- **Sidebar title:** Tasks 
- **Page content:** all the tasks available from our Linear integration, in the same format as this: https://trigger.dev/docs/integrations/apis/github-tasks. Also include one example at the bottom with clear comments. See references below for sample code.

### References & resources:

- Our current [Linear documentation](https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/apis/linear.mdx) in the GitHub repo.
- Example job code to use - [job catalog](https://github.com/triggerdotdev/trigger.dev/blob/main/references/job-catalog/src/linear.ts) and [jobs showcase](https://trigger.dev/showcase?tags=&integrations=linear).
- We use Mintlify for our docs, [documentation here](https://mintlify.com/docs/quickstart)

<sub>[TRI-1394](https://linear.app/triggerdotdev/issue/TRI-1394/improve-the-linear-integration-documentation)</sub>",,
1935565857,599,[TRI-1392] yarn dlx @trigger.dev/cli@latest init fails,"It seems to have an issue with the mock-fs package. This package needs to be in dependencies because of how we've setup some of the tests.

## To reproduce

Run `yarn dlx @trigger.dev/cli@latest init` in a blank Next.js project.

NOTE: this is only an issue with Yarn.

You'll see this output:

```
yarn dlx @trigger.dev/cli@latest init
➤ YN0000: ┌ Resolution step
➤ YN0032: │ fsevents@npm:2.3.3: Implicit dependencies on node-gyp are discouraged
➤ YN0000: └ Completed in 5s 870ms
➤ YN0000: ┌ Fetch step
➤ YN0000: └ Completed
➤ YN0000: ┌ Link step
➤ YN0000: │ ESM support for PnP uses the experimental loader API and is therefore experimental
➤ YN0007: │ ngrok@npm:5.0.0-beta.2 must be built because it never has been before or the last one failed
➤ YN0000: └ Completed in 0s 919ms
➤ YN0000: Done with warnings in 6s 937ms

/Users/matt/.yarn/berry/cache/mock-fs-npm-5.2.0-5103a7b507-8.zip/node_modules/mock-fs/lib/readfilecontext.js:43
  const origRead = prototype.read;
                             ^

TypeError: Cannot read properties of undefined (reading 'read')
    at exports.patchReadFileContext (/Users/matt/.yarn/berry/cache/mock-fs-npm-5.2.0-5103a7b507-8.zip/node_modules/mock-fs/lib/readfilecontext.js:43:30)
    at Object.<anonymous> (/Users/matt/.yarn/berry/cache/mock-fs-npm-5.2.0-5103a7b507-8.zip/node_modules/mock-fs/lib/index.js:57:1)
    at Module._compile (node:internal/modules/cjs/loader:1165:14)
    at Object.Module._extensions..js (node:internal/modules/cjs/loader:1219:10)
    at Object.require$$0.Module._extensions..js (/private/var/folders/6d/6cqqr2456_z22rz84zx9t8500000gn/T/xfs-2fbd7429/dlx-62739/.pnp.cjs:13867:33)
    at Module.load (node:internal/modules/cjs/loader:1043:32)
    at Function.require$$0.Module._load (/private/var/folders/6d/6cqqr2456_z22rz84zx9t8500000gn/T/xfs-2fbd7429/dlx-62739/.pnp.cjs:13686:22)
    at ModuleWrap.<anonymous> (node:internal/modules/esm/translators:169:29)
    at ModuleJob.run (node:internal/modules/esm/module_job:193:25)
    at processTicksAndRejections (node:internal/process/task_queues:96:5)
```

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1392](https://linear.app/triggerdotdev/issue/TRI-1392/yarn-dlx-triggerdevclilatest-init-fails)</sub>",,
1931500401,583,[TRI-1378] bug: Tasks with properties that are missing label/text fail to run,"For example, if you call `io.resend.sendEmail` with an undefined or null `from` parameter the task won't run because the requestBody will be invalid as there will be a property on the task with `text` set to undefined or null, and thus parsing the request body with `RunTaskOptionsSchema` will fail. We should be more lenient with the properties and stripe any out that have null or undefined values. BUT we should make sure the types for properties in `runTask` still show them as required and not optional.

To reproduce:

```ts
client.defineJob({
  id: ""send-resend-email"",
  name: ""Send Resend Email"",
  version: ""0.1.0"",
  trigger: eventTrigger({
    name: ""send.email"",
  }),
  integrations: {
    resend,
  },
  run: async (payload, io, ctx) => {
    const response = await io.resend.sendEmail(""📧"", {
      to: payload.to,
      subject: payload.subject,
      text: payload.text,
      from: payload.from,
    });

    await io.logger.info(""Sent email"", { response });
  },
});
```

Then you can test that job with a blank `from` in the payload.

<sub>[TRI-1378](https://linear.app/triggerdotdev/issue/TRI-1378/bug-tasks-with-properties-that-are-missing-labeltext-fail-to-run)</sub>",,
1931426490,582,[TRI-1377] Throwing a string from inside runTask doesn't bubble up properly to the run,"If you do this inside of run, the run fails (which is correct) but you get ""Unknown error"" on the run.

```ts
await io.runTask(
    ""a-task"",
    async () => {
       throw ""Shopify Order not found"";
    },
);
```

It works properly if you do `throw new Error(""Shopify Order not found"");`

<sub>[TRI-1377](https://linear.app/triggerdotdev/issue/TRI-1377/throwing-a-string-from-inside-runtask-doesnt-bubble-up-properly-to-the)</sub>",,
1928566304,569,"[TRI-1372] Add a framework adaptor for SolidStart, with manual setup docs","**_Please make sure to use Typescript for all code_**

### Task 1 - SolidStart Adaptor
- [ ] Create a new folder in `packages` called `solidstart`
- [ ] Create the adaptor for SolidStart. Use [this Next.js adaptor](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/nextjs/src/index.ts) code as reference when creating yours. Include all setup configurations to fully support the framework, e.g. Next.js requires adaptor support for both App and Pages routers.
- [ ] Create a basic SolidStart project that uses the adaptor in `references/solidstart` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/solidstart` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference SolidStart where needed, including updating the the URLs.

### Task 3 – Write the documentation
- [ ] Create a manual setup guide in the docs. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 4 – Update the webapp onboarding
- [ ] Create a `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.solidstart` with the onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.
![CleanShot 2023-09-07 at 16 42 14](https://github.com/triggerdotdev/trigger.dev/assets/7555566/e235930d-f99e-408f-bc72-e98ce3d18892)


<sub>[TRI-1372](https://linear.app/triggerdotdev/issue/TRI-1372/add-a-framework-adaptor-for-solidstart-with-manual-setup-docs)</sub>",,
1926321783,553,[TRI-1362] docs: Add better documentation for how to use Task Callbacks,"We currently only have a small amount of documentation for task callbacks in the [io.runTask()](https://trigger.dev/docs/sdk/io/runtask) docs but it would be great to flesh out the documentation in more detail, especially usage with just `io.runTask` instead of `io.replicate.runTask`, e.g.:

```ts
await io.runTask(
  ""use-callback-url"",
  async (task) => {
    // task.callbackUrl is the URL to call when the task is done
    // The output of this task will be the body POSTed to this URL
  },
  {
    name: ""Use the callbackUrl to notify the caller when the task is done"",
    callback: {
      enabled: true,
      timeoutInSeconds: 300, // If task.callbackUrl is not called within 300 seconds, the task will fail
    },
  }
);
```

Things the doc should cover:

 - When it makes sense to use callback URLs (a callback from an external system). Would be great to find another example of this other than Replicate
 - How to correctly type runTask so the output type is correct
 - How the request to the task URL works (POST and the entire JSON body becomes the task output)
 - How the timeout works

I think this would probably best live in Documentation -> Guides -> Task Callbacks

<sub>[TRI-1362](https://linear.app/triggerdotdev/issue/TRI-1362/docs-add-better-documentation-for-how-to-use-task-callbacks)</sub>",,
1925999381,545,"[TRI-1357] bug: On an integration page, the Jobs table doesn't show jobs that only use the integration for the trigger","### Describe the bug

The integration page has a table with the jobs associated with the integration. In that table only jobs that use the integration inside the run function appear. If you are just using the integration for a trigger, it won't appear in the table.

### To reproduce

1. Create this Job

```
//you'll need to import the client from whichever file you created it in
import { Github, events } from ""@trigger.dev/github"";

const github = new Github({ id: ""github"" });

// Sends a Slack message to a channel if a GitHub issue is left open for 24 hours
client.defineJob({
  id: ""github-new-issue-reminder"",
  name: ""GitHub: new issue reminder"",
  version: ""1.0.0"",
  trigger: github.triggers.repo({
    event: events.onIssueOpened,
    owner: ""<your-org-name>"",
    repo: ""<your-repo-name>"",
  }),
  run: async (payload, io, ctx) => {    
  },
});
```

1. Make sure this Job code is run, by importing into the jobs index file, or importing into the api/trigger route.
2. Run the site and the CLI dev command
3. Got to the integrations page and connect to the GitHub integration
4. Now click through from that page to the GItHub integration page, note how the Table doesn't show any Jobs.
![CleanShot_2023-10-04_at_12 57 17](https://github.com/triggerdotdev/trigger.dev/assets/10635986/d756c6c4-773a-47d6-b98c-929295758701)


<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1357](https://linear.app/triggerdotdev/issue/TRI-1357/bug-on-an-integration-page-the-jobs-table-doesnt-show-jobs-that-only)</sub>",,
1922339463,526,[TRI-1334] [TRI-1331] CLI warning if using @trigger.dev/react package with Next.js pages directory,"## Problem

We add the `@trigger.dev/react` package when you run `npx @trigger.dev/cli@latest init` in a Next.js project. The Next.js pages directory has a known issue with ESM modules.

We currently have an open issue but this still isn't great: [https://github.com/triggerdotdev/trigger.dev/issues/331](https://github.com/triggerdotdev/trigger.dev/issues/331)

## Solution

Show a clear warning in our CLI init command that gives you instructions on what to do, if you're using Next.js + pages router. 

### If on Next.js >13.1, add this to next.config file:

```
const nextConfig = {
  transpilePackages: [""@trigger.dev/react""],
};

module.exports = nextConfig;
```

### If on Next.js <13.1, add this to next.config file:

1. Install next-transpile-modules package

```
const withTM = require('next-transpile-modules')(['@trigger.dev/react']); // pass the modules you would like to see transpiled

module.exports = withTM({
  //...existing config object
});
```

### How to

* It makes most sense to add this to [the post-install step](https://github.com/triggerdotdev/trigger.dev/blob/e350659e244e6976747f726984c83a780ba94882/packages/cli/src/frameworks/nextjs/index.ts#L91).
* There's already a function to check for pages directory that can be used

  ```
  const nextJsDir = await detectPagesOrAppDir(path);
  ```
* [Here's some code](https://github.com/triggerdotdev/trigger.dev/blob/e350659e244e6976747f726984c83a780ba94882/packages/cli/src/frameworks/nextjs/index.ts#L111) that could potentially be adapted to check the Next.js version. But be careful when checking versions because special characters are used in package.json files, like ""^"" and ""\*"". So either you should get the actual version installed (not using the package.json) or use a semver package to do the comparison.
* Drawing a box using `boxen` would be a nice way to highlight this information, see [this code](https://github.com/triggerdotdev/trigger.dev/blob/e350659e244e6976747f726984c83a780ba94882/packages/cli/src/frameworks/express/index.ts#L39) for an example.

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1331](https://linear.app/triggerdotdev/issue/TRI-1331/cli-warning-if-using-triggerdevreact-package-with-nextjs-pages)</sub>

<sub>[TRI-1334](https://linear.app/triggerdotdev/issue/TRI-1334/[tri-1331]-cli-warning-if-using-triggerdevreact-package-with-nextjs)</sub>",,
1917122842,515,[TRI-1310] Add a Deno adaptor,"This have a pre-requisite before it's possible:

\#252

### What needs to be done?

After the above issue is completed, the adaptor should be straight forward.

A new adaptor in `packages/deno` needs to be created. There are several to look at as inspiration, the simplest being Remix: [https://github.com/triggerdotdev/trigger.dev/blob/main/packages/remix/src/index.ts](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/remix/src/index.ts)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1310](https://linear.app/triggerdotdev/issue/TRI-1310/add-a-deno-adaptor)</sub>",,
1913245521,509,[TRI-1296] feat: CLI dev should work with injected environment variables,"### Is your feature request related to a problem? Please describe.

The CLI dev command fails if you don't use .env files – instead using something like 1Password to inject the values.

### Describe the solution you'd like to see

Make the @trigger.dev/cli first check if the TRIGGER_API_KEY is defined in the current process.

### Additional information

This is the relevant code: [https://github.com/triggerdotdev/trigger.dev/blob/main/packages/cli/src/utils/getTriggerApiDetails.ts#L36](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/cli/src/utils/getTriggerApiDetails.ts#L36)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1296](https://linear.app/triggerdotdev/issue/TRI-1296/feat-cli-dev-should-work-with-injected-environment-variables)</sub>",,
1907680995,497,[TRI-1287] bug:  dynamic trigger registrations that don't succeed should disable the event dispatcher,"### Provide environment information

```
  System:
    OS: macOS 13.5.1
    CPU: (10) arm64 Apple M1 Max
    Memory: 769.42 MB / 32.00 GB
    Shell: 5.9 - /bin/zsh
  Binaries:
    Node: 18.12.1 - ~/.nvm/versions/node/v18.12.1/bin/node
    npm: 8.19.2 - ~/.nvm/versions/node/v18.12.1/bin/npm
    pnpm: 7.18.1 - ~/.nvm/versions/node/v18.12.1/bin/pnpm
```

### Describe the bug

When registering a dynamic trigger, if the registration job fails, the Event Dispatcher associated with that registration is still active. It needs to be disabled in the case  the registration job fails. This could cause duplicate runs.

### Reproduction repo

N/A

### To reproduce

```ts
import { Github, events } from ""@trigger.dev/github"";

const dynamicOnIssueOpenedTrigger = client.defineDynamicTrigger({
  id: ""github-issue-opened"",
  event: events.onIssueOpened,
  source: github.sources.repo,
});

const github = new Github({ id: ""github"", token: process.env.GITHUB_PAT! });

client.defineJob({
  id: ""register-issue-opened"",
  name: ""Register Issue Opened for Account"",
  version: ""0.0.1"",
  trigger: eventTrigger({
    name: ""register.issue.opened"",
  }),
  run: async (payload, io, ctx) => {
    await dynamicOnIssueOpenedTrigger.register(
      payload.id,
      {
        owner: payload.owner,
        repo: payload.repo,
      }
    );
  },
});

client.defineJob({
  id: ""dynamic-issue-opened"",
  name: ""Dynamic Issue Opened for Account"",
  version: ""0.0.1"",
  trigger: dynamicOnIssueOpenedTrigger,
  integrations: {
    github,
  },
  run: async (payload, io, ctx) => {
    await io.github.issues.createComment(""create-issue-comment"", {
      owner: payload.repository.owner.login,
      repo: payload.repository.name,
      issueNumber: payload.issue.number,
      body: `Hello there: \n\n\`\`\`json\n${JSON.stringify(
        payload,
        null,
        2
      )}\`\`\`\n\n\`\`\`json\n${JSON.stringify(ctx, null, 2)}\`\`\``,
    });
  },
});
```

Use the preceding code and make sure the GITHUB_PAT does not have webhook read&write scope.

1. Run the `register-issue-opened` job with the `id`, `owner`, and `repo` payload
2. Fix the GITHUB_PAT to be able to do webhook read&write
3. Make sure to restart
4. Run the `register-issue-opened` job with the same `id`, `owner`, and `repo` payload as Step 1
5. Create an issue on the repo
6. Notice that two runs have occurred

### Additional information

_No response_

<sub>[TRI-1287](https://linear.app/triggerdotdev/issue/TRI-1287/bug-dynamic-trigger-registrations-that-dont-succeed-should-disable-the)</sub>",,
1900766921,487,bug: Type Instantiation is excessively deep Error when Defining a Job schema with `eventTrigger`,"### Provide environment information


  System:
    OS: Linux 6.1 Manjaro Linux
    CPU: (16) x64 Intel(R) Core(TM) i7-10870H CPU @ 2.20GHz
    Memory: 20.98 GB / 31.13 GB
    Container: Yes
    Shell: 5.1.16 - /bin/bash
  Binaries:
    Node: 20.5.1 - ~/.nvm/versions/node/v20.5.1/bin/node
    Yarn: 1.22.19 - ~/.nvm/versions/node/v20.5.1/bin/yarn
    npm: 9.8.0 - ~/.nvm/versions/node/v20.5.1/bin/npm


### Describe the bug

#### Description
While implementing a job that fetches and stores Discourse posts using the Trigger.dev SDK and Supabase, I encountered a TypeScript error: ""Type instantiation is excessively deep and possibly infinite (ts2589)"".

The error occurs when defining the `eventTrigger` as shown below:

```typescript
client.defineJob({
  id: ""discourse-example-job"",
  name: ""Fetch and Store Discourse Posts"",
  version: ""0.0.1"",
  trigger: eventTrigger({
    name: ""supabase.fetch-data"",
    schema: z.object({
      org_id: z.string(),
      base_discourse_url: z.string(),
    }),
  }),
  // ... (rest of the code)
});
```
Error Message

`Type instantiation is excessively deep and possibly infinite.ts(2589)`

### Reproduction repo

Private Repo

### To reproduce

### Steps to Reproduce
1. Define a job using client.defineJob
2. Inside the eventTrigger method, define a z.object schema with the properties as shown above.
3. Upon doing so, the TypeScript error appears.

### Expected Behavior
I expect to be able to define the job's trigger with eventTrigger and the z.object schema without encountering a TypeScript error.


### Additional information

### Additional Information

 ""@trigger.dev/nextjs"": ""^2.0.14"",
    ""@trigger.dev/react"": ""^2.1.0"",
    ""@trigger.dev/sdk"": ""^2.0.14"",
    ""@trigger.dev/supabase"": ""^2.0.14"",
    
  Node version: v20.5.1
",,
1899085737,484,[TRI-1281] feat: Add an optional `to` param to `@trigger.dev/cli init update`,"### Is your feature request related to a problem? Please describe.

When running `npx @trigger.dev/cli@latest update` we should allow you to pass in a `to` option which would set the version to upgrade to (instead of the default which is ""latest"".

### Describe the solution you'd like to see

* Add a `to` option to the update command, default to ""latest"": [https://github.com/triggerdotdev/trigger.dev/blob/e350659e244e6976747f726984c83a780ba94882/packages/cli/src/cli/index.ts#L98](https://github.com/triggerdotdev/trigger.dev/blob/e350659e244e6976747f726984c83a780ba94882/packages/cli/src/cli/index.ts#L98)
* If the `to` flag isn't ""latest"" then get ncu to do the change without spitting out the confirmation. There's a flag called `upgrade` that should work. This file is where edits need to happen: [https://github.com/triggerdotdev/trigger.dev/blob/e350659e244e6976747f726984c83a780ba94882/packages/cli/src/commands/update.ts#L35](https://github.com/triggerdotdev/trigger.dev/blob/e350659e244e6976747f726984c83a780ba94882/packages/cli/src/commands/update.ts#L35)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1281](https://linear.app/triggerdotdev/issue/TRI-1281/feat-add-an-optional-to-param-to-triggerdevcli-init-update)</sub>",,
1892893561,469,[TRI-1273] Create a function call example for OpenAI,"It would be great to create a function call example for OpenAI here: https://github.com/triggerdotdev/trigger.dev/blob/main/examples/job-catalog/src/openai.ts

Use these docs for how to do function calling: https://gpt.pomb.us/

<sub>[TRI-1273](https://linear.app/triggerdotdev/issue/TRI-1273/create-a-function-call-example-for-openai)</sub>",,
1887949656,453,[TRI-1256] Framework: support for SvelteKit,"# Build support for SvelteKit into Trigger.dev

**_Please make sure to use Typescript for all code_**

### Task 1 - SvelteKit Adaptor
- [ ] Create a new folder in `packages` called `svelteKit`
- [ ] Create the adaptor for SvelteKit. Use [this Next.js adaptor](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/nextjs/src/index.ts) code as reference when creating yours. Include all setup configurations to fully support the framework, e.g. Next.js requires adaptor support for both App and Pages routers.
- [ ] Create a basic SvelteKit project that uses the adaptor in `examples/svelteKit` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/svelteKit` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference SvelteKit where needed, including updating the the URLs.

### Task 3 – Write the documentation
- [ ] Locate the `manual-setup-svelteKit.mdx` folder in `/docs/_snippets/`. Use this file to write your documentation, overwriting any contents of that file. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 4 – Update the webapp onboarding
- [ ] In the `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.svelteKit` replace the `<FrameworkComingSoon/>` component with your new onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.
![CleanShot 2023-09-07 at 16 42 14](https://github.com/triggerdotdev/trigger.dev/assets/7555566/e235930d-f99e-408f-bc72-e98ce3d18892)

<sub>[TRI-1256](https://linear.app/triggerdotdev/issue/TRI-1256/framework-support-for-sveltekit)</sub>",,
1887945446,452,[TRI-1255] Framework: support for Astro,"# Build support for Astro into Trigger.dev

**_Please make sure to use Typescript for all code_**

### Task 1 - Astro Adaptor
- [ ] Create a new folder in `packages` called `astro`
- [ ] Create the adaptor for Astro. Use [this Next.js adaptor](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/nextjs/src/index.ts) code as reference when creating yours. Include all setup configurations to fully support the framework, e.g. Next.js requires adaptor support for both App and Pages routers.
- [ ] Create a basic Astro project that uses the adaptor in `examples/astro` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/astro` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference Astro where needed, including updating the the URLs.

### Task 3 – Write the documentation
- [ ] Locate the `manual-setup-astro.mdx` folder in `/docs/_snippets/`. Use this file to write your documentation, overwriting any contents of that file. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 4 – Update the webapp onboarding
- [ ] In the `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.astro` replace the `<FrameworkComingSoon/>` component with your new onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.
![CleanShot 2023-09-07 at 16 42 14](https://github.com/triggerdotdev/trigger.dev/assets/7555566/e235930d-f99e-408f-bc72-e98ce3d18892)

<sub>[TRI-1255](https://linear.app/triggerdotdev/issue/TRI-1255/framework-support-for-astro)</sub>",,
1887942893,451,[TRI-1254] Framework: support for Express,"# Build support for Express into Trigger.dev

**_Please make sure to use Typescript for all code_**

### Task 1 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/express` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference Express where needed, including updating the the URLs.

### Task 2 – Write the documentation
- [ ] Locate the `manual-setup-express.mdx` folder in `/docs/_snippets/`. Use this file to write your documentation, overwriting any contents of that file. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 3 – Update the webapp onboarding
- [ ] In the `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.express` replace the `<FrameworkComingSoon/>` component with your new onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.
![CleanShot 2023-09-07 at 16 42 14](https://github.com/triggerdotdev/trigger.dev/assets/7555566/e235930d-f99e-408f-bc72-e98ce3d18892)

<sub>[TRI-1254](https://linear.app/triggerdotdev/issue/TRI-1254/framework-support-for-express)</sub>",,
1887941244,450,[TRI-1253] Framework: support for Fastify,"# Build support for Fastify into Trigger.dev

**_Please make sure to use Typescript for all code_**

### Task 1 - Fastify Adaptor
- [ ] Create a new folder in `packages` called `fastify`
- [ ] Create the adaptor for Fastify. Use [this Next.js adaptor](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/nextjs/src/index.ts) code as reference when creating yours. Include all setup configurations to fully support the framework, e.g. Next.js requires adaptor support for both App and Pages routers.
- [ ] Create a basic Fastify project that uses the adaptor in `examples/fastify` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/fastify` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference Fastify where needed, including updating the the URLs.

### Task 3 – Write the documentation
- [ ] Locate the `manual-setup-fastify.mdx` folder in `/docs/_snippets/`. Use this file to write your documentation, overwriting any contents of that file. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 4 – Update the webapp onboarding
- [ ] In the `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.fastify` replace the `<FrameworkComingSoon/>` component with your new onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.
![CleanShot 2023-09-07 at 16 42 14](https://github.com/triggerdotdev/trigger.dev/assets/7555566/e235930d-f99e-408f-bc72-e98ce3d18892)

<sub>[TRI-1253](https://linear.app/triggerdotdev/issue/TRI-1253/framework-support-for-fastify)</sub>",,
1887939147,449,[TRI-1252] Framework: support for Nest.js,"# Build support for Nest.js into Trigger.dev

**_Please make sure to use Typescript for all code_**

### Task 1 - Nest.js Adaptor
- [ ] Create a new folder in `packages` called `nestjs`
- [ ] Create the adaptor for Nest.js. Use [this Next.js adaptor](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/nextjs/src/index.ts) code as reference when creating yours. Include all setup configurations to fully support the framework, e.g. Next.js requires adaptor support for both App and Pages routers.
- [ ] Create a basic Nest.js project that uses the adaptor in `examples/nestjs` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/nestjs` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference Nest.js where needed, including updating the the URLs.

### Task 3 – Write the documentation
- [ ] Locate the `manual-setup-nestjs.mdx` folder in `/docs/_snippets/`. Use this file to write your documentation, overwriting any contents of that file. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 4 – Update the webapp onboarding
- [ ] In the `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.nestjs` replace the `<FrameworkComingSoon/>` component with your new onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.
![CleanShot 2023-09-07 at 16 42 14](https://github.com/triggerdotdev/trigger.dev/assets/7555566/e235930d-f99e-408f-bc72-e98ce3d18892)

<sub>[TRI-1252](https://linear.app/triggerdotdev/issue/TRI-1252/framework-support-for-nestjs)</sub>",,
1887936714,448,[TRI-1251] Framework: support for Redwood.js,"# Build support for Redwood into Trigger.dev

**_Please make sure to use Typescript for all code_**

### Task 1 - Redwood Adaptor
- [ ] Create a new folder in `packages` called `redwood`
- [ ] Create the adaptor for Redwood. Use [this Next.js adaptor](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/nextjs/src/index.ts) code as reference when creating yours. Include all setup configurations to fully support the framework, e.g. Next.js requires adaptor support for both App and Pages routers.
- [ ] Create a basic Redwood project that uses the adaptor in `examples/redwood` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/redwood` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference Redwood where needed, including updating the the URLs.

### Task 3 – Write the documentation
- [ ] Locate the `manual-setup-redwood.mdx` folder in `/docs/_snippets/`. Use this file to write your documentation, overwriting any contents of that file. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 4 – Update the webapp onboarding
- [ ] In the `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.redwood` replace the `<FrameworkComingSoon/>` component with your new onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.
![CleanShot 2023-09-07 at 16 42 14](https://github.com/triggerdotdev/trigger.dev/assets/7555566/e235930d-f99e-408f-bc72-e98ce3d18892)

<sub>[TRI-1251](https://linear.app/triggerdotdev/issue/TRI-1251/framework-support-for-redwoodjs)</sub>",,
1887861160,447,[TRI-1250] Framework: support for Nuxt,"# Build support for Nuxt into Trigger.dev

***Please make sure to use Typescript for all code***

### Task 1 - Nuxt Adaptor

- [ ] Create a new folder in `packages` called `nuxt`
- [ ] Create the adaptor for Nuxt. Use [this Next.js adaptor](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/nextjs/src/index.ts) code as reference when creating yours. Include all setup configurations to fully support the framework, e.g. Next.js requires adaptor support for both App and Pages routers.
- [ ] Create a basic Nuxt project that uses the adaptor in `examples/nuxt` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a [README.md](http://README.md) file

- [ ] Create a new [README.md](http://README.md) file inside the `packages/nuxt` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference Nuxt where needed, including updating the the URLs.

### Task 3 – Write the documentation

- [ ] Locate the `manual-setup-nuxt.mdx` folder in `/docs/_snippets/`. Use this file to write your documentation, overwriting any contents of that file. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 4 – Update the webapp onboarding

- [ ] In the `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.nuxt` replace the `<FrameworkComingSoon/>` component with your new onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.

![](https://uploads.linear.app/80a884b1-f84c-49d6-91db-07a391663d20/8994af96-bd76-4767-a1f1-0bea2cc98e2a/d235a893-1c57-4645-8651-432f7764357d?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzgwYTg4NGIxLWY4NGMtNDlkNi05MWRiLTA3YTM5MTY2M2QyMC84OTk0YWY5Ni1iZDc2LTQ3NjctYTFmMS0wYmVhMmNjOThlMmEvZDIzNWE4OTMtMWM1Ny00NjQ1LTg2NTEtNDMyZjc3NjQzNTdkIiwiaWF0IjoxNzExNjM0MDYzLCJleHAiOjE3MTE3MjA0NjN9.lWJgPEDs19uLEJ9IKBe4fjK9lSnMGbInwng4SH6Fzj8)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1250](https://linear.app/triggerdotdev/issue/TRI-1250/framework-support-for-nuxt)</sub>",,
1887806623,445,[TRI-1249] Framework: Support for Remix,"# Build support for Remix into Trigger.dev

**_Please make sure to use Typescript for all code_**

### Task 1 - Remix Adaptor
- [ ] Create a new folder in `packages` called `remix`
- [ ] Create the adaptor for Remix. Use [this Next.js adaptor](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/nextjs/src/index.ts) code as reference when creating yours. Include all setup configurations to fully support the framework, e.g. Next.js requires adaptor support for both App and Pages routers.
- [ ] Create a basic Remix project that uses the adaptor in `examples/remix` folder. Include a basic Job in Trigger.dev, e.g. a simple Job that just does a delay inside it. Screen grab the full Run dashboard page showing it successfully worked. Here are examples of how to do cross-project references in [package.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/package.json#L14) and [tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/aae143d96e1cd3c2b2b2ccb5120f75651a4261d0/examples/nextjs-example/tsconfig.json#L31).
- [ ] Provide a screen grab of your terminal showing the Adaptor is working

### Task 2 – Add a README.md file
- [ ] Create a new README.md file inside the `packages/remix` folder and copy in the contents from `packages/nextjs/README.md`. Adjust the wording to reference Remix where needed, including updating the the URLs.

### Task 3 – Write the documentation
- [ ] Locate the `manual-setup-remix.mdx` folder in `/docs/_snippets/`. Use this file to write your documentation, overwriting any contents of that file. Follow the structure of [this Next.js example](https://trigger.dev/docs/documentation/guides/manual/nextjs) for reference when writing yours.
- [ ] Update the table at the bottom of the `client-adaptors.mdx` page with the framework you’ve worked on.

### Task 4 – Update the webapp onboarding
- [ ] In the `route.tsx` page located in `_app.orgs.$organizationSlug.projects.$projectParam.setup.remix` replace the `<FrameworkComingSoon/>` component with your new onboarding steps. Follow the same structure as the Next.js example when creating your own. Ignore the very top step for adding this framework to a new project, just focus on the steps to add it to an existing project (so don’t include the `<RadioGroup/>` toggle selector at the top). Make sure you also include the `useProjectSetupComplete();` hook at the top of the page – this triggers a particle effect when the new job is successfully created and redirects to the Jobs list 🥳 .
- [ ] In the `FrameworkSelector.tsx` file, add “supported” to the framework you’ve worked on.
![CleanShot 2023-09-07 at 16 42 14](https://github.com/triggerdotdev/trigger.dev/assets/7555566/e235930d-f99e-408f-bc72-e98ce3d18892)

<sub>[TRI-1249](https://linear.app/triggerdotdev/issue/TRI-1249/framework-support-for-remix)</sub>",,
1882401344,436,"[TRI-1230] TypeScript ""Type instantiation is excessively deep and possibly infinite.ts(2589)"" error when using eventTrigger w/zod schema (different Zod versions)","When using the `eventTrigger` with zod to define the event schema TypeScript gives this error:

![](https://uploads.linear.app/80a884b1-f84c-49d6-91db-07a391663d20/4bca3b0b-e32b-420d-8198-f5f3e52d8733/66f377c7-1a97-42ec-b5ad-8b4c4974672c?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzgwYTg4NGIxLWY4NGMtNDlkNi05MWRiLTA3YTM5MTY2M2QyMC80YmNhM2IwYi1lMzJiLTQyMGQtODE5OC1mNWYzZTUyZDg3MzMvNjZmMzc3YzctMWE5Ny00MmVjLWI1YWQtOGI0YzQ5NzQ2NzJjIiwiaWF0IjoxNjkzOTMzMjU5LCJleHAiOjE2OTQwMTk2NTl9.f8-Cl_2WEvsRxv1wuGksLGbbDnPNRK2uvoC2R60AYSE)

This only seems to be happening in Next.js projects created with `create-t3-app`. I've reproduced it here:

[https://github.com/ericallam/t3-trigger-app/blob/bbade197052ae5d790c7b46509628a5c8d57ba94/src/jobs/examples.ts#L19](https://github.com/ericallam/t3-trigger-app/blob/bbade197052ae5d790c7b46509628a5c8d57ba94/src/jobs/examples.ts#L19)

We need to track down the issue and figure out how to fix it (or provide a workaround for t3-app)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1230](https://linear.app/triggerdotdev/issue/TRI-1230/typescript-possibly-infinite-error-when-using-eventtrigger-wzod-schema)</sub>",,
1878016760,426,[TRI-1200] `@trigger.dev/stripe` triggers should not allow invalid events,"Currently we don't do any client-side filtering of events passed to triggers:

```
stripe.onPrice({ events: [""price.created"", ""this.is.invalid""] })
```

Other than TypeScript errors, nothing will stop the above trigger to attempt to register the `this.is.invalid` event, which will result in an error response from the Stripe API. We should filter these out (and print a warning) to prevent this issue.

<sub>[TRI-1200](https://linear.app/triggerdotdev/issue/TRI-1200/triggerdevstripe-triggers-should-not-allow-invalid-events)</sub>",,
1875267653,425,feature request: Supabase Management integration available to local supabase as well,"## Current issue
1. run supabase locally: `npx supabase start`
2. create a job using the Supabase Management SDK on local. 
3. the following error occurs and the integration is not created.

```
Error: Failed to run query: Unauthorized (401): invalid signature
    at SupabaseManagementAPI.createResponseError_fn (/workspaces/nextjs-supabase-triggerdev-test/node_modules/supabase-management-js/dist/index.js:1102:10)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async SupabaseManagementAPI.runQuery (/workspaces/nextjs-supabase-triggerdev-test/node_modules/supabase-management-js/dist/index.js:626:13)
    at async executeTask (/workspaces/nextjs-supabase-triggerdev-test/node_modules/@trigger.dev/sdk/dist/index.js:930:24)
    at async ioConnection.<computed> [as runQuery] (/workspaces/nextjs-supabase-triggerdev-test/node_modules/@trigger.dev/sdk/dist/index.js:506:18)
    at async Object.register (/workspaces/nextjs-supabase-triggerdev-test/node_modules/@trigger.dev/supabase/dist/index.js:540:28)
    at async ExternalSource.register (/workspaces/nextjs-supabase-triggerdev-test/node_modules/@trigger.dev/sdk/dist/index.js:1810:21)
    at async Object.run (/workspaces/nextjs-supabase-triggerdev-test/node_modules/@trigger.dev/sdk/dist/index.js:1497:25)
    at async #executeJob (/workspaces/nextjs-supabase-triggerdev-test/node_modules/@trigger.dev/sdk/dist/index.js:1600:20)
    at async TriggerClient.handleRequest (/workspaces/nextjs-supabase-triggerdev-test/node_modules/@trigger.dev/sdk/dist/index.js:1312:25)
    at async handler (/workspaces/nextjs-supabase-triggerdev-test/node_modules/@trigger.dev/nextjs/dist/index.js:32:22)
```

## Cause
The `supabase-management-js` used internally assumes the use of the cloud version. Therefore, it is not possible to issue a webhook to a locally hosted supabase.
Furthermore, there is no API to enable webhooks in local supabase.

## Suggestion for improvement
### case 1
1. when creating a Supabase Management class, the connection string to the supabase-db can be passed as an argument.
2. the argument of 1. is given, execute the query of `createTriggerQuery` directly.

### case 2
case 1 is preferable because it can be automated, but if SQL execution is not preferred, this option is also available.

1. when creating a Supabase Management class, you can pass an option to omit automatic webhook create as an argument.
2. the argument of 1. is given, instead of executed the query of `createTriggerQuery`, output it to the log (to be executed manually by the user)",,
1870563880,422,[TRI-1170] Ensure `@trigger.dev/openai` background tasks have retry configuration,"These backgroundFetch tasks need to have their retry configuration set:

- [`backgroundCreateCompletion`](https://github.com/triggerdotdev/trigger.dev/blob/4685b630d90f6b63db691759c15f2fd6aa433e80/integrations/openai/src/tasks.ts)
- [`backgroundCreateChatCompletion`](https://github.com/triggerdotdev/trigger.dev/blob/4685b630d90f6b63db691759c15f2fd6aa433e80/integrations/openai/src/tasks.ts)

View the docs on `backgroundFetch` retry here: https://trigger.dev/docs/sdk/io/backgroundfetch

And the OpenAI error codes here: https://platform.openai.com/docs/guides/error-codes

<sub>[TRI-1170](https://linear.app/triggerdotdev/issue/TRI-1170/ensure-triggerdevopenai-background-tasks-have-retry-configuration)</sub>",,
1870555163,421,[TRI-1169] Create a Vercel integration package,"Vercel have webhook events that we could be exposed through a `@trigger.dev/vercel` integration:

[https://vercel.com/docs/observability/webhooks-overview/webhooks-api](https://vercel.com/docs/observability/webhooks-overview/webhooks-api)

They also have an API for registering webhooks that we can use:

[https://vercel.com/docs/rest-api/endpoints#webhooks](https://vercel.com/docs/rest-api/endpoints#webhooks)

# Useful docs/code

* [Development guide](https://github.com/triggerdotdev/trigger.dev/blob/main/CONTRIBUTING.md)
* [Create integration guide](https://trigger.dev/docs/integrations/create)
* [Other integration packages](https://github.com/triggerdotdev/trigger.dev/tree/main/integrations), especially ones with webhooks like GitHub, Typeform, and Linear.

# Requirements

* Make sure that you have fully tested that each webhook works and comes through to your locally running dashboard
* Make sure you've implemented the best practice security in verifying the payloads. Vercel talk about this in their linked docs above.
* Make sure to add Vercel to the [integrationCatalog](https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/services/externalApis/integrationCatalog.server.ts).

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1169](https://linear.app/triggerdotdev/issue/TRI-1169/create-a-vercel-integration-package)</sub>",,
1870538742,420,"[TRI-1168] When indexing Jobs, if they fail to parse the errors don't get sent back to users","To reproduce create a Job with an interval of less than 60 seconds, and reun `npx @trigger.dev/cli@latest dev`

```
client.defineJob({
  // This is the unique identifier for your Job, it must be unique across all Jobs in your project
  id: ""job-3"",
  name: ""Third job"",
  version: ""0.0.3"",
  // This is triggered by an event using eventTrigger. You can also trigger Jobs with webhooks, on schedules, and more: https://trigger.dev/docs/documentation/concepts/triggers/introduction
  trigger: intervalTrigger({
    seconds: 5,
  }),
  run: async (payload, io, ctx) => {
    await io.logger.info(""You console it! 🤦"");
  },
});
```

This will silently fail to appear in the dashboard and will stop all other Jobs from registering as well.

We need to change this code to use safeParse and to return an error with the details if it fails.

[https://github.com/triggerdotdev/trigger.dev/blob/1d7e5737a0234b5654a685b08f5c09720018fbb9/apps/webapp/app/services/endpointApi.server.ts#L131](https://github.com/triggerdotdev/trigger.dev/blob/1d7e5737a0234b5654a685b08f5c09720018fbb9/apps/webapp/app/services/endpointApi.server.ts#L131)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1168](https://linear.app/triggerdotdev/issue/TRI-1168/when-indexing-jobs-if-they-fail-to-parse-the-errors-dont-get-sent-back)</sub>",,
1865576522,393,[TRI-1151] Lower maxAttempts for specific tasks when those tasks call to development endpoints,"For the following worker tasks:

* performRunExecutionV2
* deliverHttpSourceRequest
* indexEndpoint

We currently are setting the maxAttempts statically to:

* performRunExecutionV2 to 12
* deliverHttpSourceRequest to 14
* indexEndpoint to 7

While those values make sense when they are hitting production endpoints, as we want to retry just in case production endpoints are temporary down for whatever reason, they really don't make sense for development endpoints, since development endpoints are usually either running or not, so maxAttempts should be set to 1.

This would greatly reduce the graphile worker load for these tasks.

So we should set the maxAttempts for these at `enqueue` time.

### performRunExecutionV2

This is enqueued from a single location:

[https://github.com/triggerdotdev/trigger.dev/blob/1fd1d267800647af8139851bc22876cbf4643d5f/apps/webapp/app/models/jobRunExecution.server.ts#L32](https://github.com/triggerdotdev/trigger.dev/blob/1fd1d267800647af8139851bc22876cbf4643d5f/apps/webapp/app/models/jobRunExecution.server.ts#L32)

We can add an option to

```
export type EnqueueRunExecutionV2Options = {
  runAt?: Date;
  resumeTaskId?: string;
  isRetry?: boolean;
  skipRetrying?: boolean;
};

export async function enqueueRunExecutionV2(
  run: JobRun,
  tx: PrismaClientOrTransaction,
  options: EnqueueRunExecutionV2Options = {}
) {
  const job = await executionWorker.enqueue(
    ""performRunExecutionV2"",
    {
      id: run.id,
      reason: run.status === ""PREPROCESSING"" ? ""PREPROCESS"" : ""EXECUTE_JOB"",
      resumeTaskId: options.resumeTaskId,
      isRetry: typeof options.isRetry === ""boolean"" ? options.isRetry : false,
    },
    {
      queueName: `job:${run.jobId}:env:${run.environmentId}`,
      tx,
      runAt: options.runAt,
      jobKey: `job_run:${run.id}`,
      maxAttempts: options.skipRetrying ? 1 : undefined
    }
  );
}
```

Then we'd just have to update the calls to `enqueueRunExecutionV2` to add `skipRetrying = true` in certain envs:

[https://github.com/triggerdotdev/trigger.dev/blob/1fd1d267800647af8139851bc22876cbf4643d5f/apps/webapp/app/services/runs/startRun.server.ts#L86](https://github.com/triggerdotdev/trigger.dev/blob/1fd1d267800647af8139851bc22876cbf4643d5f/apps/webapp/app/services/runs/startRun.server.ts#L86)

```
await enqueueRunExecutionV2(updatedRun, this.#prismaClient, {
   skipRetrying: run.environment.type === RuntimeEnvironmentType.DEVELOPMENT,
});
```

### deliverHttpSourceRequest

This is enqueued in one place:

[https://github.com/triggerdotdev/trigger.dev/blob/1fd1d267800647af8139851bc22876cbf4643d5f/apps/webapp/app/services/sources/handleHttpSource.server.ts#L50](https://github.com/triggerdotdev/trigger.dev/blob/1fd1d267800647af8139851bc22876cbf4643d5f/apps/webapp/app/services/sources/handleHttpSource.server.ts#L50)

The `TriggerSource` has an environment relation so can easily just use that to set the maxAttempts to 1 in dev.

### indexEndpoint

This is enqueued from multiple places, e.g.:

[https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/routes/api.v1.endpoints.$environmentId.$endpointSlug.index.$indexHookIdentifier.ts/#L115](https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/routes/api.v1.endpoints.$environmentId.$endpointSlug.index.$indexHookIdentifier.ts/#L115)

The Endpoint itself has a relation to the environment so it should work similar to how indexEndpoint is enqueued.

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1151](https://linear.app/triggerdotdev/issue/TRI-1151/lower-maxattempts-for-specific-tasks-when-those-tasks-call-to)</sub>",,
1865537583,392,[TRI-1150] Cleanup failed graphile worker tasks,"Currently we don't delete graphile worker tasks that have failed. (their attempts = maxAttempts). We should run a periodic process to delete worker tasks that have last run more than a week in the past and they will never be reattempted. We can use the recurring tasks functionality to run something every hour to do this:

https://github.com/triggerdotdev/trigger.dev/blob/1fd1d267800647af8139851bc22876cbf4643d5f/apps/webapp/app/services/worker.server.ts#L125

<sub>[TRI-1150](https://linear.app/triggerdotdev/issue/TRI-1150/cleanup-failed-graphile-worker-tasks)</sub>",,
1865327166,391,[TRI-1149] bug: Cannot get eslint-plugin working on a fresh Next.js project,"Here's the reproduction project:

https://github.com/ericallam/my-app

As you can see I've setup the eslint-plugin, but for some reason `npm run lint` isn't finding any errors in this code:

```ts
import { Job, eventTrigger } from ""@trigger.dev/sdk"";
import { client } from ""@/trigger"";

// your first job
new Job(client, {
  id: ""example-job"",
  name: ""Example Job"",
  version: ""0.0.1"",
  trigger: eventTrigger({
    name: ""example.event"",
  }),
  run: async (payload, io, ctx) => {
    await io.runTask(""example.task"", { name: ""Task 1"" }, async () => {});
    await io.runTask(""example.task"", { name: ""Task 2"" }, async () => {});
  },
});
```

cc: @ologbonowiwi

<sub>[TRI-1149](https://linear.app/triggerdotdev/issue/TRI-1149/bug-cannot-get-eslint-plugin-working-on-a-fresh-nextjs-project)</sub>",,
1863884753,385,[TRI-1133] The React hook useEventRunDetails should accept string | undefined,"It should work but the TypeScript type is incorrect in the params.

## Steps
1. Change the eventId type in `packages/react/src/events.ts` to be `string | undefined`. Do not use an optional as we want to force people to put a value here.
2. Test this by modifying the examples/nextjs-example to have an undefined when it uses the hook

<sub>[TRI-1133](https://linear.app/triggerdotdev/issue/TRI-1133/the-react-hook-useeventrundetails-should-accept-string-or-undefined)</sub>",,
1860129504,379,[TRI-1127] Improvement: Add a `@trigger.dev/testing` package that allows for unit testing job runs,"Currently, we don't have a clean way of unit testing jobs, it would be nice to have a `@trigger.dev/testing` package that could be used to do test job runs with mocked `io` and make assertions:

```ts
const jobToTest = client.defineJob({
  id: ""stripe-example-1"",
  name: ""Stripe Example 1"",
  version: ""0.1.0"",
  trigger: eventTrigger({
    name: ""stripe.example"",
    schema: z.object({
      customerId: z.string(),
      source: z.string(),
    }),
  }),
  integrations: {
    stripe,
  },
  run: async (payload, io, ctx) => {
    await io.stripe.createCharge(""create-charge"", {
      amount: 100,
      currency: ""usd"",
      source: payload.source,
      customer: payload.customerId,
    });
  },
});

import { testJob } from ""@trigger.dev/testing"";

// Inside a test file
const testRun = testJob(jobToTest, {
  payload: {
    customerId: ""cus_123"",
    source: ""src_123"",
  },
});

expect(testRun).toHaveSucceeded();
// Test the stripe charge was called with the correct params
expect(testRun.io.stripe.createCharge).toHaveBeenCalledWith(""create-charge"", {
  amount: 100,
  currency: ""usd"",
  source: ""src_123"",
});
```

<sub>[TRI-1127](https://linear.app/triggerdotdev/issue/TRI-1127/improvement-add-a-triggerdevtesting-package-that-allows-for-unit)</sub>",,
1859567092,376,[TRI-1125] `@trigger.dev/cli init` reports the wrong file name for app dir and javascript projects,"I just ran `@trigger.dev/cli init` against a Next.js project using the App Dir and JavaScript and it output the following message:

```
✅ Created app route at src/app/api/trigger.ts
```

Even though the file was actually created at `src/app/api/trigger/route.js`

We should make sure that this output is correctly specified for different setups:

- [ ] App Dir w/ JS
- [ ] App Dir w/ TS
- [ ] Pages Dir w/ JS
- [ ] Pages Dir w/ TS


<sub>[TRI-1125](https://linear.app/triggerdotdev/issue/TRI-1125/triggerdevcli-init-reports-the-wrong-file-name-for-app-dir-and)</sub>",,
1855298460,352,[TRI-1092] Add the SendGrid integration to the catalog,"Integrations can be added to the catalog, which appears on the Integrations page in the app:

![CleanShot 2023-08-17 at 17.03.40@2x.png](https://uploads.linear.app/80a884b1-f84c-49d6-91db-07a391663d20/d471bf96-12dc-41c4-a588-1fcd6df3c126/f7e7c8cf-f5c5-45eb-b811-870b84316f6c?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzgwYTg4NGIxLWY4NGMtNDlkNi05MWRiLTA3YTM5MTY2M2QyMC9kNDcxYmY5Ni0xMmRjLTQxYzQtYTU4OC0xZmNkNmRmM2MxMjYvZjdlN2M4Y2YtZjVjNS00NWViLWI4MTEtODcwYjg0MzE2ZjZjIiwiaWF0IjoxNjkyMjg4NTMxLCJleHAiOjE2OTIzNzQ5MzF9.xzCX64gvdQ7aB9N7arHsA4ZziKH0-m8v7u0Jcn7t_lY)

To do this:

1. A SendGrid integration file needs to be created, like this Resend one: [https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/services/externalApis/integrations/resend.ts](https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/services/externalApis/integrations/resend.ts) 
2. It needs to be added to the catalog: [https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/services/externalApis/integrationCatalog.server.ts](https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/services/externalApis/integrationCatalog.server.ts)

Please keep the integrations alphabetical (to help my OCD 😉 )

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-1092](https://linear.app/triggerdotdev/issue/TRI-1092/add-the-sendgrid-integration-to-the-catalog)</sub>",,
1851698290,339,Issue while deploying on fly io,"Path: /documentation/guides/self-hosting/flyio

not able to deploy this on fly io

2023-08-15T15:44:27.353 app[148ed6e1f7d248] mia [info] You may have to run ${S(""prisma generate"")} for your changes to take effect.`,this.config.clientVersion);return r}parseEngineResponse(r){if(!r)throw new oe(""Response from the Engine was empty"",{clientVersion:this.config.clientVersion});try{return JSON.parse(r)}catch{throw new oe(""Unable to JSON.parse response from engine"",{clientVersion:this.config.clientVersion})}}convertDatasources(r){let n=Object.create(null);for(let{name:i,url:o}of r)n[i]=o;return n}async loadEngine(){if(!this.engine){this.QueryEngineConstructor||(this.library=await this.libraryLoader.loadLibrary(),this.QueryEngineConstructor=this.library.QueryEngine);try{let r=new WeakRef(this);this.engine=new this.QueryEngineConstructor({datamodel:this.datamodel,env:process.env,logQueries:this.config.logQueries??!1,ignoreEnvVarErrors:!0,datasourceOverrides:this.datasourceOverrides,logLevel:this.logLevel,configDir:this.config.cwd,engineProtocol:this.engineProtocol},n=>{r.deref()?.logger(n)}),ca++}catch(r){let n=r,i=this.parseInitError(n.message);throw typeof i==""string""?n:new Q(i.message,this.config.clientVersion,i.error_code)}}}logger(r){let n=this.parseEngineResponse(r);if(!!n){if(""span""in n){this.config.tracingHelper.createEngineSpan(n);return}n.level=n?.level.toLowerCase()??""unknown"",Bp(n)?this.logEmitter.emit(""query"",{timestamp:new Date,query:n.query,params:n.params,duration:Number(n.duration_ms),target:n.module_path}):Vp(n)?this.loggerRustPanic=new be(this.getErrorMessageWithLink(`${n.message}: ${n.reason} in ${n.file}:${n.line}:${n.column}`),this.config.clientVersion):this.logEmitter.emit(n.level,{timestamp:new Date,message:n.message,target:n.module_path})}}getErrorMessageWithLink(r){return sa({platform:this.platform,title:r,version:this.config.clientVersion,engineVersion:this.versionInfo?.commit,database:this.config.activeProvider,query:this.lastQuery})}parseInitError(r){try{return JSON.parse(r)}catch{}return r}parseRequestError(r){try{return JSON.parse(r)}catch{}return r}on(r,n){r===""beforeExit""?this.beforeExitListener=n:this.logEmitter.on(r,n)}async start(){if(await this.libraryInstantiationPromise,await this.libraryStoppingPromise,this.libraryStartingPromise)return qe(`library already starting, this.libraryStarted: ${this.libraryStarted}`),this.libraryStartingPromise;if(this.libraryStarted)return;let r=async()=>{qe(""library starting"");try{let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.connect(JSON.stringify(n)),this.libraryStarted=!0,qe(""library started"")}catch(n){let i=this.parseInitError(n.message);throw typeof i==""string""?n:new Q(i.message,this.config.clientVersion,i.error_code)}finally{this.libraryStartingPromise=void 0}};return this.libraryStartingPromise=this.config.tracingHelper.runInChildSpan(""connect"",r),this.libraryStartingPromise}async stop(){if(await this.libraryStartingPromise,await this.executingQueryPromise,this.libraryStoppingPromise)return qe(""library is already stopping""),this.libraryStoppingPromise;if(!this.libraryStarted)return;let r=async()=>{await new Promise(i=>setTimeout(i,5)),qe(""library stopping"");let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.disconnect(JSON.stringify(n)),this.libraryStarted=!1,this.libraryStoppingPromise=void 0,qe(""library stopped"")};return this.libraryStoppingPromise=this.config.tracingHelper.runInChildSpan(""disconnect"",r),this.libraryStoppingPromise}async getDmmf(){await this.start();let r=this.config.tracingHelper.getTraceParent(),n=await this.engine.dmmf(JSON.stringify({traceparent:r}));return this.config.tracingHelper.runInChildSpan({name:""parseDmmf"",internal:!0},()=>JSON.parse(n))}version(){return this.versionInfo=this.library?.version(),this.versionInfo?.version??""unknown""}debugPanic(r){return this.library?.debugPanic(r)}async request(r,{traceparent:n,interactiveTransaction:i}){qe(`sending request, this.libraryStarted: ${this.libraryStarted}`);let o=JSON.stringify({traceparent:n}),s=JSON.stringify(r);try{await this.start(),this.executingQueryPromise=this.engine?.query(s,o,i?.id),this.lastQuery=s;let a=this.parseEngineResponse(await this.executingQueryPromise);if(a.errors)throw a.errors.length===1?this.buildQueryError(a.errors[0]):new oe(JSON.stringify(a.errors),{clientVersion:this.config.clientVersion});if(this.loggerRustPanic)throw this.loggerRustPanic;return{data:a,elapsed:0}}catch(a){if(a instanceof Q)throw a;if(a.code===""GenericFailure""&&a.message?.startsWith(""PANIC:""))throw new be(this.getErrorMessageWithLink(a.message),this.config.clientVersion);let l=this.parseRequestError(a.message);throw typeof l==""string""?a:new oe(`${l.message}

2023-08-15T15:44:27.353 app[148ed6e1f7d248] mia [info] ^

2023-08-15T15:44:27.353 app[148ed6e1f7d248] mia [info] PrismaClientInitializationError: Error opening a TLS connection: unexpected EOF

2023-08-15T15:44:27.353 app[148ed6e1f7d248] mia [info] at r (/triggerdotdev/node_modules/.pnpm/@prisma+client@4.16.2_prisma@4.16.0/node_modules/@prisma/client/runtime/library.js:108:2574)

2023-08-15T15:44:27.400 app[148ed6e1f7d248] mia [info]  ELIFECYCLE  Command failed with exit code 1.

2023-08-15T15:44:27.718 app[148ed6e1f7d248] mia [info] INFO Main child exited normally with code: 1

2023-08-15T15:44:27.719 app[148ed6e1f7d248] mia [info] INFO Starting clean up.

2023-08-15T15:44:27.720 app[148ed6e1f7d248] mia [info] WARN hallpass exited, pid: 256, status: signal: 15 (SIGTERM)

2023-08-15T15:44:27.727 app[148ed6e1f7d248] mia [info] 2023/08/15 15:44:27 listening on [fdaa:2:4fd7:a7b:184:f397:2946:2]:22 (DNS: [fdaa::3]:53)

2023-08-15T15:44:28.720 app[148ed6e1f7d248] mia [info] [ 12.308936] reboot: Restarting system

2023-08-15T15:44:28.928 runner[148ed6e1f7d248] mia [info] machine did not have a restart policy, defaulting to restart

2023-08-15T15:44:36.497 app[148ed6e1f7d248] mia [info] [ 0.039871] PCI: Fatal: No config space access function found

2023-08-15T15:44:36.718 app[148ed6e1f7d248] mia [info] INFO Starting init (commit: b437b5b)...

2023-08-15T15:44:36.737 app[148ed6e1f7d248] mia [info] INFO Preparing to run: `docker-entrypoint.sh ./scripts/entrypoint.sh` as node

2023-08-15T15:44:36.745 app[148ed6e1f7d248] mia [info] INFO [fly api proxy] listening at /.fly/api

2023-08-15T15:44:36.752 app[148ed6e1f7d248] mia [info] 2023/08/15 15:44:36 listening on [fdaa:2:4fd7:a7b:184:f397:2946:2]:22 (DNS: [fdaa::3]:53)

2023-08-15T15:44:36.755 app[148ed6e1f7d248] mia [info] + [ -n ]

2023-08-15T15:44:36.755 app[148ed6e1f7d248] mia [info] + pnpm --filter @trigger.dev/database db:migrate:deploy

2023-08-15T15:44:38.170 app[148ed6e1f7d248] mia [info] > @trigger.dev/database@0.0.0 db:migrate:deploy /triggerdotdev/packages/database

2023-08-15T15:44:38.170 app[148ed6e1f7d248] mia [info] > prisma migrate deploy

2023-08-15T15:44:38.808 app[148ed6e1f7d248] mia [info] Prisma schema loaded from prisma/schema.prisma

2023-08-15T15:44:38.842 app[148ed6e1f7d248] mia [info] Datasource ""db"": PostgreSQL database ""postgres"", schema ""public"" at ""wallofreviews-trigger-v2-fly-demo-db.flycast:5432""

2023-08-15T15:44:39.088 app[148ed6e1f7d248] mia [info] Error: P1011: Error opening a TLS connection: unexpected EOF

2023-08-15T15:44:39.107 app[148ed6e1f7d248] mia [info] undefined

2023-08-15T15:44:39.109 app[148ed6e1f7d248] mia [info] /triggerdotdev/packages/database:

2023-08-15T15:44:39.109 app[148ed6e1f7d248] mia [info]  ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  @trigger.dev/database@0.0.0 db:migrate:deploy: `prisma migrate deploy`

2023-08-15T15:44:39.109 app[148ed6e1f7d248] mia [info] Exit status 1

2023-08-15T15:44:39.121 app[148ed6e1f7d248] mia [info] + cp packages/database/prisma/schema.prisma apps/webapp/prisma/

2023-08-15T15:44:39.126 app[148ed6e1f7d248] mia [info] + cp node_modules/@prisma/engines/libquery_engine-debian-openssl-1.1.x.so.node apps/webapp/prisma/

2023-08-15T15:44:39.143 app[148ed6e1f7d248] mia [info] + pnpm --filter webapp db:seed

2023-08-15T15:44:39.656 app[148ed6e1f7d248] mia [info] > webapp@1.0.0 db:seed /triggerdotdev/apps/webapp

2023-08-15T15:44:39.656 app[148ed6e1f7d248] mia [info] > node prisma/seed.js

2023-08-15T15:44:39.734 app[148ed6e1f7d248] mia [info] 🔌 setting up prisma client to postgres://postgres@wallofreviews-trigger-v2-fly-demo-db.flycast:5432

2023-08-15T15:44:39.740 app[148ed6e1f7d248] mia [info] 🔌 prisma client connected

2023-08-15T15:44:39.749 app[148ed6e1f7d248] mia [info] prisma:info Starting a postgresql pool with 3 connections.

2023-08-15T15:44:39.933 app[148ed6e1f7d248] mia [info] prisma:error

2023-08-15T15:44:39.933 app[148ed6e1f7d248] mia [info] Invalid `prisma.integrationDefinition.upsert()` invocation:

2023-08-15T15:44:39.933 app[148ed6e1f7d248] mia [info] Error opening a TLS connection: unexpected EOF

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] PrismaClientInitializationError:

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] Invalid `prisma.integrationDefinition.upsert()` invocation:

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] Error opening a TLS connection: unexpected EOF

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] at Rn.handleRequestError (/triggerdotdev/apps/webapp/prisma/seed.js:174:7589)

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] at Rn.handleAndLogRequestError (/triggerdotdev/apps/webapp/prisma/seed.js:174:6742)

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] at /triggerdotdev/apps/webapp/prisma/seed.js:177:3006

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] at async /triggerdotdev/apps/webapp/prisma/seed.js:177:3221

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] at async t._executeRequest (/triggerdotdev/apps/webapp/prisma/seed.js:177:11390)

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] at async fg (/triggerdotdev/apps/webapp/prisma/seed.js:519:60716)

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] at async pg (/triggerdotdev/apps/webapp/prisma/seed.js:519:61621) {

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] clientVersion: '4.16.0',

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] errorCode: undefined

2023-08-15T15:44:39.936 app[148ed6e1f7d248] mia [info] }

2023-08-15T15:44:39.943 app[148ed6e1f7d248] mia [info] undefined

2023-08-15T15:44:39.944 app[148ed6e1f7d248] mia [info] /triggerdotdev/apps/webapp:

2023-08-15T15:44:39.944 app[148ed6e1f7d248] mia [info]  ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  webapp@1.0.0 db:seed: `node prisma/seed.js`

2023-08-15T15:44:39.944 app[148ed6e1f7d248] mia [info] Exit status 1

2023-08-15T15:44:39.970 app[148ed6e1f7d248] mia [info] + cd /triggerdotdev/apps/webapp

2023-08-15T15:44:39.970 app[148ed6e1f7d248] mia [info] + exec dumb-init pnpm run start

2023-08-15T15:44:40.380 app[148ed6e1f7d248] mia [info] > webapp@1.0.0 start /triggerdotdev/apps/webapp

2023-08-15T15:44:40.380 app[148ed6e1f7d248] mia [info] > cross-env NODE_ENV=production node --max-old-space-size=8192 ./build/server.js

2023-08-15T15:44:41.676 app[148ed6e1f7d248] mia [info] 🔌 setting up prisma client to postgres://postgres@wallofreviews-trigger-v2-fly-demo-db.flycast:5432

2023-08-15T15:44:41.680 app[148ed6e1f7d248] mia [info] 🔌 prisma client connected

2023-08-15T15:44:41.925 app[148ed6e1f7d248] mia [info] {""runnerOptions"":{""connectionString"":""postgres://postgres:SGbxbMIWU8vqBjh@wallofreviews-trigger-v2-fly-demo-db.flycast:5432"",""concurrency"":5,""pollInterval"":1000,""noPreparedStatements"":false},""timestamp"":""2023-08-15T15:44:41.925Z"",""name"":""webapp"",""message"":""Initializing worker queue with options""}

2023-08-15T15:44:42.389 app[148ed6e1f7d248] mia [info] No PostHog API key, so analytics won't track

2023-08-15T15:44:44.301 app[148ed6e1f7d248] mia [info] ✅ app ready: http://localhost:3000

2023-08-15T15:44:45.939 app[148ed6e1f7d248] mia [info] prisma:info Starting a postgresql pool with 3 connections.

2023-08-15T15:44:46.355 app[148ed6e1f7d248] mia [info] /triggerdotdev/node_modules/.pnpm/@prisma+client@4.16.2_prisma@4.16.0/node_modules/@prisma/client/runtime/library.js:108

2023-08-15T15:44:46.355 app[148ed6e1f7d248] mia [info] You may have to run ${S(""prisma generate"")} for your changes to take effect.`,this.config.clientVersion);return r}parseEngineResponse(r){if(!r)throw new oe(""Response from the Engine was empty"",{clientVersion:this.config.clientVersion});try{return JSON.parse(r)}catch{throw new oe(""Unable to JSON.parse response from engine"",{clientVersion:this.config.clientVersion})}}convertDatasources(r){let n=Object.create(null);for(let{name:i,url:o}of r)n[i]=o;return n}async loadEngine(){if(!this.engine){this.QueryEngineConstructor||(this.library=await this.libraryLoader.loadLibrary(),this.QueryEngineConstructor=this.library.QueryEngine);try{let r=new WeakRef(this);this.engine=new this.QueryEngineConstructor({datamodel:this.datamodel,env:process.env,logQueries:this.config.logQueries??!1,ignoreEnvVarErrors:!0,datasourceOverrides:this.datasourceOverrides,logLevel:this.logLevel,configDir:this.config.cwd,engineProtocol:this.engineProtocol},n=>{r.deref()?.logger(n)}),ca++}catch(r){let n=r,i=this.parseInitError(n.message);throw typeof i==""string""?n:new Q(i.message,this.config.clientVersion,i.error_code)}}}logger(r){let n=this.parseEngineResponse(r);if(!!n){if(""span""in n){this.config.tracingHelper.createEngineSpan(n);return}n.level=n?.level.toLowerCase()??""unknown"",Bp(n)?this.logEmitter.emit(""query"",{timestamp:new Date,query:n.query,params:n.params,duration:Number(n.duration_ms),target:n.module_path}):Vp(n)?this.loggerRustPanic=new be(this.getErrorMessageWithLink(`${n.message}: ${n.reason} in ${n.file}:${n.line}:${n.column}`),this.config.clientVersion):this.logEmitter.emit(n.level,{timestamp:new Date,message:n.message,target:n.module_path})}}getErrorMessageWithLink(r){return sa({platform:this.platform,title:r,version:this.config.clientVersion,engineVersion:this.versionInfo?.commit,database:this.config.activeProvider,query:this.lastQuery})}parseInitError(r){try{return JSON.parse(r)}catch{}return r}parseRequestError(r){try{return JSON.parse(r)}catch{}return r}on(r,n){r===""beforeExit""?this.beforeExitListener=n:this.logEmitter.on(r,n)}async start(){if(await this.libraryInstantiationPromise,await this.libraryStoppingPromise,this.libraryStartingPromise)return qe(`library already starting, this.libraryStarted: ${this.libraryStarted}`),this.libraryStartingPromise;if(this.libraryStarted)return;let r=async()=>{qe(""library starting"");try{let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.connect(JSON.stringify(n)),this.libraryStarted=!0,qe(""library started"")}catch(n){let i=this.parseInitError(n.message);throw typeof i==""string""?n:new Q(i.message,this.config.clientVersion,i.error_code)}finally{this.libraryStartingPromise=void 0}};return this.libraryStartingPromise=this.config.tracingHelper.runInChildSpan(""connect"",r),this.libraryStartingPromise}async stop(){if(await this.libraryStartingPromise,await this.executingQueryPromise,this.libraryStoppingPromise)return qe(""library is already stopping""),this.libraryStoppingPromise;if(!this.libraryStarted)return;let r=async()=>{await new Promise(i=>setTimeout(i,5)),qe(""library stopping"");let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.disconnect(JSON.stringify(n)),this.libraryStarted=!1,this.libraryStoppingPromise=void 0,qe(""library stopped"")};return this.libraryStoppingPromise=this.config.tracingHelper.runInChildSpan(""disconnect"",r),this.libraryStoppingPromise}async getDmmf(){await this.start();let r=this.config.tracingHelper.getTraceParent(),n=await this.engine.dmmf(JSON.stringify({traceparent:r}));return this.config.tracingHelper.runInChildSpan({name:""parseDmmf"",internal:!0},()=>JSON.parse(n))}version(){return this.versionInfo=this.library?.version(),this.versionInfo?.version??""unknown""}debugPanic(r){return this.library?.debugPanic(r)}async request(r,{traceparent:n,interactiveTransaction:i}){qe(`sending request, this.libraryStarted: ${this.libraryStarted}`);let o=JSON.stringify({traceparent:n}),s=JSON.stringify(r);try{await this.start(),this.executingQueryPromise=this.engine?.query(s,o,i?.id),this.lastQuery=s;let a=this.parseEngineResponse(await this.executingQueryPromise);if(a.errors)throw a.errors.length===1?this.buildQueryError(a.errors[0]):new oe(JSON.stringify(a.errors),{clientVersion:this.config.clientVersion});if(this.loggerRustPanic)throw this.loggerRustPanic;return{data:a,elapsed:0}}catch(a){if(a instanceof Q)throw a;if(a.code===""GenericFailure""&&a.message?.startsWith(""PANIC:""))throw new be(this.getErrorMessageWithLink(a.message),this.config.clientVersion);let l=this.parseRequestError(a.message);throw typeof l==""string""?a:new oe(`${l.message}

2023-08-15T15:44:46.355 app[148ed6e1f7d248] mia [info] ^

2023-08-15T15:44:46.368 app[148ed6e1f7d248] mia [info] PrismaClientInitializationError: Error opening a TLS connection: unexpected EOF

2023-08-15T15:44:46.368 app[148ed6e1f7d248] mia [info] at r (/triggerdotdev/node_modules/.pnpm/@prisma+client@4.16.2_prisma@4.16.0/node_modules/@prisma/client/runtime/library.js:108:2574)

2023-08-15T15:44:46.481 app[148ed6e1f7d248] mia [info]  ELIFECYCLE  Command failed with exit code 1.

2023-08-15T15:44:46.762 app[148ed6e1f7d248] mia [info] INFO Main child exited normally with code: 1

2023-08-15T15:44:46.763 app[148ed6e1f7d248] mia [info] INFO Starting clean up.

2023-08-15T15:44:46.764 app[148ed6e1f7d248] mia [info] WARN hallpass exited, pid: 256, status: signal: 15 (SIGTERM)

2023-08-15T15:44:46.771 app[148ed6e1f7d248] mia [info] 2023/08/15 15:44:46 listening on [fdaa:2:4fd7:a7b:184:f397:2946:2]:22 (DNS: [fdaa::3]:53)

2023-08-15T15:44:47.765 app[148ed6e1f7d248] mia [info] [ 11.304070] reboot: Restarting system

2023-08-15T15:44:47.960 runner[148ed6e1f7d248] mia [info] machine did not have a restart policy, defaulting to restart

2023-08-15T15:44:51.763 app[148ed6e1f7d248] mia [info] [ 0.040196] PCI: Fatal: No config space access function found

2023-08-15T15:44:51.988 app[148ed6e1f7d248] mia [info] INFO Starting init (commit: b437b5b)...

2023-08-15T15:44:52.008 app[148ed6e1f7d248] mia [info] INFO Preparing to run: `docker-entrypoint.sh ./scripts/entrypoint.sh` as node

2023-08-15T15:44:52.015 app[148ed6e1f7d248] mia [info] INFO [fly api proxy] listening at /.fly/api

2023-08-15T15:44:52.022 app[148ed6e1f7d248] mia [info] 2023/08/15 15:44:52 listening on [fdaa:2:4fd7:a7b:184:f397:2946:2]:22 (DNS: [fdaa::3]:53)

2023-08-15T15:44:52.025 app[148ed6e1f7d248] mia [info] + [ -n ]

2023-08-15T15:44:52.025 app[148ed6e1f7d248] mia [info] + pnpm --filter @trigger.dev/database db:migrate:deploy

2023-08-15T15:44:53.432 app[148ed6e1f7d248] mia [info] > @trigger.dev/database@0.0.0 db:migrate:deploy /triggerdotdev/packages/database

2023-08-15T15:44:53.432 app[148ed6e1f7d248] mia [info] > prisma migrate deploy

2023-08-15T15:44:54.060 app[148ed6e1f7d248] mia [info] Prisma schema loaded from prisma/schema.prisma

2023-08-15T15:44:54.093 app[148ed6e1f7d248] mia [info] Datasource ""db"": PostgreSQL database ""postgres"", schema ""public"" at ""wallofreviews-trigger-v2-fly-demo-db.flycast:5432""

2023-08-15T15:44:54.334 app[148ed6e1f7d248] mia [info] Error: P1011: Error opening a TLS connection: unexpected EOF

2023-08-15T15:44:54.352 app[148ed6e1f7d248] mia [info] undefined

2023-08-15T15:44:54.353 app[148ed6e1f7d248] mia [info] /triggerdotdev/packages/database:

2023-08-15T15:44:54.353 app[148ed6e1f7d248] mia [info]  ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  @trigger.dev/database@0.0.0 db:migrate:deploy: `prisma migrate deploy`

2023-08-15T15:44:54.353 app[148ed6e1f7d248] mia [info] Exit status 1

2023-08-15T15:44:54.365 app[148ed6e1f7d248] mia [info] + cp packages/database/prisma/schema.prisma apps/webapp/prisma/

2023-08-15T15:44:54.370 app[148ed6e1f7d248] mia [info] + cp node_modules/@prisma/engines/libquery_engine-debian-openssl-1.1.x.so.node apps/webapp/prisma/

2023-08-15T15:44:54.387 app[148ed6e1f7d248] mia [info] + pnpm --filter webapp db:seed

2023-08-15T15:44:54.899 app[148ed6e1f7d248] mia [info] > webapp@1.0.0 db:seed /triggerdotdev/apps/webapp

2023-08-15T15:44:54.899 app[148ed6e1f7d248] mia [info] > node prisma/seed.js

2023-08-15T15:44:54.977 app[148ed6e1f7d248] mia [info] 🔌 setting up prisma client to postgres://postgres@wallofreviews-trigger-v2-fly-demo-db.flycast:5432

2023-08-15T15:44:54.982 app[148ed6e1f7d248] mia [info] 🔌 prisma client connected

2023-08-15T15:44:54.993 app[148ed6e1f7d248] mia [info] prisma:info Starting a postgresql pool with 3 connections.

2023-08-15T15:44:55.177 app[148ed6e1f7d248] mia [info] prisma:error

2023-08-15T15:44:55.177 app[148ed6e1f7d248] mia [info] Invalid `prisma.integrationDefinition.upsert()` invocation:

2023-08-15T15:44:55.177 app[148ed6e1f7d248] mia [info] Error opening a TLS connection: unexpected EOF

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] PrismaClientInitializationError:

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] Invalid `prisma.integrationDefinition.upsert()` invocation:

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] Error opening a TLS connection: unexpected EOF

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] at Rn.handleRequestError (/triggerdotdev/apps/webapp/prisma/seed.js:174:7589)

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] at Rn.handleAndLogRequestError (/triggerdotdev/apps/webapp/prisma/seed.js:174:6742)

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] at /triggerdotdev/apps/webapp/prisma/seed.js:177:3006

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] at async /triggerdotdev/apps/webapp/prisma/seed.js:177:3221

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] at async t._executeRequest (/triggerdotdev/apps/webapp/prisma/seed.js:177:11390)

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] at async fg (/triggerdotdev/apps/webapp/prisma/seed.js:519:60716)

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] at async pg (/triggerdotdev/apps/webapp/prisma/seed.js:519:61621) {

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] clientVersion: '4.16.0',

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] errorCode: undefined

2023-08-15T15:44:55.180 app[148ed6e1f7d248] mia [info] }

2023-08-15T15:44:55.187 app[148ed6e1f7d248] mia [info] undefined

2023-08-15T15:44:55.187 app[148ed6e1f7d248] mia [info] /triggerdotdev/apps/webapp:

2023-08-15T15:44:55.187 app[148ed6e1f7d248] mia [info]  ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  webapp@1.0.0 db:seed: `node prisma/seed.js`

2023-08-15T15:44:55.187 app[148ed6e1f7d248] mia [info] Exit status 1

2023-08-15T15:44:55.211 app[148ed6e1f7d248] mia [info] + cd /triggerdotdev/apps/webapp

2023-08-15T15:44:55.211 app[148ed6e1f7d248] mia [info] + exec dumb-init pnpm run start

2023-08-15T15:44:55.616 app[148ed6e1f7d248] mia [info] > webapp@1.0.0 start /triggerdotdev/apps/webapp

2023-08-15T15:44:55.616 app[148ed6e1f7d248] mia [info] > cross-env NODE_ENV=production node --max-old-space-size=8192 ./build/server.js

2023-08-15T15:44:56.877 app[148ed6e1f7d248] mia [info] 🔌 setting up prisma client to postgres://postgres@wallofreviews-trigger-v2-fly-demo-db.flycast:5432

2023-08-15T15:44:56.881 app[148ed6e1f7d248] mia [info] 🔌 prisma client connected

2023-08-15T15:44:57.122 app[148ed6e1f7d248] mia [info] {""runnerOptions"":{""connectionString"":""postgres://postgres:SGbxbMIWU8vqBjh@wallofreviews-trigger-v2-fly-demo-db.flycast:5432"",""concurrency"":5,""pollInterval"":1000,""noPreparedStatements"":false},""timestamp"":""2023-08-15T15:44:57.122Z"",""name"":""webapp"",""message"":""Initializing worker queue with options""}

2023-08-15T15:44:57.573 app[148ed6e1f7d248] mia [info] No PostHog API key, so analytics won't track

2023-08-15T15:44:58.686 app[148ed6e1f7d248] mia [info] ✅ app ready: http://localhost:3000

2023-08-15T15:44:59.788 app[148ed6e1f7d248] mia [info] prisma:info Starting a postgresql pool with 3 connections.

2023-08-15T15:45:00.143 app[148ed6e1f7d248] mia [info] /triggerdotdev/node_modules/.pnpm/@prisma+client@4.16.2_prisma@4.16.0/node_modules/@prisma/client/runtime/library.js:108

2023-08-15T15:45:00.143 app[148ed6e1f7d248] mia [info] You may have to run ${S(""prisma generate"")} for your changes to take effect.`,this.config.clientVersion);return r}parseEngineResponse(r){if(!r)throw new oe(""Response from the Engine was empty"",{clientVersion:this.config.clientVersion});try{return JSON.parse(r)}catch{throw new oe(""Unable to JSON.parse response from engine"",{clientVersion:this.config.clientVersion})}}convertDatasources(r){let n=Object.create(null);for(let{name:i,url:o}of r)n[i]=o;return n}async loadEngine(){if(!this.engine){this.QueryEngineConstructor||(this.library=await this.libraryLoader.loadLibrary(),this.QueryEngineConstructor=this.library.QueryEngine);try{let r=new WeakRef(this);this.engine=new this.QueryEngineConstructor({datamodel:this.datamodel,env:process.env,logQueries:this.config.logQueries??!1,ignoreEnvVarErrors:!0,datasourceOverrides:this.datasourceOverrides,logLevel:this.logLevel,configDir:this.config.cwd,engineProtocol:this.engineProtocol},n=>{r.deref()?.logger(n)}),ca++}catch(r){let n=r,i=this.parseInitError(n.message);throw typeof i==""string""?n:new Q(i.message,this.config.clientVersion,i.error_code)}}}logger(r){let n=this.parseEngineResponse(r);if(!!n){if(""span""in n){this.config.tracingHelper.createEngineSpan(n);return}n.level=n?.level.toLowerCase()??""unknown"",Bp(n)?this.logEmitter.emit(""query"",{timestamp:new Date,query:n.query,params:n.params,duration:Number(n.duration_ms),target:n.module_path}):Vp(n)?this.loggerRustPanic=new be(this.getErrorMessageWithLink(`${n.message}: ${n.reason} in ${n.file}:${n.line}:${n.column}`),this.config.clientVersion):this.logEmitter.emit(n.level,{timestamp:new Date,message:n.message,target:n.module_path})}}getErrorMessageWithLink(r){return sa({platform:this.platform,title:r,version:this.config.clientVersion,engineVersion:this.versionInfo?.commit,database:this.config.activeProvider,query:this.lastQuery})}parseInitError(r){try{return JSON.parse(r)}catch{}return r}parseRequestError(r){try{return JSON.parse(r)}catch{}return r}on(r,n){r===""beforeExit""?this.beforeExitListener=n:this.logEmitter.on(r,n)}async start(){if(await this.libraryInstantiationPromise,await this.libraryStoppingPromise,this.libraryStartingPromise)return qe(`library already starting, this.libraryStarted: ${this.libraryStarted}`),this.libraryStartingPromise;if(this.libraryStarted)return;let r=async()=>{qe(""library starting"");try{let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.connect(JSON.stringify(n)),this.libraryStarted=!0,qe(""library started"")}catch(n){let i=this.parseInitError(n.message);throw typeof i==""string""?n:new Q(i.message,this.config.clientVersion,i.error_code)}finally{this.libraryStartingPromise=void 0}};return this.libraryStartingPromise=this.config.tracingHelper.runInChildSpan(""connect"",r),this.libraryStartingPromise}async stop(){if(await this.libraryStartingPromise,await this.executingQueryPromise,this.libraryStoppingPromise)return qe(""library is already stopping""),this.libraryStoppingPromise;if(!this.libraryStarted)return;let r=async()=>{await new Promise(i=>setTimeout(i,5)),qe(""library stopping"");let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.disconnect(JSON.stringify(n)),this.libraryStarted=!1,this.libraryStoppingPromise=void 0,qe(""library stopped"")};return this.libraryStoppingPromise=this.config.tracingHelper.runInChildSpan(""disconnect"",r),this.libraryStoppingPromise}async getDmmf(){await this.start();let r=this.config.tracingHelper.getTraceParent(),n=await this.engine.dmmf(JSON.stringify({traceparent:r}));return this.config.tracingHelper.runInChildSpan({name:""parseDmmf"",internal:!0},()=>JSON.parse(n))}version(){return this.versionInfo=this.library?.version(),this.versionInfo?.version??""unknown""}debugPanic(r){return this.library?.debugPanic(r)}async request(r,{traceparent:n,interactiveTransaction:i}){qe(`sending request, this.libraryStarted: ${this.libraryStarted}`);let o=JSON.stringify({traceparent:n}),s=JSON.stringify(r);try{await this.start(),this.executingQueryPromise=this.engine?.query(s,o,i?.id),this.lastQuery=s;let a=this.parseEngineResponse(await this.executingQueryPromise);if(a.errors)throw a.errors.length===1?this.buildQueryError(a.errors[0]):new oe(JSON.stringify(a.errors),{clientVersion:this.config.clientVersion});if(this.loggerRustPanic)throw this.loggerRustPanic;return{data:a,elapsed:0}}catch(a){if(a instanceof Q)throw a;if(a.code===""GenericFailure""&&a.message?.startsWith(""PANIC:""))throw new be(this.getErrorMessageWithLink(a.message),this.config.clientVersion);let l=this.parseRequestError(a.message);throw typeof l==""string""?a:new oe(`${l.message}

2023-08-15T15:45:00.143 app[148ed6e1f7d248] mia [info] ^

2023-08-15T15:45:00.154 app[148ed6e1f7d248] mia [info] PrismaClientInitializationError: Error opening a TLS connection: unexpected EOF

2023-08-15T15:45:00.154 app[148ed6e1f7d248] mia [info] at r (/triggerdotdev/node_modules/.pnpm/@prisma+client@4.16.2_prisma@4.16.0/node_modules/@prisma/client/runtime/library.js:108:2574)

2023-08-15T15:45:00.258 app[148ed6e1f7d248] mia [info]  ELIFECYCLE  Command failed with exit code 1.

2023-08-15T15:45:01.033 app[148ed6e1f7d248] mia [info] INFO Main child exited normally with code: 1

2023-08-15T15:45:01.033 app[148ed6e1f7d248] mia [info] INFO Starting clean up.

2023-08-15T15:45:01.034 app[148ed6e1f7d248] mia [info] WARN hallpass exited, pid: 256, status: signal: 15 (SIGTERM)

2023-08-15T15:45:01.041 app[148ed6e1f7d248] mia [info] 2023/08/15 15:45:01 listening on [fdaa:2:4fd7:a7b:184:f397:2946:2]:22 (DNS: [fdaa::3]:53)

2023-08-15T15:45:02.034 app[148ed6e1f7d248] mia [info] [ 10.307405] reboot: Restarting system

2023-08-15T15:45:02.243 runner[148ed6e1f7d248] mia [info] machine did not have a restart policy, defaulting to restart

2023-08-15T15:45:24.474 app[148ed6e1f7d248] mia [info] [ 0.040617] PCI: Fatal: No config space access function found

2023-08-15T15:45:24.698 app[148ed6e1f7d248] mia [info] INFO Starting init (commit: b437b5b)...

2023-08-15T15:45:24.717 app[148ed6e1f7d248] mia [info] INFO Preparing to run: `docker-entrypoint.sh ./scripts/entrypoint.sh` as node

2023-08-15T15:45:24.725 app[148ed6e1f7d248] mia [info] INFO [fly api proxy] listening at /.fly/api

2023-08-15T15:45:24.732 app[148ed6e1f7d248] mia [info] 2023/08/15 15:45:24 listening on [fdaa:2:4fd7:a7b:184:f397:2946:2]:22 (DNS: [fdaa::3]:53)

2023-08-15T15:45:24.735 app[148ed6e1f7d248] mia [info] + [ -n ]

2023-08-15T15:45:24.735 app[148ed6e1f7d248] mia [info] + pnpm --filter @trigger.dev/database db:migrate:deploy

2023-08-15T15:45:26.501 app[148ed6e1f7d248] mia [info] > @trigger.dev/database@0.0.0 db:migrate:deploy /triggerdotdev/packages/database

2023-08-15T15:45:26.501 app[148ed6e1f7d248] mia [info] > prisma migrate deploy

2023-08-15T15:45:27.154 app[148ed6e1f7d248] mia [info] Prisma schema loaded from prisma/schema.prisma

2023-08-15T15:45:27.184 app[148ed6e1f7d248] mia [info] Datasource ""db"": PostgreSQL database ""postgres"", schema ""public"" at ""wallofreviews-trigger-v2-fly-demo-db.flycast:5432""

2023-08-15T15:45:27.444 app[148ed6e1f7d248] mia [info] Error: P1011: Error opening a TLS connection: unexpected EOF

2023-08-15T15:45:27.463 app[148ed6e1f7d248] mia [info] undefined

2023-08-15T15:45:27.464 app[148ed6e1f7d248] mia [info] /triggerdotdev/packages/database:

2023-08-15T15:45:27.464 app[148ed6e1f7d248] mia [info]  ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  @trigger.dev/database@0.0.0 db:migrate:deploy: `prisma migrate deploy`

2023-08-15T15:45:27.464 app[148ed6e1f7d248] mia [info] Exit status 1

2023-08-15T15:45:27.476 app[148ed6e1f7d248] mia [info] + cp packages/database/prisma/schema.prisma apps/webapp/prisma/

2023-08-15T15:45:27.481 app[148ed6e1f7d248] mia [info] + cp node_modules/@prisma/engines/libquery_engine-debian-openssl-1.1.x.so.node apps/webapp/prisma/

2023-08-15T15:45:27.497 app[148ed6e1f7d248] mia [info] + pnpm --filter webapp db:seed

2023-08-15T15:45:28.012 app[148ed6e1f7d248] mia [info] > webapp@1.0.0 db:seed /triggerdotdev/apps/webapp

2023-08-15T15:45:28.012 app[148ed6e1f7d248] mia [info] > node prisma/seed.js

2023-08-15T15:45:28.090 app[148ed6e1f7d248] mia [info] 🔌 setting up prisma client to postgres://postgres@wallofreviews-trigger-v2-fly-demo-db.flycast:5432

2023-08-15T15:45:28.094 app[148ed6e1f7d248] mia [info] 🔌 prisma client connected

2023-08-15T15:45:28.106 app[148ed6e1f7d248] mia [info] prisma:info Starting a postgresql pool with 3 connections.

2023-08-15T15:45:28.291 app[148ed6e1f7d248] mia [info] prisma:error

2023-08-15T15:45:28.291 app[148ed6e1f7d248] mia [info] Invalid `prisma.integrationDefinition.upsert()` invocation:

2023-08-15T15:45:28.291 app[148ed6e1f7d248] mia [info] Error opening a TLS connection: unexpected EOF

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] PrismaClientInitializationError:

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] Invalid `prisma.integrationDefinition.upsert()` invocation:

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] Error opening a TLS connection: unexpected EOF

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] at Rn.handleRequestError (/triggerdotdev/apps/webapp/prisma/seed.js:174:7589)

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] at Rn.handleAndLogRequestError (/triggerdotdev/apps/webapp/prisma/seed.js:174:6742)

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] at /triggerdotdev/apps/webapp/prisma/seed.js:177:3006

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] at async /triggerdotdev/apps/webapp/prisma/seed.js:177:3221

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] at async t._executeRequest (/triggerdotdev/apps/webapp/prisma/seed.js:177:11390)

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] at async fg (/triggerdotdev/apps/webapp/prisma/seed.js:519:60716)

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] at async pg (/triggerdotdev/apps/webapp/prisma/seed.js:519:61621) {

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] clientVersion: '4.16.0',

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] errorCode: undefined

2023-08-15T15:45:28.294 app[148ed6e1f7d248] mia [info] }

2023-08-15T15:45:28.301 app[148ed6e1f7d248] mia [info] undefined

2023-08-15T15:45:28.302 app[148ed6e1f7d248] mia [info] /triggerdotdev/apps/webapp:

2023-08-15T15:45:28.302 app[148ed6e1f7d248] mia [info]  ERR_PNPM_RECURSIVE_RUN_FIRST_FAIL  webapp@1.0.0 db:seed: `node prisma/seed.js`

2023-08-15T15:45:28.302 app[148ed6e1f7d248] mia [info] Exit status 1

2023-08-15T15:45:28.324 app[148ed6e1f7d248] mia [info] + cd /triggerdotdev/apps/webapp

2023-08-15T15:45:28.324 app[148ed6e1f7d248] mia [info] + exec dumb-init pnpm run start

2023-08-15T15:45:28.731 app[148ed6e1f7d248] mia [info] > webapp@1.0.0 start /triggerdotdev/apps/webapp

2023-08-15T15:45:28.731 app[148ed6e1f7d248] mia [info] > cross-env NODE_ENV=production node --max-old-space-size=8192 ./build/server.js

2023-08-15T15:45:30.057 app[148ed6e1f7d248] mia [info] 🔌 setting up prisma client to postgres://postgres@wallofreviews-trigger-v2-fly-demo-db.flycast:5432

2023-08-15T15:45:30.064 app[148ed6e1f7d248] mia [info] 🔌 prisma client connected

2023-08-15T15:45:30.295 app[148ed6e1f7d248] mia [info] {""runnerOptions"":{""connectionString"":""postgres://postgres:SGbxbMIWU8vqBjh@wallofreviews-trigger-v2-fly-demo-db.flycast:5432"",""concurrency"":5,""pollInterval"":1000,""noPreparedStatements"":false},""timestamp"":""2023-08-15T15:45:30.295Z"",""name"":""webapp"",""message"":""Initializing worker queue with options""}

2023-08-15T15:45:30.730 app[148ed6e1f7d248] mia [info] No PostHog API key, so analytics won't track

2023-08-15T15:45:31.886 app[148ed6e1f7d248] mia [info] ✅ app ready: http://localhost:3000

2023-08-15T15:45:32.558 app[148ed6e1f7d248] mia [info] prisma:info Starting a postgresql pool with 3 connections.

2023-08-15T15:45:33.495 app[148ed6e1f7d248] mia [info] /triggerdotdev/node_modules/.pnpm/@prisma+client@4.16.2_prisma@4.16.0/node_modules/@prisma/client/runtime/library.js:108

2023-08-15T15:45:33.495 app[148ed6e1f7d248] mia [info] You may have to run ${S(""prisma generate"")} for your changes to take effect.`,this.config.clientVersion);return r}parseEngineResponse(r){if(!r)throw new oe(""Response from the Engine was empty"",{clientVersion:this.config.clientVersion});try{return JSON.parse(r)}catch{throw new oe(""Unable to JSON.parse response from engine"",{clientVersion:this.config.clientVersion})}}convertDatasources(r){let n=Object.create(null);for(let{name:i,url:o}of r)n[i]=o;return n}async loadEngine(){if(!this.engine){this.QueryEngineConstructor||(this.library=await this.libraryLoader.loadLibrary(),this.QueryEngineConstructor=this.library.QueryEngine);try{let r=new WeakRef(this);this.engine=new this.QueryEngineConstructor({datamodel:this.datamodel,env:process.env,logQueries:this.config.logQueries??!1,ignoreEnvVarErrors:!0,datasourceOverrides:this.datasourceOverrides,logLevel:this.logLevel,configDir:this.config.cwd,engineProtocol:this.engineProtocol},n=>{r.deref()?.logger(n)}),ca++}catch(r){let n=r,i=this.parseInitError(n.message);throw typeof i==""string""?n:new Q(i.message,this.config.clientVersion,i.error_code)}}}logger(r){let n=this.parseEngineResponse(r);if(!!n){if(""span""in n){this.config.tracingHelper.createEngineSpan(n);return}n.level=n?.level.toLowerCase()??""unknown"",Bp(n)?this.logEmitter.emit(""query"",{timestamp:new Date,query:n.query,params:n.params,duration:Number(n.duration_ms),target:n.module_path}):Vp(n)?this.loggerRustPanic=new be(this.getErrorMessageWithLink(`${n.message}: ${n.reason} in ${n.file}:${n.line}:${n.column}`),this.config.clientVersion):this.logEmitter.emit(n.level,{timestamp:new Date,message:n.message,target:n.module_path})}}getErrorMessageWithLink(r){return sa({platform:this.platform,title:r,version:this.config.clientVersion,engineVersion:this.versionInfo?.commit,database:this.config.activeProvider,query:this.lastQuery})}parseInitError(r){try{return JSON.parse(r)}catch{}return r}parseRequestError(r){try{return JSON.parse(r)}catch{}return r}on(r,n){r===""beforeExit""?this.beforeExitListener=n:this.logEmitter.on(r,n)}async start(){if(await this.libraryInstantiationPromise,await this.libraryStoppingPromise,this.libraryStartingPromise)return qe(`library already starting, this.libraryStarted: ${this.libraryStarted}`),this.libraryStartingPromise;if(this.libraryStarted)return;let r=async()=>{qe(""library starting"");try{let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.connect(JSON.stringify(n)),this.libraryStarted=!0,qe(""library started"")}catch(n){let i=this.parseInitError(n.message);throw typeof i==""string""?n:new Q(i.message,this.config.clientVersion,i.error_code)}finally{this.libraryStartingPromise=void 0}};return this.libraryStartingPromise=this.config.tracingHelper.runInChildSpan(""connect"",r),this.libraryStartingPromise}async stop(){if(await this.libraryStartingPromise,await this.executingQueryPromise,this.libraryStoppingPromise)return qe(""library is already stopping""),this.libraryStoppingPromise;if(!this.libraryStarted)return;let r=async()=>{await new Promise(i=>setTimeout(i,5)),qe(""library stopping"");let n={traceparent:this.config.tracingHelper.getTraceParent()};await this.engine?.disconnect(JSON.stringify(n)),this.libraryStarted=!1,this.libraryStoppingPromise=void 0,qe(""library stopped"")};return this.libraryStoppingPromise=this.config.tracingHelper.runInChildSpan(""disconnect"",r),this.libraryStoppingPromise}async getDmmf(){await this.start();let r=this.config.tracingHelper.getTraceParent(),n=await this.engine.dmmf(JSON.stringify({traceparent:r}));return this.config.tracingHelper.runInChildSpan({name:""parseDmmf"",internal:!0},()=>JSON.parse(n))}version(){return this.versionInfo=this.library?.version(),this.versionInfo?.version??""unknown""}debugPanic(r){return this.library?.debugPanic(r)}async request(r,{traceparent:n,interactiveTransaction:i}){qe(`sending request, this.libraryStarted: ${this.libraryStarted}`);let o=JSON.stringify({traceparent:n}),s=JSON.stringify(r);try{await this.start(),this.executingQueryPromise=this.engine?.query(s,o,i?.id),this.lastQuery=s;let a=this.parseEngineResponse(await this.executingQueryPromise);if(a.errors)throw a.errors.length===1?this.buildQueryError(a.errors[0]):new oe(JSON.stringify(a.errors),{clientVersion:this.config.clientVersion});if(this.loggerRustPanic)throw this.loggerRustPanic;return{data:a,elapsed:0}}catch(a){if(a instanceof Q)throw a;if(a.code===""GenericFailure""&&a.message?.startsWith(""PANIC:""))throw new be(this.getErrorMessageWithLink(a.message),this.config.clientVersion);let l=this.parseRequestError(a.message);throw typeof l==""string""?a:new oe(`${l.message}

2023-08-15T15:45:33.495 app[148ed6e1f7d248] mia [info] ^

2023-08-15T15:45:33.504 app[148ed6e1f7d248] mia [info] PrismaClientInitializationError: Error opening a TLS connection: unexpected EOF

2023-08-15T15:45:33.504 app[148ed6e1f7d248] mia [info] at r (/triggerdotdev/node_modules/.pnpm/@prisma+client@4.16.2_prisma@4.16.0/node_modules/@prisma/client/runtime/library.js:108:2574)

2023-08-15T15:45:33.567 app[148ed6e1f7d248] mia [info]  ELIFECYCLE  Command failed with exit code 1.

2023-08-15T15:45:33.739 app[148ed6e1f7d248] mia [info] INFO Main child exited normally with code: 1

2023-08-15T15:45:33.739 app[148ed6e1f7d248] mia [info] INFO Starting clean up.

2023-08-15T15:45:33.740 app[148ed6e1f7d248] mia [info] WARN hallpass exited, pid: 256, status: signal: 15 (SIGTERM)

2023-08-15T15:45:33.748 app[148ed6e1f7d248] mia [info] 2023/08/15 15:45:33 listening on [fdaa:2:4fd7:a7b:184:f397:2946:2]:22 (DNS: [fdaa::3]:53)

2023-08-15T15:45:34.741 app[148ed6e1f7d248] mia [info] [ 10.303148] reboot: Restarting system

2023-08-15T15:45:34.896 runner[148ed6e1f7d248] mia [info] machine has reached its max restart count (10)",,
1851512422,338,"[TRI-1068] Improve `io.runTask`: move callback to second arg and move ""task options"" to be an optional 3rd argument","Currently `io.runTask` looks like this:

```ts
await io.runTask(""key"", { name: ""Task 1"" }, async (task) => {});
```

Which is kind of ugly. We should make the second ""task options"" parameter by an optional 3rd argument so the above can be written like:

```ts
await io.runTask(""key"", async (task) => {});
```

And then if you want to specify task options:

```ts
await io.runTask(""key"", async (task) => {}, { name: ""Task 1"" });
```

<sub>[TRI-1068](https://linear.app/triggerdotdev/issue/TRI-1068/improve-ioruntask-move-callback-to-second-arg-and-move-task-options-to)</sub>",,
1851173335,337,[TRI-1065] Improvement: ability to configure job execution retry options and better docs on run retry workings,"Retrying job run executions is currently hardcoded but we should allow users to define (on the client level) different options for retrying, with certain limits. For example

```ts
new TriggerClient({
  // .. other options
  runs: {
    retries: 25,
    factor: 2,
    minTimeout: 1000,
    maxTimeout: 30000,
    randomize: true
  }
});
```

I think this belongs on the TriggerClient instead of the Job because this is a ""deployment"" factor, relating more to the characteristics of where the TriggerClient is running than anything about a specific job.

https://github.com/triggerdotdev/trigger.dev/blob/main/apps/webapp/app/services/runs/performRunExecution.server.ts

<sub>[TRI-1065](https://linear.app/triggerdotdev/issue/TRI-1065/improvement-ability-to-configure-job-execution-retry-options-and)</sub>",,
1849746711,331,[TRI-1029] `@trigger.dev/react` doesn't work out of the box with Next.js Page Router: Cannot use import statement outside a module Error,"When using `@trigger.dev/react` in Next.js Page Router, importing will cause an error because Page Router modules aren't automatically transpiled to CJS (whereas they are in App Router).

From Next 13.1 onwards, the fix is to the add `@trigger.dev/react` to the list of transpiled packages in the next.config.js file:

```js
const nextConfig = {
  transpilePackages: [""@trigger.dev/react""],
};

module.exports = nextConfig;
```

In Next versions below 13.1, the [next-transpile-modules](https://www.npmjs.com/package/next-transpile-modules) package should be used in `next.config.js`:

```js next.config.js
const withTM = require('next-transpile-modules')(['@trigger.dev/react']); // pass the modules you would like to see transpiled

module.exports = withTM({});
```

We should do the following:

- [ ] Look into why Next.js is using the ESM module exported by `@trigger.dev/react` instead of the CJS
- [ ] If nothing can be done about the above issue, then we should make sure `@trigger.dev/cli init` correctly handles this (whenever the `@trigger.dev/react` stuff is added to the `init` command (see https://github.com/triggerdotdev/trigger.dev/issues/330)
- [ ] Add to the React Hooks docs (and the Next.js quickstart) info about this

<sub>[TRI-1029](https://linear.app/triggerdotdev/issue/TRI-1029/triggerdevreact-doesnt-work-out-of-the-box-with-nextjs-page-router)</sub>",,
1847041666,315,[TRI-1008] Add `io.waitUntil` function to allow a job run to wait for a dynamic condition,"This kind of thing would be really useful in jobs:

```ts
await io.waitUntil(""has used invite"", {
  condition: async () => {
    const user = await prisma.user.findUniqueOrThrow({
      where: {
        id: payload.userId,
      },
    });

    return user.invitationCodeId !== null;
  },
});
```

This would basically retry the condition function in an interval, and only continue once the condition function returned `true`.

The strategy for how frequent to call the condition function could be configurable:

- Set an interval frequency (minimum would be 60 seconds, max would be 1 day). Would also need some kind of timeout thing like ""exit if the condition doesn't return true within 30 days""
- Set an exponential backoff strategy (similar to our task retries) with a maximum of 25 retries

This can be achieved using only subtasks and `io.wait`, something like:

```ts
type WaitUntilOptions = {
  condition: () => Promise<boolean>;
  checkInterval?: number;
};

function waitUntil(
  key: string,
  io: IO,
  options: WaitUntilOptions
): Promise<void> {
  return io.runTask(
    key,
    {
      name: ""Wait until"",
    },
    async (task) => {
      const result = await options.condition();
      if (result) return;

      //if more than 14 days has passed then throw
      const startedAt = task.startedAt;
      if (!startedAt) return;
      const now = new Date();
      const diff = now.getTime() - startedAt.getTime();
      const days = diff / (1000 * 60 * 60 * 24);
      if (days > 14) {
        throw new Error(
          `Waited for 14 days for condition to be true but it never was.`
        );
      }

      await io.wait(
        `${key}:${new Date().toISOString()}`,
        options.checkInterval ? Math.max(options.checkInterval, 30) : 60 * 60
      );
    }
  );
}
```

But i'd prefer this not to produce a bunch of tasks that are only there for the interval. 



<sub>[TRI-1008](https://linear.app/triggerdotdev/issue/TRI-1008/add-iowaituntil-function-to-allow-a-job-run-to-wait-for-a-dynamic)</sub>",,
1846782525,310,[TRI-1007] Better handle retrying rate-limited resend requests in `@trigger.dev/resend`,"Resend has a rate limit of 10 requests per second. They also send [Rate limit headers](https://resend.com/docs/api-reference/introduction#rate-limit) with every request, meaning we should be able to use the same method as we do in our GitHub integration to only retry a sendEmail task when it will actually succeed, instead of doing a backoff strategy.

The `sendEmail` task is defined here: 

https://github.com/triggerdotdev/trigger.dev/blob/main/integrations/resend/src/index.ts#L10

You can see how we schedule retries using rate limiting headers in our github integration here:

https://github.com/triggerdotdev/trigger.dev/blob/c246578a8123cdd53bed819bee33cb16c85df561/integrations/github/src/tasks.ts#L18

<sub>[TRI-1007](https://linear.app/triggerdotdev/issue/TRI-1007/better-handle-retrying-rate-limited-resend-requests-in)</sub>",,
1846728954,308,Bug: Express applications using own body parser middleware will crash ,"## Context

Express middleware usage per the example provided in the package/code is as follows:

```js
 * @example
 * ```ts
 * import express from ""express"";
 * import { TriggerClient } from ""@trigger.dev/sdk"";
 * import { createMiddleware } from ""@trigger.dev/express"";
 *
 * const client = new TriggerClient({
 *  id: ""my-client"",
 *  apiKey: process.env[""TRIGGER_API_KEY""]!,
 * });
 *
 * const app = express();
 *
 * const middleware = createMiddleware(client);
 *
 * app.use(middleware);
 *
 * app.listen(8080, () => {
 *  console.log(""Listening on port 8080"");
 * });
 * ```
 */
```

## Expected

It's a probable assumption that many Express applications make use of Express's built-in `bodyParser` in order to access HTTP requests JSON payload via `req.body`, such as:

```js
const express = require('express')
const app = express()
app.use(express.json())

// respond with ""hello world"" when a GET request is made to the homepage
app.post('/api/hello', (req, res) => {
  res.send('hello ', req.body.name)
})
```

Using Trigger.dev's Express integration should work fine.

## Actual

Due to the Express integration code here https://github.com/triggerdotdev/trigger.dev/blob/main/packages/express/src/index.ts#L93C1-L97 

The `body` object key isn't receiving a stream in the format it expects, and as such the middleware function throws an exception (which leads to a Node.js process crash, documented reasons via #306):

```sh
$ node server.js

Listening on port 8080
undefined:1

SyntaxError: Unexpected end of JSON input
    at JSON.parse (<anonymous>)
    at Request.json (/Users/lirantal/projects/repos/trigger.dev/node_modules/.pnpm/@remix-run+web-fetch@4.3.5/node_modules/@remix-run/web-fetch/dist/lib.node.cjs:465:15)
    at processTicksAndRejections (node:internal/process/task_queues:96:5)
    at async TriggerClient.handleRequest (/Users/lirantal/projects/repos/trigger.dev/packages/trigger-sdk/dist/index.js:1262:22)
    at async /Users/lirantal/projects/repos/trigger.dev/packages/express/dist/index.js:61:22
```

",,
1846693602,306,Bug: current async middleware doesn't catch exceptions,"## Context

Express middleware usage is:

```js
const middleware = createMiddleware(client);
app.use(middleware);
```

## Expected

If for any reason the code in this middleware throws an exception then the error shouldn't crash the Node.js process, and instead be forwarded to the next middleware via `next(error)`

## Actual

If any exceptions are thrown within the middleware code provided by `@trigger.dev/express`, it won't be caught and will crash the Node.js process as an 'uncaught exception' scenario.

This happens to Express lacking native support for promises and so any async promises code within middleware needs to be wrapped with a try/catch.",,
1845809315,303,Removing the fetch fork from the Express package,"## Expected results

The Express package at `@trigger.dev/express` uses the remix fork of a fetch implementation which IMHO adds an unnecessary dependency that is yet one more thing to maintain and worry about, and unnecessarily adds more code handling and import that don't help with readability.

Is there a specific reason to rely on `@remix-run/web-fetch` ? Node.js natively supports fetch.

## Actual results

I'm in favor of keeping things simple and straight-forward and would want to propose a code update that refactors the dependency out and implements the headers copy for the trigger.dev handshake via vanilla Node.js / JS code.",,
1843349121,294,[TRI-970] Create documentation guide for EventFilter,"We need to create a full guide in the documentation that covers `EventFilter` and how to use it.

We [currently have a small section on the docs event page](https://trigger.dev/docs/documentation/concepts/triggers/events#event-filters), but this should be fleshed out and turned into a full separate page.

Check out this file for how it works:

[https://github.com/triggerdotdev/trigger.dev/blob/main/packages/core/test/eventFilterMatches.test.ts](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/core/test/eventFilterMatches.test.ts)

Should also cover how to use it in the context of `eventTrigger`:

[https://github.com/triggerdotdev/trigger.dev/blob/645643ea41430dd30145565f1deac2a5d483ab62/packages/trigger-sdk/src/triggers/eventTrigger.ts#L11](https://github.com/triggerdotdev/trigger.dev/blob/645643ea41430dd30145565f1deac2a5d483ab62/packages/trigger-sdk/src/triggers/eventTrigger.ts#L11)

Other types of Triggers also support `EventFilter`, such as stripe triggers:

[https://github.com/triggerdotdev/trigger.dev/blob/645643ea41430dd30145565f1deac2a5d483ab62/integrations/stripe/src/index.ts#L345](https://github.com/triggerdotdev/trigger.dev/blob/645643ea41430dd30145565f1deac2a5d483ab62/integrations/stripe/src/index.ts#L345)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-970](https://linear.app/triggerdotdev/issue/TRI-970/create-documentation-guide-for-eventfilter)</sub>",,
1843332483,293,[TRI-969] Add support for returning Blob from `io.runTask` callback,"Currently it's not possible to return a Blob from io.runTask. The types work but it doesn't work in practice, since we serialize/deserialize task outputs when they are saved to the database. Explicit support should be added to runTask to support this. For example, it's not currently possible to download a file using our supabase integration:

```ts
const data = await io.supabase.runTask(""download-file"", async (supa) => {
      const response = await supa.storage
        .from(payload.record.bucket_id!)
        .download(payload.record.name!);

      if (response.error) {
        throw response.error;
      }

      return response.data; // response.data is a Blob
    });
```

<sub>[TRI-969](https://linear.app/triggerdotdev/issue/TRI-969/add-support-for-returning-blob-from-ioruntask-callback)</sub>",,
1841310653,280,[TRI-950] `io.runTask` return type of the callback has TypeScript error when it includes an `unknown` type,"To recreate this issue:

```ts
await io.runTask(""foo"", { name: ""Foo"" }, async () => {
  return {
    foo: ""bar"",
  } as unknown;
});
```

That is because the return type of the callback is typed as required to extend `SerializedJson`:

https://github.com/triggerdotdev/trigger.dev/blob/fa942fc9f5aa1c2255efdb6304600be7f89cf20b/packages/trigger-sdk/src/io.ts#L434

We do this so the types of the return of `runTask` will match what is actually returned, since we run the results of the `runTask` callback through a JSON stringify/parsing as task output is stored in the database as JSON. Because of Resumability, this is a requirement, unless another solution can be identified.

I'm also now realizing that this SerializedJson might be incorrectly typed as well, as it can include `Date` and `Symbol`:

https://github.com/triggerdotdev/trigger.dev/blob/fa942fc9f5aa1c2255efdb6304600be7f89cf20b/packages/core/src/schemas/json.ts#L12

So this could cause issues when resuming a run and using the cached task output, where Date's would be symbols and the types would be wrong. It would be great to test this and possible change the required type to `DeserializedJson`. 

<sub>[TRI-950](https://linear.app/triggerdotdev/issue/TRI-950/ioruntask-return-type-of-the-callback-has-typescript-error-when-it)</sub>",,
1836592665,260,[TRI-878] CLI init fails with Next.js projects that don't have a next.config.js,"It's not compulsory to have a `next.config.js` file. For example this repo: [https://github.com/rishi-raj-jain/lemonsqueezy-nextjs-poc](https://github.com/rishi-raj-jain/lemonsqueezy-nextjs-poc).

Instead we should look at the `package.json` for the `next` dependency: [https://github.com/rishi-raj-jain/lemonsqueezy-nextjs-poc/blob/997ef6cd4680ee8bd4fe9d466ede6dacad3b0d91/package.json#L16](https://github.com/rishi-raj-jain/lemonsqueezy-nextjs-poc/blob/997ef6cd4680ee8bd4fe9d466ede6dacad3b0d91/package.json#L16)

This file needs updating with improved logic, checking for the `next` key in the package.json dependencies object. [https://github.com/triggerdotdev/trigger.dev/blob/main/packages/cli/src/utils/detectNextJsProject.ts](https://github.com/triggerdotdev/trigger.dev/blob/main/packages/cli/src/utils/detectNextJsProject.ts)

It should be tested in a Next project – see the Contributions guide for how to test the CLI.

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-878](https://linear.app/triggerdotdev/issue/TRI-878/cli-init-fails-with-nextjs-projects-that-dont-have-a-nextconfigjs)</sub>",,
1836502707,259,"[TRI-886] Update ""Create an integration"" docs for monorepo with tsconfig paths","When creating an integration inside the Trigger.dev monorepo (this repo) you need to add some paths to the tsconfig. Like this: [https://github.com/triggerdotdev/trigger.dev/blob/main/integrations/resend/tsconfig.json](https://github.com/triggerdotdev/trigger.dev/blob/main/integrations/resend/tsconfig.json)

We should add this to our docs page: [https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/create.mdx](https://github.com/triggerdotdev/trigger.dev/blob/main/docs/integrations/create.mdx)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-886](https://linear.app/triggerdotdev/issue/TRI-886/update-create-an-integration-docs-for-monorepo-with-tsconfig-paths)</sub>",,
1835754182,258,@trigger.dev/express throws Request with GET/HEAD method cannot have body,"Hey Folks,

Today while I'm doing a PoC with the trigger client with the express adapter, when I run 'trigger-cli dev' the express server just throws  `throws Request with GET/HEAD method cannot have body`

I followed the error and it seems an error in the `@trigger.dev/express` when it tries to convert to a standard request in specific to this line:

https://github.com/triggerdotdev/trigger.dev/blob/1b0973fbc12ab1442b6deb75b745c4ced7edf6fb/packages/express/src/index.ts#L97",,
1833741890,251,[TRI-563] Add an event catalog to TriggerClient and generic type inference to `sendEvent()`,"# Proposal

## Adding an event catalog to TriggerClient

```
new TriggerClient({ events: { ... } })
```

You can specify the possible events on the TriggerClient. Then they would be type checked when using sendEvent, and we can pull that information into the Dashboard to display and improve the test experience.

## Allow passing a generic argument to sendEvent

client.sendEvent and io.sendEvent can accept the event type. This would take precedence over the catalog.

```
const job = client.defineJob({
  id: ""test-background-fetch-retry"",
  name: ""Test background fetch retry"",
  version: ""0.0.1"",
  enabled,
  trigger: eventTrigger({
    name: ""test.background-fetch"",
    schema: z.object({
      url: z.string(),
    }),
  }),
  run: async (payload, io, ctx) => {
    
  },
});

//add the ability to have type inference on sendEvent
client.sendEvent<myEvent>({ name: ""test.background-fetch"", payload: { url: ""https://google.com"" }});
```

It would check/autocomplete the name of the event, as well as the payload.

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-563](https://linear.app/triggerdotdev/issue/TRI-563/add-an-event-catalog-to-triggerclient-and-generic-type-inference-to)</sub>",,
1833233280,245,[TRI-861] Next.js warning - Module not found: Can't resolve encoding,"Using the `@trigger.dev/sdk` in a Next.js project produces the following warning:

```
- warn ./node_modules/node-fetch/lib/index.js
Module not found: Can't resolve 'encoding' in '/Users/eric/code/triggerdotdev/trigger.dev-examples/latest-packages/node_modules/node-fetch/lib'
```

It turns out this is a pretty widely experienced warning that doesn't actually effect anything in Next.js. See this supabase-js issue:

https://github.com/supabase/supabase-js/issues/612

`encoding` is an optional dependency of `node-fetch` and so there is no issue with it missing.

If you would like to get rid of this warning, just run:

```sh
npm add encoding -D
```

To add the `encoding` dependency to your dev deps. Of course this won't stop this warning from appearing from production builds, so you can also do:

```sh
npm add encoding
```

<sub>[TRI-861](https://linear.app/triggerdotdev/issue/TRI-861/nextjs-warning-module-not-found-cant-resolve-encoding)</sub>",,
1829492756,239,[TRI-828] Connection scopes (for github at least) aren't being properly stored as an array of strings,"If you connect to github through OAuth, and then view the scopes in the IntegrationConnection table, you should notice that it is an array of scopes, but with a single string separated by commas. 

![CleanShot 2023-07-31 at 16.32.39@2x.png](https://uploads.linear.app/80a884b1-f84c-49d6-91db-07a391663d20/63425761-3080-41f0-97d2-dd106fc5a425/0177fc67-abba-43b8-87ef-a58b125f8fc7?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzgwYTg4NGIxLWY4NGMtNDlkNi05MWRiLTA3YTM5MTY2M2QyMC82MzQyNTc2MS0zMDgwLTQxZjAtOTdkMi1kZDEwNmZjNWE0MjUvMDE3N2ZjNjctYWJiYS00M2I4LTg3ZWYtYTU4YjEyNWY4ZmM3IiwiaWF0IjoxNjkwODE3NjkwLCJleHAiOjE2OTA5MDQwOTB9.OVjU04lFn4GKRWSJq_sVbi7PKM0aXP3dpoAPSIX2Xvc)

It seems like the convertToken ([https://github.com/triggerdotdev/trigger.dev/blob/463cbed7dfbd1ab5fca80efadfe8c61aad518c49/apps/webapp/app/services/externalApis/oauth2.server.ts#L249](https://github.com/triggerdotdev/trigger.dev/blob/463cbed7dfbd1ab5fca80efadfe8c61aad518c49/apps/webapp/app/services/externalApis/oauth2.server.ts#L249)) function isn't correctly splitting the scopes string, because the scopeSeparator for github is a space but as you can see from the screenshot above, the scopes are coming back comma separated. This might be a case where the scopes are space separated when constructing them to be sent to github but formatted in a different way when getting the scopes.

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-828](https://linear.app/triggerdotdev/issue/TRI-828/connection-scopes-for-github-at-least-arent-being-properly-stored-as)</sub>",,
1823075025,224,[TRI-768] The CLI init command should generate a jobs/index file and jobs should be imported there.,"When `npx @trigger.dev/cli@latest init` is run it generates the Trigger API route, and an example job.

In the Trigger API route (`app/api/trigger.route.ts` for app router and `pages/api/trigger.ts` for pages router) it imports an individual example job:

```
import { createAppRoute } from ""@trigger.dev/nextjs"";
import { client } from ""@/trigger"";

// Replace this with your own jobs
import ""@/jobs/examples"";

//this route is used to send and receive data with Trigger.dev
export const { POST, dynamic } = createAppRoute(client);
```

Let's change it so we have an `index` file inside the `jobs` folder and just that is imported here.

In that `index` file we would import the `examples` file.

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-768](https://linear.app/triggerdotdev/issue/TRI-768/the-cli-init-command-should-generate-a-jobsindex-file-and-jobs-should)</sub>",,
1820071663,211,[TRI-732] Replace `tsconfig` package with `tsconfck` in @trigger.dev/cli,"Currently we are using the [tsconfig](https://www.npmjs.com/package/tsconfig) package for parsing/resolving the tsconfig.json file, but unfortunately the tsconfig package does not support trailing commas (see [here](https://github.com/TypeStrong/tsconfig/issues/30)) (which tsconfig.json does for some reason). We should replace the tsconfig package with [tsconfck](https://www.npmjs.com/package/tsconfck) to better support the weird dialect of JSON that is tsconfig.json.

<sub>[TRI-732](https://linear.app/triggerdotdev/issue/TRI-732/replace-tsconfig-package-with-tsconfck-in-triggerdevcli)</sub>",,
1819871948,210,[TRI-728] @trigger.dev/cli dev command should actually detect if a Next.js project is running on the specified port before opening a tunnel,"Currently in the dev command we don't check if there is a server running locally on the specified port (by default port 3000) in the `dev` command, even though we say we are (see code here: https://github.com/triggerdotdev/trigger.dev/blob/09f906f7a193ade59fb65eaf8da936fe428f13b9/packages/cli/src/commands/dev.ts#L56)

If there is no server found running on the port, we should print an error message clearly explaining the issue and then exit the command.

The way to check if there is a server found running on the port is to perform a ""PING"" to the `endpointHandlerUrl`.  You can do that with the following code (which uses node-fetch)

```ts
const response = await fetch(endpointHandlerUrl, {
  method: ""HEAD"",
  headers: {
    ""x-trigger-api-key"": apiKey,
    ""x-trigger-action"": ""PING"",
    ""x-trigger-endpoint-id"": endpointId,
  },
});
```

<sub>[TRI-728](https://linear.app/triggerdotdev/issue/TRI-728/triggerdevcli-dev-command-should-actually-detect-if-a-nextjs-project)</sub>",,
1816698388,205,[TRI-711] Add JavaScript support to the CLI init command,"Currently the init command generates TypeScript files:

* trigger.ts
* The API route (location and content varies for pages or app router)
* Example job file

If JavaScript is detected then we should generate JS files instead of TS.

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-711](https://linear.app/triggerdotdev/issue/TRI-711/add-javascript-support-to-the-cli-init-command)</sub>",,
1815411930,201,[TRI-709] Add git database tasks to `@trigger.dev/github` integration,"The `@trigger.dev/github` integration currently only supports a limited number of tasks found here:

https://github.com/triggerdotdev/trigger.dev/blob/main/integrations/github/src/tasks.ts

We should add tasks for cover the entire ""git database"" collection of rest API endpoints, found here:

- [ ] Blobs: https://docs.github.com/en/rest/git/blobs?apiVersion=2022-11-28
- [ ] Commits: https://docs.github.com/en/rest/git/commits?apiVersion=2022-11-28
- [ ] References: https://docs.github.com/en/rest/git/refs?apiVersion=2022-11-28
- [ ] Tags: https://docs.github.com/en/rest/git/tags?apiVersion=2022-11-28
- [ ] Trees: https://docs.github.com/en/rest/git/trees?apiVersion=2022-11-28



<sub>[TRI-709](https://linear.app/triggerdotdev/issue/TRI-709/add-git-database-tasks-to-triggerdevgithub-integration)</sub>",,
1813269503,198,[TRI-703] Chore: update webapp to Remix 2.0.1,"We're already using most of Remix's v2 features, as future flags in our [remix.config.js](https://github.com/triggerdotdev/trigger.dev/blob/e350659e244e6976747f726984c83a780ba94882/apps/webapp/remix.config.js#L3).

## How to

1. Read Remix's recommendations in the [v2 release](https://github.com/remix-run/remix/releases/tag/remix%402.0.0)
2. They recommend upgrading to 1.19.3 first: `npx upgrade-remix 1.19.3`.
3. Upgrading to `v2_meta` and `v2_headers`. These should be trivial as I don't think we use the headers function anywhere, and every route on the site requires login so only the root.tsx meta function is being used right now.
4. Upgrade Remix to [v2.0.1](https://github.com/remix-run/remix/releases/tag/remix%402.0.1).
5. Run `pnpm run typecheck --filter webapp` to find and fix TypeScript errors.
6. Run the webapp and check it functions as expected

Please follow the [contribution guide](https://github.com/triggerdotdev/trigger.dev/blob/main/CONTRIBUTING.md) development section to setup and run the web app.

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-703](https://linear.app/triggerdotdev/issue/TRI-703/chore-update-webapp-to-remix-201)</sub>",,
1809828805,186,[TRI-689] Login through magic link not working in Safari when running on localhost:3030,"Safari version: Version 16.4.1 (17615.1.26.101.10, 17615)

To recreate, make sure you DON'T have the `RESEND_API_KEY` env var set, so the magic link is printed to the terminal instead of actually sent as an email (I can't recreate the problem when the magic link is sent through the email).

After navigating to the magic link (in Safari) you will get redirected back to the magic link page, instead of into the dashboard.

I'm thinking this might have something to do with the the cookie session storage (which you can find here: https://github.com/triggerdotdev/trigger.dev/blob/bca0df2692a9255d79a3858e8bb091cdfa883632/apps/webapp/app/services/sessionStorage.server.ts) but I'm not exactly sure what is causing it

<sub>[TRI-689](https://linear.app/triggerdotdev/issue/TRI-689/login-through-magic-link-not-working-in-safari-when-running-on)</sub>",,
1803316979,158,[TRI-651] @trigger.dev/typeform: Check that webhook has a matching url,"When registering a typeform webhook, we see if an existing webhook for the tag/form exists, and if it does we update the webhook and return. We also need to make sure that the url of the webhook matches that of the `httpSource.url`. If they don't match, then we need to take the ""create webhook"" path.

[https://github.com/triggerdotdev/trigger.dev/blob/main/integrations/typeform/src/index.ts#L189](https://github.com/triggerdotdev/trigger.dev/blob/main/integrations/typeform/src/index.ts#L189)

<sub>From [SyncLinear.com](https://synclinear.com) | [TRI-651](https://linear.app/triggerdotdev/issue/TRI-651/triggerdevtypeform-check-that-webhook-has-a-matching-url)</sub>",,
1794108154,145,"Error with setup ""pnpm dlx @trigger.dev/cli@latest init"" vs. ""npx @trigger.dev/cli@latest init -k tr_dev_*********** -t https://cloud.trigger.dev""","I was having a problem with setting up the initial init. I was following the tutorial from the jobs page and when I copy and paste the string with the params included from step 1 it fails. (See fig 1. and fig.2)

```Aborting installation...
TypeError [ERR_INVALID_URL]: Invalid URL
 ERROR  Command failed with exit code 1: cli init -k tr_dev_***********  -t https://cloud.trigger.dev

pnpm: Command failed with exit code 1: cli init -k tr_dev_*********** -t https://cloud.trigger.dev
    at makeError (/opt/homebrew/Cellar/pnpm/8.6.2/libexec/dist/pnpm.cjs:24241:17)
    at handlePromise (/opt/homebrew/Cellar/pnpm/8.6.2/libexec/dist/pnpm.cjs:24812:33)
    at runMicrotasks (<anonymous>)
    at processTicksAndRejections (node:internal/process/task_queues:96:5)
    at async Object.handler [as dlx] (/opt/homebrew/Cellar/pnpm/8.6.2/libexec/dist/pnpm.cjs:207055:7)
    at async /opt/homebrew/Cellar/pnpm/8.6.2/libexec/dist/pnpm.cjs:216461:21
    at async main (/opt/homebrew/Cellar/pnpm/8.6.2/libexec/dist/pnpm.cjs:216428:34)
    at async runPnpm (/opt/homebrew/Cellar/pnpm/8.6.2/libexec/dist/pnpm.cjs:216683:5)
    at async /opt/homebrew/Cellar/pnpm/8.6.2/libexec/dist/pnpm.cjs:216675:7
```

<img width=""731"" alt=""Screenshot 2023-07-07 at 3 15 50 PM"" src=""https://github.com/triggerdotdev/trigger.dev/assets/43126781/fdd8a368-b5e0-46eb-ada2-4d6bf1cb2cf5""> fig 1.


<img width=""661"" alt=""Screenshot 2023-07-07 at 3 14 02 PM"" src=""https://github.com/triggerdotdev/trigger.dev/assets/43126781/74f2acfa-2d72-4432-96dd-119af1fb9c3b""> fig 2.

But if I follow the guide from https://trigger.dev/docs/documentation/quickstart and I don't pass the params and use the command line it works. (See fig 3.)

Works: ```pnpm dlx @trigger.dev/cli@latest init```
Does not work:  ```pnpm dlx @trigger.dev/cli@latest init -k tr_dev_********** -t https://cloud.trigger.dev```

<img width=""701"" alt=""Screenshot 2023-07-07 at 3 16 25 PM"" src=""https://github.com/triggerdotdev/trigger.dev/assets/43126781/50516275-d7c2-4c47-a342-6050c16e1fbf"">


",,
1639642336,109,Create @trigger.dev/nextjs adapter,"Create an adapter for using Trigger.dev in a next.js project. Something like this:

```ts
import { Trigger, EntryPoint, customEvent } from ""@trigger.dev/sdk"";
import { createHandler } from ""@trigger.dev/nextjs"";

const entryPoint = new EntryPoint({
  apiKey: process.env.TRIGGER_API_KEY,
});

new Trigger({
  id: ""my-workflow"",
  name: ""My workflow"",
  logLevel: ""debug"",
  on: customEvent({ name: ""user.created"" }),
  run: async (event, ctx) => {
    await ctx.logger.info(""Inside the smoke test workflow, received event"", {
      event,
      myDate: new Date(),
    });

    return { foo: ""bar"" };
  },
}).register(entryPoint);

const handler = createHandler(entryPoint);

export default handler;
```",,
1620438749,78,require esm error,"Follow the steps

1. npx create-trigger@latest blank-starter
1. yarn
2. yarn build
3. yarn start

And I got

```
Error [ERR_REQUIRE_ESM]: require() of ES Module node_modules/terminal-link/index.js from /node_modules/@trigger.dev/sdk/dist/index.js not supported.
```",,
1580832061,58,runOnce doesn't get re-run on server restart,"If a runOnce task doesn't complete and your server goes down, it doesn't retry when the server is back up.

```js
run: async (event, ctx) => {
    const { videoId } = event;
    const result = await ctx.runOnce(videoId, async (idempotencyKey) => {
      await new Promise((r) => setTimeout(r, 10000));
      return ""finished"";
    });
    return { result };
  }
```

This does not restart if I kill the server mid-way. It just console.logs this when the server is back up:
 `[trigger.dev]  Run cldzype0* complete 🏃 [render-video]`",,
